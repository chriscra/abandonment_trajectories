---
title: "Summary statistics"
author: "Christopher L. Crawford"
date: "4/23/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r initialize}
source("/Users/christophercrawford/Google_Drive/_Projects/abandonment_trajectories/scripts/0_start.R")
source(paste0(p_proj, "scripts/util/_util_master.R"))
```

```{r load-data}
run_label <- "_2021_03_13"

# load combined persistence, area, and turnover datasets:

# replaced "abn_decay_data" with "persistence_dat"
# in 4_decay_models.Rmd, this object is also referred to as "dat_l"
persistence_dat <- read_csv(file = paste0(p_dat_derived, "persistence_dat", run_label, ".csv")) %>%
  mutate(site = as.factor(site),
         bins = as.factor(bins),
         year_abn_bins = as.factor(year_abn_bins),
         cohort = as.factor(cohort))

area_dat <- read_csv(file = paste0(p_dat_derived, "area_dat", run_label, ".csv"))
turnover_dat <- read_csv(file = paste0(p_dat_derived, "turnover_dat", run_label, ".csv"))

site_df <- read.csv(file = paste0(p_dat_derived, "site_df.csv"))

```


# Summary statistics for manuscript

```{r calc-mean-lengths}
# -------------------------------------------------------- #
# Christopher Crawford, Princeton University, March 9th, 2021

# Script to produce length plots based on distilled length data.tables from "3_distill_lengths.R"
# -------------------------------------------------------- #


# download from the cluster with the following bash command:
# scp clc6@della:/scratch/network/clc6/abandonment_trajectories/data_derived/input_rasters/length_distill_df_2021-03-05.csv /Users/christophercrawford/Google\ Drive/_Projects/abandonment_trajectories/data_derived/_2021-03-05/


# set up parameters:
# data.frame of all sites contains information about sites
site_df <- read.csv(file = paste0(p_dat_derived, "site_df.csv"))

run_label <- "_2021_03_13" #"_2021-03-05"
# _2021_03_13



# 0. Load distilled length data
length_distill_df <- read_csv(file = paste0(p_dat_derived, run_label, "/", 
                                            "length_distill_df", run_label, ".csv"))
# length_distill_df %>% filter(site == "shaanxi") %>% select(length_type) %>% unique()


mean_length_df <- lapply(c(1, 3, 5, 7, 10), function(x) {
  length_distill_df %>% as_tibble() %>% 
    mutate(product = length*freq) %>% 
    filter(length >= x) %>% # to filter by length # this is important for max, since some pixels have max length of 0
    group_by(site, length_type) %>% 
    summarise(
      n_abn_periods = sum(freq), # number of abandonment periods at each site:
      mean_duration = sum(product)/sum(freq),
      median_duration = median(rep(length, freq)),
      sd_duration = sd(rep(length, freq))
      ) %>% 
    mutate(abn_threshold = x) 
}) %>% bind_rows() %>% ungroup()

# add order for plotting:
mean_length_df <-
  mean_length_df %>%
  left_join(., 
            filter(., abn_threshold == 5, length_type == "all") %>% 
              arrange(mean_duration) %>% 
              mutate(order = 1:n()) %>% select(site, order)
            )


# save mean_length_df
write_csv(mean_length_df, file = paste0(p_dat_derived, run_label, "/", "mean_length_df", run_label, ".csv"))
cat(fill = TRUE, "Saved mean_length_df to:", paste0(p_dat_derived, run_label, "/", "mean_length_df", run_label, ".csv"))

# mean_length_df <- read_csv(file = paste0(p_dat_derived, run_label, "/", "mean_length_df", run_label, ".csv"))
```

## Mean abandonment duration

Question 1: There are two ways to calculate the mean duration across all sites. Which is better:
1. Mean of means: take the mean of all of the site mean lengths
2. Pool all raw abandonment periods together, and take mean of that. (Alternatively, the weighted mean of means by sample size.)

Question 2: If we calculate the mean of means, to deal with different sample sizes, how should we calculate the standard deviation?
1. Standard deviation of the mean values, or
2. Mean of standard deviations at each site.

The first has an advantage of giving each site the same weight. Because the sample sizes at each site are not the same, the interpretation gets a bit tricky if one simply pools all the periods. In this case, sites with a larger area, which have more pixels and therefore more periods of abandonment, have a larger effect on the overall mean.
the two are quite similar, so just use the mean of means

```{r all-sites-summary-stats, include = FALSE}
# ---------------------------------------------------------------- #
# 1. Take mean of the site mean lengths:
# note, this is the value given for the horizontal dashed lines on the main mean abn duration figure
# knitr::include_graphics(path = paste0(p_plots, run_label, "/mean_lengths", run_label, ".png"))


# load files ------------- #
# load all length data (distilled)
length_distill_df <- read_csv(file = paste0(p_dat_derived, run_label, "/", 
                                            "length_distill_df", run_label, ".csv"))

# load mean length data:
mean_length_df <- read_csv(file = paste0(p_dat_derived, run_label, "/", "mean_length_df", run_label, ".csv"))

mean_length_df %>% filter(abn_threshold == 5, length_type == "all") %>% .$sd_duration %>% summary()

summary_stats_all <- mean_length_df %>% 
  group_by(abn_threshold, length_type) %>%
  summarise(mean_of_means = mean(mean_duration, na.rm = TRUE),
            mean_of_medians = mean(median_duration, na.rm = TRUE),
            mean_of_sds = mean(sd_duration, na.rm = TRUE)
            )

# just # our standard 5 year abandonment threshold: 
summary_stats_all_sites <- mean_length_df %>%
  filter(abn_threshold == 5,
         length_type == "all") %>% 
  group_by(abn_threshold, length_type) %>%
  summarise(mean_of_means = mean(mean_duration),
            mean_of_medians = mean(median_duration),
            sd_of_means = sd(mean_duration),
            mean_of_sds = mean(sd_duration),
            mean_n_abn_periods = mean(n_abn_periods)
            )

summary_stats_all_sites$mean_of_means
summary_stats_all_sites$sd_of_means
summary_stats_all_sites$mean_of_sds

sd(filter(mean_length_df, length_type == "all", abn_threshold == 5)$mean_duration)


# ---------------------------------------------------------------- #
# 2. Pool all raw abandonment periods together
summary_stats_all_sites_pooled <- length_distill_df %>%
  as_tibble() %>%
  filter(length >= 5, length_type == "all") %>%
  mutate(product = length*freq) %>%
  group_by() %>%
  summarise(
    total_n_abn_periods = sum(freq),
    mean_duration = sum(product)/sum(freq),
    median_duration = median(rep(length, freq)),
    # mean_test = mean(rep(length, freq)), # same as above
    sd_duration = sd(rep(length, freq))
    )

summary_stats_all_sites_pooled$mean_duration

# alternatively, calculate the weighted mean, using the number of abandonment periods at each site:

mean_length_df %>% 
  filter(length_type == "all", abn_threshold == 5) %>% 
  mutate(prod = mean_duration * n_abn_periods) %>%
  group_by() %>%
  summarise(sum_prod = sum(prod),
            sum_n = sum(n_abn_periods),
            w_mean = sum_prod/sum_n)

# alternative method #2: make a vector of all periods, and compute stats directly
# length_filtered <- length_distill_df %>%
#   as_tibble() %>%
#   filter(length >= 5, length_type == "all")
# 
# length_filtered_distilled <- length_filtered %>% 
#   group_by(length) %>% 
#   summarise(total_freq = sum(freq)) 
# 
# repeats <- rep(length_filtered_distilled$length, length_filtered_distilled$total_freq)
# sd(repeats)
# mean(repeats)
# median(repeats)

# save files:

write_csv(summary_stats_all_sites, file = paste0(p_dat_derived, run_label, "/", "summary_stats_all_sites", run_label, ".csv"))

write_csv(summary_stats_all_sites_pooled, file = paste0(p_dat_derived, run_label, "/", "summary_stats_all_sites_pooled", run_label, ".csv"))


# summary_stats_all_sites <- read_csv(file = paste0(p_dat_derived, run_label, "/", "summary_stats_all_siteS", run_label, ".csv"))
# summary_stats_all_sites_pooled <- read_csv(file = paste0(p_dat_derived, run_label, "/", "summary_stats_all_sites_pooled", run_label, ".csv"))
```

### Save mean abandonment duration plots

Three plots:
1. Summary figure: mean length (all periods and max lengths) for each site
2. Summary lengths by abandonment threshold (like 1, but with different thresholds)
3. Histograms (all periods and max lengths)



```{r plot-mean-abn-duration}

# create directory for plot outputs
if(!dir.exists(paste0(p_output, "plots/", run_label))) {
  dir.create(paste0(p_output, "plots/", run_label))
}

# -------------------------------------------------------- #
# 1. Plot mean length of time abandoned (>= 5) ----

gg_mean_length <-
  ggplot(data = mean_length_df %>%
           filter(abn_threshold == "5"),
         mapping = aes(x = fct_reorder(site, order), #fct_reorder2(site, abn_threshold, desc(mean_duration)),
                       y = mean_duration, 
                       color = length_type)) + 
  theme_classic() +
  theme(axis.text.x = element_text(angle = 330, vjust = 1, hjust = 0),
        plot.caption = element_text(face = "italic")) +
  labs(#title = "Mean length of abandonment",
       #caption = "Counting only recultivation of 2 or more continuous years",
       linetype = NULL,
       color = "Mean of:", 
       y = "Mean abandonment duration (years)", 
       x = "Site") +
  geom_point(size = 2, alpha = 0.85) + 
  geom_hline(data = mean_length_df %>% 
               group_by(abn_threshold, length_type) %>%
               summarise(overall_mean = mean(mean_duration, na.rm = TRUE)) %>% 
               filter(abn_threshold == "5"), 
             mapping = aes(yintercept = overall_mean, 
                           col = length_type, 
                           linetype = "Mean \nAcross \nSites")) + 
  scale_linetype_manual(values = c("Mean \nAcross \nSites" = "dashed")) + 
  scale_color_discrete(labels = c(all = "All periods", 
                                   max = "Max. length \nper pixel")) +
  # scale_shape_manual(values = c(16, 21), # filled and closed circles
  #                    labels = c(all = "All periods", 
  #                               max = "Max. length \nper pixel")) + 
  scale_x_discrete(breaks = site_df$site,
                   labels = site_df$description) +
  scale_y_continuous(breaks = c(12:20)) + 
  guides(color = guide_legend(order = 1))
    


# ----------------- save ---------------- #
ggsave(plot = gg_mean_length,
       filename = paste0(p_plots, run_label, "/mean_lengths_long", run_label, ".pdf"), 
    width = 5.5, height = 5, units = "in")

# png(filename = paste0(p_output, "plots/", run_label, "/mean_lengths", run_label, ".png"), 
#     # width = 6, height = 5, 
#     width = 5, height = 4, 
#     units = "in", res = 400)
# print(gg_mean_length)
# dev.off()

library(colorblindr)
cvd_grid(gg_mean_length)



# 2. Plot mean length across multiple abandonment thresholds ------

gg_mean_length_by_threshold_old <-
  ggplot(data = mean_length_df,
         mapping = aes(x = fct_reorder(site, mean_duration), y = mean_duration, fill = fct_reorder(site, mean_duration))) + 
  theme_classic() +
  theme(
    axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0, size = 7),
        # plot.caption = element_text(face = "italic"),
        legend.position = "bottom") +
  labs(
    # title = "Mean length of abandonment",
       #caption = "Counting only recultivation of 2 or more continuous years",
       linetype = NULL,
       fill = "Site", 
       y = "Mean length of time abandoned (years)",
       x = "Site") +
  geom_col(width = 0.75) + #coord_flip() + 
  facet_grid(
    length_type ~ abn_threshold,
    # abn_threshold ~ length_type,
             labeller = labeller(length_type = c(all = "all lengths", #old = "new",
                                                 max = "max length per pixel"),
                                 abn_threshold = c("1" = "abn threshold = 1",
                                                   "3" = "abn threshold = 3",
                                                   "5" = "abn threshold = 5",
                                                   "7" = "abn threshold = 7",
                                                   "10" = "abn threshold = 10"))) +
  geom_hline(data = mean_length_df %>% 
               group_by(abn_threshold, length_type) %>%
               summarise(overall_mean = mean(mean_duration, na.rm = TRUE)), 
             mapping = aes(yintercept = overall_mean, linetype = "Mean across sites"),
             show.legend = TRUE,
             color = "black", size = 0.75) + 
  scale_linetype_manual(values = c("Mean across sites" = "dashed")) + 
  guides(
    # fill = guide_legend(override.aes = list(linetype = 0))
    fill = "none"
         )

gg_mean_length_by_threshold_side <-
  ggplot(data = mean_length_df,
         mapping = aes(x = fct_reorder(site, desc(mean_duration)), 
                       y = mean_duration, fill = as_factor(abn_threshold))) + 
  theme_classic() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 345, vjust = 1, hjust = 0)) +
  labs(linetype = NULL,
       fill = "Abandonment threshold (years)", 
       y = "Mean length of time abandoned (years)",
       x = "Site") +
  geom_col(width = 0.75, position = position_dodge()) + #coord_flip() +
  # geom_point(size = 2, position = position_dodge()) + #coord_flip() + 
  facet_grid(vars(length_type),
             labeller = labeller(length_type = c(all = "all lengths", #old = "new",
                                                 max = "max length per pixel"))) +
  geom_hline(data = mean_length_df %>% 
               group_by(abn_threshold, length_type) %>%
               summarise(overall_mean = mean(mean_duration, na.rm = TRUE)), 
             mapping = aes(yintercept = overall_mean, 
                           linetype = "Mean across sites",
                           color = as_factor(abn_threshold)),
             show.legend = TRUE, #color = "black",
             size = 0.75
             ) + 
  scale_linetype_manual(values = c("Mean across sites" = "dashed")) + 
  guides(
    fill = guide_legend(override.aes = list(linetype = 0)),
    # fill = "none",
    color = "none"
         ) 

# ----------------- save ---------------- #

ggsave(plot = gg_mean_length_by_threshold_old,
       filename = paste0(p_plots, run_label, "/mean_lengths_by_threshold_old", run_label, ".pdf"), 
    width = 8.5, height = 5, units = "in")

ggsave(plot = gg_mean_length_by_threshold_side + scale_fill_manual(values = viridis(n = 5)) + scale_color_manual(values = viridis(n = 5)),
       filename = paste0(p_plots, run_label, "/mean_lengths_by_threshold", run_label, ".pdf"), 
    width = 8.5, height = 5, units = "in")




# 3. Save Histograms ----

# -------------------------------------------------------------------- #
# ----------------- plot histograms ---------------- #
# -------------------------------------------------------------------- #

for (i in 1:11) {
  gg_hist <-
    ggplot(data = filter(length_distill_df, site == site_df$site[i], length > 0)) + 
    theme_classic() +
    labs(linetype = "", x = "Time abandoned (years)", 
         y = expression("Count  (10"^{6}*" pixels)"),
         color = "Mean") +
    geom_col(mapping = aes(x = length, y = freq/(10^6)), fill = "gray70") +
    facet_grid(rows = vars(length_type), scales = "free",
               labeller = labeller(length_type = c(all = "all abn. periods", #old = "new",
                                                   max = "max. length per pixel"))) +
    # means
    geom_vline(data = filter(mean_length_df, site == site_df$site[i], 
                             !abn_threshold %in% c(3)), 
               mapping = aes(xintercept = mean_duration, 
                             color = as_factor(abn_threshold)#, linetype = "Mean (>=1)"
                             ),
               show.legend = TRUE, size = 1, linetype = "dashed") + 

    scale_color_manual(values = viridis(n = 4), #c("5" = "#C51B7D", "1" = "#F1B6DA"),
                       labels = c("5" = "Mean (\u2265 5)", "1" = "Mean (\u2265 1)",
                                  "7" = "Mean (\u2265 7)", "10" = "Mean (\u2265 10)")) +

    theme(#legend.position = c(0.85, 0.95)
      )

  # save
  png(filename = paste0(p_output, "plots/", run_label, "/length_hist_all", 
                        # "/length_hist", 
                        run_label, site_df$label[i], ".png"), 
      width = 7, height = 5, units = "in", res = 400)
  print(gg_hist)
  dev.off()
}

```

```{r vt}
# create distribution of points for violin plots, density plots, histograms, etc.

vt <- length_distill_df %>% as_tibble() %>% 
    filter(length >= 5,
           # site == "shaanxi",
           length_type == "all") %>% # to filter by length # this is important for max, since some pixels have max length of 0 
  mutate(fr = round(freq/10000, 
                    digits = 0)) %>% 
  group_by(site) %>%
  summarise(site = unique(site), 
            length = rep(length, fr),
            mean = mean(length))

# vt <- vt %>%
#   left_join(., vt %>% ungroup() %>%
#               arrange(mean) %>% select(site, mean) %>% unique() %>%
#               mutate(order = 1:n()))

# adding order based on site-level mean abandonment duration (all periods)
vt <- vt %>%
  left_join(., mean_length_df %>% 
              filter(abn_threshold == "5", length_type == "all") %>% 
              arrange(length_type, mean_duration) %>% 
              mutate(order = 1:n()) %>% select(site, order),
            by = "site")



# -------------------------------------------------------------- #
# the same as vt, but with just the maximum periods, not all periods
# -------------------------------------------------------------- #
vt_max <- length_distill_df %>% as_tibble() %>% 
    filter(length >= 5, length_type == "max") %>% # to filter by length # this is important for max, since some pixels have max length of 0 
  mutate(fr = round(freq/10000, digits = 0)) %>% 
  group_by(site) %>%
  summarise(site = unique(site), 
            length = rep(length, fr),
            mean = mean(length))

# vt_max <- vt_max %>%
#   left_join(., vt_max %>% ungroup() %>%
#               arrange(mean) %>% select(site, mean) %>% unique() %>%
#               mutate(order = 1:n()))


# adding order based on site-level mean abandonment duration (max length per pixel)

vt_max <- vt_max %>%
  left_join(., mean_length_df %>% 
              filter(abn_threshold == "5", length_type == "max") %>% 
              arrange(length_type, mean_duration) %>% 
              mutate(order = 1:n()) %>% select(site, order),
            by = "site")
```


```{r violin}

# Fancy violin plots

gg_mean_w_violin <-
  ggplot() + 
  theme_classic() +
  theme(axis.text.x = element_text(angle = 330, vjust = 1, hjust = 0),
        plot.caption = element_text(face = "italic")) +
  labs(linetype = NULL,
       color = "Mean of:", 
       y = "Mean abandonment duration (years)", 
       x = "Site") +
  geom_jitter(data = vt, 
              mapping = aes(x = fct_reorder(site, order), y = length),
              height = 0.5, width = 0.2, alpha = 0.025) +
  
  geom_violin(data = vt, 
              mapping = aes(x = fct_reorder(site, order), y = length), scale = "width", alpha = 0) +
  
  geom_point(data = mean_length_df %>%
           filter(abn_threshold == "5"),
             mapping = aes(x = fct_reorder(site, order), y = mean_duration, color = length_type),
             size = 3, alpha = 0.85) + 
  
  geom_hline(data = mean_length_df %>% 
               group_by(abn_threshold, length_type) %>%
               summarise(overall_mean = mean(mean_duration, na.rm = TRUE)) %>% 
               filter(abn_threshold == "5"), 
             mapping = aes(yintercept = overall_mean, 
                           col = length_type, 
                           linetype = "Mean \nAcross \nSites")) + 
  
  scale_linetype_manual(values = c("Mean \nAcross \nSites" = "dashed")) + 
  scale_color_discrete(labels = c(all = "All periods", 
                                   max = "Max. length \nper pixel")) +
  scale_x_discrete(breaks = site_df$site,
                   labels = site_df$description) +
  guides(color = guide_legend(order = 1)) + 
  scale_y_continuous(breaks = c(5, 10, 15, 20, 25, 30))


ggsave(plot = gg_mean_w_violin,
       filename = paste0(p_plots, run_label, "/mean_lengths_w_violin", run_label, ".pdf"), 
    width = 6, height = 5, units = "in")



```

```{r fig2-ridges}
vt

show_col(hue_pal()(3)[1]) # default ggplot colors

ggplot() + 
  geom_density_ridges2(
    data = vt, 
    mapping = aes(y = as.numeric(fct_reorder(site, desc(order))), 
                  x = length, group = site),
    stat = "binline", bins = 26,
    scale = 0.95,
    panel_scaling = FALSE) + 
  scale_y_continuous(breaks = 1:length(fig2_labels1),
                     labels = NULL,
                     sec.axis = sec_axis(~.,
                                         breaks = 1:length(fig2_labels1),
                                         labels = fig2_labels1)) + 
  labs(y = "Proportion")

# gg_mean_length_ridges <-
  ggplot() +
  
  geom_density_ridges2(
    data = vt, 
    mapping = aes(y = fct_reorder(site, desc(order)), 
                  x = length, group = site),
    stat = "binline", bins = 26, 
    scale = 0.95) + 
  
  geom_vline(data = mean_length_df %>% 
               group_by(abn_threshold, length_type) %>%
               summarise(overall_mean = mean(mean_duration, na.rm = TRUE)) %>% 
               filter(abn_threshold == "5", length_type == "all"),
             mapping = aes(xintercept = overall_mean, 
                           # col = length_type, 
                           linetype = "Mean across all sites"),
             color = hue_pal()(3)[1]) + 
  scale_linetype_manual(values = c("Mean across all sites" = "dashed")) +
  
  geom_point(data = mean_length_df %>%
           filter(abn_threshold == "5", length_type == "all"),
             mapping = aes(y = fct_reorder(site, desc(order)),
                           x = mean_duration, 
                           color = length_type),
             size = 3, alpha = 0.85) + 
  scale_color_discrete(labels = c(all = "Site-level mean",
                                   max = "Maximum duration\nper pixel")) +
  scale_y_discrete(expand = c(0.02, 0),
                   labels = c("belarus" = "Vitebsk, Belarus /\nSmolensk, Russia",
                              "bosnia_herzegovina" = "Bosnia &\nHerzegovina",
                              "chongqing" = "Chongqing, China",
                              "goias" = "Goi치s, Brazil",
                              "iraq" = "Iraq",
                              "mato_grosso" = "Mato Grosso,\nBrazil",
                              "nebraska" = "Nebraska /\nWyoming, USA",
                              "orenburg" = "Orenburg, Russia /\nUralsk, Kazakhstan",
                              "shaanxi" = "Shaanxi/Shanxi,\nChina",
                              "volgograd" = "Volgograd, Russia",
                              "wisconsin" = "Wisconsin, USA"),
                   position = "right"#, breaks = c(0, 0.1)
                   ) +
  
  scale_x_continuous(breaks = c(5, 10, 15, 20, 25, 30), expand = c(0, 0)) + 
  theme_classic() +
  labs(
    y = NULL,
    #y = "Proportion", # of abandonment periods of a given duration",
       x = "Abandonment duration (years)",
       color = NULL, linetype = NULL) + 
  theme(legend.position = "bottom", #c(0,0.3), #
        legend.margin=margin(),
        axis.text.y = element_text(vjust = 0, size=8
                                   ),
        panel.grid.major.x = element_line()) + 
  guides(color = guide_legend(order = 1, nrow = 1, override.aes = list(linetype = 0)), 
         linetype = guide_legend(order = 2, nrow = 1#, label.vjust = 0
                                 )) + 
  coord_cartesian(clip = "off")


# gg_mean_length_ridges

# save plot
ggsave(plot = 
         gg_mean_length_ridges + 
         theme(legend.spacing.x = unit(0.5, "mm"),
               legend.position = c(0.36, -0.13), legend.direction = "horizontal",
               legend.box = "horizontal",
               plot.margin = margin(5, 5, 27, 5),
               legend.box.just = "left",
               legend.text.align = 0,
               legend.title.align = 1)
         ,
       
       filename = paste0(p_plots, "/fig2_left.pdf"), 
    width = 3.42, height = 5, units = "in")
```

```{r switch}
# make labels
fig2_labels1 <- levels(fct_reorder(vt$site, desc(vt$order)))
fig2_labels_order <- sapply(1:11, function(i) {grep(fig2_labels1[i], site_df$site)})
fig2_labels_long <- c("belarus" = "Vitebsk, Belarus /\nSmolensk, Russia",
                  "bosnia_herzegovina" = "Bosnia &\nHerzegovina",
                  "chongqing" = "Chongqing, China",
                  "goias" = "Goi치s, Brazil",
                  "iraq" = "Iraq",
                  "mato_grosso" = "Mato Grosso,\nBrazil",
                  "nebraska" = "Nebraska /\nWyoming, USA",
                  "orenburg" = "Orenburg, Russia /\nUralsk, Kazakhstan",
                  "shaanxi" = "Shaanxi/Shanxi,\nChina",
                  "volgograd" = "Volgograd, Russia",
                  "wisconsin" = "Wisconsin, USA")


gg_mean_length_ridges_switch <-
  ggplot() +
  
  geom_density_ridges2(
    data = vt, 
    mapping = aes(y = as.numeric(fct_reorder(site, desc(order))), 
                  x = length, group = site),
    stat = "binline", bins = 26, 
    scale = 0.95) + 
  
  scale_y_continuous(expand = c(0.02, 0),
                     breaks = 1:length(fig2_labels1),
                     labels = NULL,
                     position = "left",
                     sec.axis = 
                       sec_axis(~.,
                                breaks = 1:length(fig2_labels1),
                                labels = fig2_labels_long[fig2_labels_order]
                                         )) + 
  
  geom_vline(data = mean_length_df %>%
               group_by(abn_threshold, length_type) %>%
               summarise(overall_mean = mean(mean_duration, na.rm = TRUE)) %>%
               filter(abn_threshold == "5", length_type == "all"),
             mapping = aes(xintercept = overall_mean,
                           linetype = "Mean across all sites"),
             color = hue_pal()(3)[1]) +
  
  scale_linetype_manual(values = c("Mean across all sites" = "dashed")) +
  
  geom_point(data = mean_length_df %>%
           filter(abn_threshold == "5", length_type == "all"),
             mapping = aes(y = as.numeric(fct_reorder(site, desc(order))),
                           x = mean_duration, 
                           color = length_type),
             size = 3, alpha = 0.85) + 
  scale_color_discrete(labels = c(all = "Site-level mean",
                                  max = "Maximum duration\nper pixel")) +
  
  scale_x_continuous(breaks = c(5, 10, 15, 20, 25, 30), expand = c(0, 0)) +
  theme_classic() +
  labs(y = "Proportion",
       x = "Abandonment duration (years)",
       color = NULL, linetype = NULL) + 
  theme(legend.position = "bottom", #c(0,0.3), #
        legend.margin=margin(),
        axis.text.y = element_text(vjust = 0, size=8
                                   ),
        panel.grid.major.x = element_line()) + 
  guides(color = guide_legend(order = 1, nrow = 1, 
                              override.aes = list(linetype = 0)), 
         linetype = guide_legend(order = 2, nrow = 1)) + 
  coord_cartesian(clip = "off")



# save plot
ggsave(plot = 
         gg_mean_length_ridges_switch + 
         theme(legend.spacing.x = unit(0.5, "mm"),
               legend.position = c(0.6, -0.13), 
               legend.direction = "horizontal",
               legend.box = "horizontal",
               plot.margin = margin(5, 5, 27, 5),
               legend.box.just = "left",
               legend.text.align = 0,
               legend.title.align = 1),
       
       filename = paste0(p_plots, "/fig2_right.pdf"), 
    width = 3.42, height = 5, units = "in")
```


```{r fig2-ridges-w-max}

vt_max

fig2_max_labels1 <- levels(fct_reorder(vt_max$site, desc(vt_max$order)))
fig2_max_labels_order <- sapply(1:11, function(i) {grep(fig2_max_labels1[i], site_df$site)})
fig2_max_labels_long <- c("belarus" = "Vitebsk, Belarus /\nSmolensk, Russia",
                  "bosnia_herzegovina" = "Bosnia &\nHerzegovina",
                  "chongqing" = "Chongqing, China",
                  "goias" = "Goi치s, Brazil",
                  "iraq" = "Iraq",
                  "mato_grosso" = "Mato Grosso,\nBrazil",
                  "nebraska" = "Nebraska /\nWyoming, USA",
                  "orenburg" = "Orenburg, Russia /\nUralsk, Kazakhstan",
                  "shaanxi" = "Shaanxi/Shanxi,\nChina",
                  "volgograd" = "Volgograd, Russia",
                  "wisconsin" = "Wisconsin, USA")

gg_mean_length_ridges_w_max <-
  ggplot() +
  
  geom_density_ridges2(
    data = vt_max, 
    mapping = aes(y = as.numeric(fct_reorder(site, desc(order))), 
                  x = length, group = site),
    stat = "binline", bins = 26, 
    scale = 0.95) + 
  
  scale_y_continuous(expand = c(0.02, 0),
                     breaks = 1:length(fig2_max_labels1),
                     labels = NULL,
                     position = "left",
                     sec.axis = 
                       sec_axis(~.,
                                breaks = 1:length(fig2_max_labels1),
                                labels = fig2_max_labels_long[fig2_max_labels_order]
                                         )) +
  
  # scale_y_discrete(expand = c(0.02, 0),
  #                  labels = c("belarus" = "Vitebsk, Belarus /\nSmolensk, Russia",
  #                             "bosnia_herzegovina" = "Bosnia &\n Herzegovina",
  #                             "chongqing" = "Chongqing, China",
  #                             "goias" = "Goi치s, Brazil",
  #                             "iraq" = "Iraq",
  #                             "mato_grosso" = "Mato Grosso,\nBrazil",
  #                             "nebraska" = "Nebraska /\nWyoming, USA",
  #                             "orenburg" = "Orenburg, Russia /\nUralsk, Kazakhstan",
  #                             "shaanxi" = "Shaanxi/Shanxi,\nChina",
  #                             "volgograd" = "Volgograd, Russia",
  #                             "wisconsin" = "Wisconsin, USA")) +
  
  geom_vline(data = mean_length_df %>% 
               group_by(abn_threshold, length_type) %>%
               summarise(overall_mean = mean(mean_duration, na.rm = TRUE)) %>% 
               filter(abn_threshold == "5"),
             mapping = aes(xintercept = overall_mean, 
                           col = length_type, 
                           linetype = "Mean\nacross\nall sites")) + 
  scale_linetype_manual(values = c("Mean\nacross\nall sites" = "dashed")) +
  
  geom_point(data = mean_length_df %>%
           filter(abn_threshold == "5"),
             mapping = aes(y = as.numeric(fct_reorder(site, desc(order))),
                           x = mean_duration, 
                           color = length_type),
             size = 3, alpha = 0.85) + 
  scale_color_discrete(labels = c(all = "All abandonment periods",
                                   max = "Maximum duration\nper pixel")) +
    
  scale_x_continuous(breaks = c(5, 10, 15, 20, 25, 30), expand = c(0, 0)) + 
  theme_classic() +
  labs(y = "Proportion", 
       x = "Abandonment duration (years)",
       color = "Site-level \nmean of:", linetype = NULL) + 
  theme(legend.position = "bottom", #c(0,0.3), #
        legend.margin=margin(),
        axis.text.y = element_text(vjust = 0, size=8
                                   ),
        panel.grid.major.x = element_line()) + 
  guides(color = guide_legend(order = 1, nrow = 2, 
                              override.aes = list(linetype = 0)), 
         linetype = guide_legend(order = 2, label.vjust = 0)) + 
  coord_cartesian(clip = "off")


# gg_mean_length_ridges_w_max

# save plot
ggsave(plot = gg_mean_length_ridges_w_max + 
         theme(legend.spacing.x = unit(0.5, "mm"),
               legend.position = c(0.7, -0.17), legend.direction = "horizontal", 
               legend.box = "horizontal",
               plot.margin = margin(5, 5, 45, 5),
               legend.box.just = "left",
               legend.text.align = 0, 
               legend.title.align = 1),
       filename = paste0(p_plots, "/fig2_w_max_right.pdf"), 
    width = 3.42, height = 5, units = "in")

```


```{r histograms}
# gg_raw_hist <-
  ggplot(data = length_distill_df %>% 
           filter(#site == site_df$site[9], 
             length_type == "all",
             length >= 5) %>%
           left_join(., vt %>% select(site, order) %>% unique(), by = "site")) + 
    theme_classic() +
    xlab("Time abandoned (years)") + ylab(expression("Count  (10"^{6}*" pixels)")) +
    geom_col(mapping = aes(x = length, y = freq/(10^6))) +
    facet_grid(rows = vars(fct_reorder(site, order)), scales = "free") +
    
    theme(#legend.position = c(0.85, 0.95)
          ) + 
  scale_x_continuous(breaks = seq(from = 5, to = 30, by = 5))

ggsave(plot = gg_raw_hist, 
       filename = paste0(p_plots, run_label, "/mean_lengths_default_hist", run_label, ".pdf"), 
    width = 5, height = 8, units = "in")




fig2_labels1 <- levels(fct_reorder(vt$site, desc(vt$order)))


ggplot() + 
  geom_density_ridges2(
    data = vt, 
    mapping = aes(y = as.numeric(fct_reorder(site, desc(order))), 
                  x = length, group = site),
    stat = "binline", bins = 26,
    scale = 0.95,
    panel_scaling = FALSE) + 
  scale_y_continuous(breaks = 1:length(fig2_labels1),
                     labels = NULL,
                     sec.axis = sec_axis(~.,
                                         breaks = 1:length(fig2_labels1),
                                         labels = fig2_labels1)) + 
  labs(y = "Proportion")

# testing the density plots
ggplot() +
  geom_density_ridges2(
    data = vt, 
    mapping = aes(y = fct_reorder(site, desc(order)), x = length, group = site),
    stat = "binline", bins = 26,
    scale = 0.95,
    panel_scaling = FALSE) + 
  scale_y_discrete(position = "left"#, breaks = c(0, 0.1)
                   ) + 
  labs(y = "Proportion") +
  theme(axis.text.y = element_text(size=10,face="bold"))# + 
  scale_y_continuous(breaks = c(0, 0.1), labels = c("0", "0.1"))
  

vt %>% select(site, order) %>% unique()


ggplot(data = length_distill_df %>% 
           filter(length_type == "all", length >= 5) %>%
           left_join(., vt %>% select(site, order) %>% unique(), by = "site") %>%
         left_join(., length_distill_df %>% 
                     filter(length_type == "all", length >= 5) %>% 
                     group_by(site) %>% summarise(sum = sum(freq)),
                   by = "site")) + 
    theme_classic() +
    labs(x = "Time abandoned (years)", y = "Proportion of total") + 
    geom_col(mapping = aes(x = length, y = freq/sum)) +
    facet_grid(rows = vars(fct_reorder(site, order)), scales = "free_x") +
  scale_x_continuous(breaks = seq(from = 5, to = 30, by = 5)) + 
  scale_y_continuous(breaks = c(0, 0.1))


irislabs1 <- levels(iris$Species)
irislabs2 <- c("foo", "bar", "buzz")

ggplot(iris, aes(Sepal.Length, as.numeric(Species))) +
  geom_point() +
  scale_y_continuous(breaks = 1:length(irislabs1),
                     labels = irislabs1,
                     sec.axis = sec_axis(~.,
                                         breaks = 1:length(irislabs2),
                                         labels = irislabs2))
```


```{r histograms-testing}
# 
font_size <- 14
font_family <- ""
line_size <- .5
# grid <- TRUE
if (TRUE) {
    panel.grid.major <- element_line(colour = color, size = line_size)
    axis.ticks       <- element_line(colour = color, size = line_size)
    axis.ticks.y     <- axis.ticks
  }  else {
    panel.grid.major <- element_blank()
    axis.ticks       <- element_line(colour = "black", size = line_size)
    axis.ticks.y     <- element_blank()
  }

center_axis_labels <- FALSE
if (center_axis_labels) {
    axis_just <- 0.5
    } else {
    axis_just <- 1.0
  }

  half_line <- font_size / 2
  small_rel <- 0.857
  small_size <- small_rel * font_size
  color <- "grey90"
# 


ggplot(data = length_distill_df %>% 
           filter(length_type == "all", length >= 5) %>%
           left_join(., vt %>% select(site, order) %>% unique(), by = "site") %>%
         left_join(., length_distill_df %>% 
                     filter(length_type == "all", length >= 5) %>% 
                     group_by(site) %>% summarise(sum = sum(freq)),
                   by = "site")) + 
    theme_classic() +
    labs(x = "Time abandoned (years)", y = "Proportion of total") + 
    geom_col(mapping = aes(x = length, y = freq/sum)) +
    facet_grid(rows = vars(fct_reorder(site, order)), scales = "free_x") +
  scale_x_continuous(breaks = seq(from = 5, to = 30, by = 5)) + 
theme_grey(base_size = font_size, base_family = font_family) %+replace%
    theme(
      rect              = element_rect(fill = "transparent", colour = NA, color = NA, size = 0, linetype = 0),
      text              = element_text(family = font_family, face = "plain", colour = "black",
                                       size = font_size, hjust = 0.5, vjust = 0.5, angle = 0, lineheight = .9,
                                       margin = margin(), debug = FALSE),
      axis.text         = element_text(colour = "black", size = small_size),
      #axis.title        = element_text(face = "bold"),
      axis.text.x       = element_text(margin = margin(t = small_size / 4), vjust = 1),
      axis.text.y       = element_text(margin = margin(r = small_size / 4), hjust = 1, vjust = 0),
      axis.title.x      = element_text(
        margin = margin(t = small_size / 2, b = small_size / 4),
        hjust = axis_just
      ),
      axis.title.y      = element_text(
        angle = 90,
        margin = margin(r = small_size / 2, l = small_size / 4),
        hjust = axis_just
      ),
      axis.ticks        = axis.ticks,
      axis.ticks.y      = axis.ticks.y,
      axis.line         = element_blank(),
      legend.key        = element_blank(),
      legend.key.size   = grid::unit(1, "lines"),
      legend.text       = element_text(size = rel(small_rel)),
      legend.justification = c("left", "center"),
      panel.background  = element_blank(),
      panel.border      = element_blank(),
      # make grid lines
      panel.grid.major  = panel.grid.major,
      panel.grid.minor  = element_blank(),
      strip.text        = element_text(size = rel(small_rel)),
      strip.background  = element_rect(fill = "grey80", colour = "grey50", size = 0),
      plot.background   = element_blank(),
      plot.title        = element_text(face = "bold",
                                       size = font_size,
                                       margin = margin(b = half_line), hjust = 0),
      plot.subtitle     = element_text(size = rel(small_rel),
                                       hjust = 0, vjust = 1,
                                       margin = margin(b = half_line * small_rel)),
      plot.caption      = element_text(size = rel(small_rel),
                                       hjust = 1, vjust = 1,
                                       margin = margin(t = half_line * small_rel)),
      plot.margin       = margin(half_line, font_size, half_line, half_line),
      complete = TRUE
    )


length_distill_df %>% filter(length_type == "all", length >= 5) %>% group_by(site) %>% summarise(sum = sum(freq))
```




# Area abandoned

## Area abandoned at some point during the time series

```{r total-possible-cropland}

# ------------------------------------------------------ #
# trying this for all rasters:
# ------------------------------------------------------ #
# terraOptions(todisk = TRUE)
terraOptions()

# prepared input rasters (derived by Chris)
site_input_raster_files <- list.files(paste0(p_dat_derived, "input_rasters"), full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = TRUE)

lct <- lapply(seq_along(site_input_raster_files), function(i) {rast(site_input_raster_files[i])})
names(lct) <- site_df$site

# rename raster layers:
for (i in 1:11) {
  if (names(lct[i]) == "nebraska") {
    names(lct[[i]]) <- paste0("y", 1986:2018)
  } else {
    if (names(lct[i]) == "wisconsin") {
      names(lct[[i]]) <- paste0("y", 1987:2018)
    } else {
      # everything else, just 1987:2017
      names(lct[[i]]) <- paste0("y", 1987:2017)
    }}}


tic()
lc_total_crop_mask <- lapply(1:11, function(i) {
  reclassified <- classify(lct[[i]], rcl = tribble(
  ~"is", ~"becomes", 
  0, NA,
  1, NA,
  2, NA,
  3, 1,
  4, NA))
  
  lc_crop_mask <- max(reclassified, na.rm = TRUE)
  rm(reclassified)
  
  # write new total_crop_mask raster to file:

  terra::writeRaster(lc_crop_mask,
              filename = paste0(p_dat_derived, "total_crop_mask/", 
                                site_df$site[i], "_total_crop_mask.tif"),
              overwrite = TRUE
              )

  lc_crop_mask
})
toc()
# 2033 seconds

names(lc_total_crop_mask) <- site_df$site

```

```{r area-reprex}
library(reprex)
library(raster)
library(terra)

# make test raster with raster::raster()
a <- raster::raster(ncols = 100, nrows = 100,
            xmn = -84, xmx = -83, 
            ymn = 42, ymx = 43)

# make test raster with terra::rast()
b <- terra::rast(ncols = 100, nrows = 100, 
          xmin = -84, xmax = -83, 
          ymin = 42, ymax = 43)

# give them some values
# values(a) <- 1:ncell(a)
# values(b) <- 1:ncell(b)

# calculate cell areas (km2)
a_area <- raster::area(a) # km by default
b_area <- terra::cellSize(b, unit = "km")

# sum across cells
a_sum <- raster::cellStats(a_area, "sum")
b_sum <- terra::global(b_area, fun = "sum")

a_sum
b_sum

# note that this terra workflow yields the same answer as terra::expanse()
terra::expanse(b, unit = "km")


sessionInfo()
packageVersion("raster")
packageVersion("terra")



# Note: I know that terra::expanse() accomplishes the same thing as cellSize() coupled with global(fun = "sum"), and is substantially faster... but expanse() has repeatedly caused RStudio to crash when attempting to use with large rasters (20M to 100M cells).


reprex(venue = "so")


```


```{r area-abn-summary}

# 1. Calculate area abandoned summary stats:
# ----------------------------------------------------------- #
area_summary_df <- 
  area_dat %>% 
  filter(lc %in% c("Non-veg.", "Woody veg.", "Cropland", "Grassland"),
         year == 2017) %>%
  group_by(site) %>%
  summarise(total_site_area_ha_2017 = sum(area_ha)) %>% 
  left_join(., 
            left_join(filter(area_dat, lc == "Cropland", year == 1987) %>% 
                        select(site, cropland_area_1987 = area_ha), 
                      filter(area_dat, lc == "Abandoned (>=5)", year == 2017) %>% 
                        select(site, area_abn_ha_2017 = area_ha),
                      by = c("site")), 
            by = c("site"))


# ----------------------------------------------------------- #
# 2. Calculate the area at each site that is abandoned at any point during the time series (>= 5 years)
# ----------------------------------------------------------- #
# load max age rasters
max_age_files <- list.files(paste0(p_dat_derived, "max_age/", run_label), 
                        full.names = TRUE) %>%
  grep(".tif", ., value = TRUE)

max_age_r <- lapply(seq_along(max_age_files), function(i) {
  rast(max_age_files[i]) # brick(max_age_files[i]) # to load as rasters, not SpatRasters
  })
names(max_age_r) <- site_df$site

tic()
area_ever_abn <- lapply(1:11, function(i) {
  max_age_mask <- max_age_r[[i]] %>%
    classify(., 
             rcl = tibble("is" = 0:31, 
                          becomes = if_else(is >= 5, 1, NA_real_)))
  
  area_ha <- cellSize(max_age_mask, unit = "ha", mask = TRUE) %>%
    global(., fun = "sum", na.rm = TRUE)
  
  tibble(site = site_df$site[i],
         area_ever_abn_ha = as.numeric(area_ha))
} 
) %>% bind_rows()
toc() # 75.81 sec

area_ever_abn
area_ever_abn %>% summarise(total_ever_abn_Mha = sum(area_ever_abn_ha)/1e6)


# ----------------------------------------------------------- #
# 3. Total extent of all cropland ever cultivated during time series
# ----------------------------------------------------------- #

total_crop_mask_files <- list.files(paste0(p_dat_derived, "total_crop_mask"), full.names = TRUE)
lc_total_crop_mask <- lapply(
  seq_along(total_crop_mask_files), 
  function(i) {
    rast(total_crop_mask_files[i])
    })

names(lc_total_crop_mask) <- site_df$site

# calculate area
lc_total_crop_mask_area_ha <- sapply(1:11, function(i) {
  size <- cellSize(lc_total_crop_mask[[i]], unit = "ha", mask = TRUE)
  # product <- size * lc_total_crop_mask[[i]]
  area_ha <- global(size, fun = "sum", na.rm = TRUE)
  
  as.numeric(area_ha)
  })


total_crop_mask_area <- tibble(site = site_df$site,
       total_crop_extent_ha = lc_total_crop_mask_area_ha
       )

total_crop_mask_area


# ---------------------------------------------------------------------- #
# 4. What percentage of the abandonment periods are recultivated?
# ---------------------------------------------------------------------- #

persistence_dat %>% filter(site == "shaanxi", year == 2017)
# sum up the initial_area_abn to find the total area ever abandoned, then
# sum up the area_ha in 2017 (the last year of the time series). 
# Divide the two and subtract from 1, we have the proportion of initial area abandoned that 
# was recultivated during the time series. 

area_recultivated_df <- 
  persistence_dat %>% 
  filter(year == 2017) %>%
  group_by(site) %>%
  summarise(total_area_abn_remaining_2017 = sum(area_ha),
            total_initial_area_abn = sum(initial_area_abn),
            total_area_abn_recultivated_2017 = 
              total_initial_area_abn - 
              total_area_abn_remaining_2017) %>%
  mutate(proportion_recultivated = total_area_abn_recultivated_2017/total_initial_area_abn)


# ----------------------------------------------------------- #
# Proportion of each site's area in non-vegetated land
# ----------------------------------------------------------- #
area_dat %>% 
  filter(lc %in% c("Non-veg.", "Woody veg.", "Cropland", "Grassland"), year == 2017) %>%
  group_by(site) %>%
  summarise(total_site_area_ha = sum(area_ha)) %>% 
  left_join(area_dat, ., by = c("site")) %>% 
  mutate(prop_total_area = area_ha/total_site_area_ha) %>%
  group_by(site, lc) %>%
  summarise(max_prop_in_non_veg = max(prop_total_area)) %>%
  arrange(max_prop_in_non_veg) %>%
  
# plot
  filter(., lc == "Non-veg.") # %>%
  ggplot(data = .) +
    theme_classic() +
    labs(y = expression("Area  (10"^{6}*" ha)"), x = "Year", 
         title = "Area by Land Cover, with Abandonment",
         color = NULL) + 
    geom_line(mapping = aes(x = year, y = prop_total_area, #area_ha / (10^6), # convert to millions of ha
                            group = lc, color = fct_reorder(lc, lc, .desc = TRUE)),
              size = 1.5) + 
    theme(legend.position = "bottom",
          legend.title = element_text(size = 10)) +
    guides(color = guide_legend(nrow = 2, ncol = 3)) +
    
    scale_color_manual(values = plot_cols) + 
  facet_wrap(vars(site))

# ----------------------------------------------------------- #
# merge all together
# ----------------------------------------------------------- #

area_summary_df <- area_summary_df %>% 
  left_join(., area_ever_abn, by = c("site")) %>%
  left_join(., total_crop_mask_area, by = c("site")) %>%
  left_join(., area_recultivated_df, by = c("site"))


# calculate area as various proportions
names(area_summary_df)
area_summary_df <- area_summary_df %>%
  mutate(area_2017_as_prop_site = area_abn_ha_2017/total_site_area_ha_2017,
         area_2017_as_prop_total_crop = area_abn_ha_2017/total_crop_extent_ha,
         area_2017_as_prop_crop87 = area_abn_ha_2017/cropland_area_1987,
         area_ever_abn_as_prop_site = area_ever_abn_ha/total_site_area_ha_2017,
         area_ever_abn_as_prop_total_crop = area_ever_abn_ha/total_crop_extent_ha,
         area_ever_abn_as_prop_crop87 = area_ever_abn_ha/cropland_area_1987)

# ----------------------------------------------------------- #
# save the summary file
# ----------------------------------------------------------- #
write_csv(area_summary_df, file = paste0(p_dat_derived, run_label, "/", "area_summary_df", run_label, ".csv"))
# area_summary_df <- read_csv(file = paste0(p_dat_derived, run_label, "/", "area_summary_df", run_label, ".csv"))

# area_summary_df_old_area <- read_csv(file = paste0(p_dat_derived, run_label, "_old_area", "/", "area_summary_df", run_label, ".csv"))
```




## How much area is abandoned, total?

```{r area-lc-facet-grid}
# load combined persistence, area, and turnover datasets:
persistence_dat
area_dat
turnover_dat

area_dat$lc %>% unique()
# ---------------------------------------------------------------------- #
# plot facet grid
# ---------------------------------------------------------------------- #
area_dat$lc %>% unique %>% sort()

area_dat %>% mutate(lc = as_factor(lc)) 

area_dat$lc %>% unique %>% sort()
area_dat %>% filter(lc != "Abandoned (>1)") %>% mutate(lc = as_factor(lc)) %>% .$lc
  
gg_area_lc_facet_grid <-
  ggplot(data = area_dat %>% filter(lc != "Abandoned (>1)")) +
  theme_classic() +
  # theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  labs(y = expression("Area  (10"^{6}*" ha)") , 
       x = "Year", 
       color = NULL) + 
  geom_line(mapping = aes(x = year, y = area_ha / (10^6), # convert to millions of ha
                          group = lc, color = fct_reorder(lc, lc)),
            size = 1.5) + 
  theme(legend.position = c(0.9, 0.12),
        legend.title = element_text(size = 10)) +
  scale_color_manual(values = plot_cols[-2]) +
  
  guides(color = guide_legend(nrow = 5, ncol = 1)) +

  facet_wrap(vars(site),
             labeller = as_labeller(cap_update_labels),
             scales = "free")



ggsave(plot = gg_area_lc_facet_grid,
       filename = paste0(p_plots, run_label, "/area_by_lc_grid", run_label, ".pdf"), 
    width = 7, height = 5, units = "in"
)
```




```{r area-abn-as-prop-cropland}
# what proportion of cropland five years ago is abandoned each year?
area_dat %>% 
  filter(lc == "Abandoned (>=5)", year == 2017)


# I need the gain in abandoned land, in order to determine the newly abandoned area as a proportion of the amount of cropland five years before
the_year <- 2012

left_join(
  turnover_dat %>% 
    filter(site == "shaanxi", change == "gain") %>% 
    select(site, year, abn_area_ha = area_ha), #, year == the_year)
  
  area_dat %>% 
    filter(site == "shaanxi", lc == "Cropland") %>%
    mutate(year = year + 5) %>% 
    select(site, cropland_area_5_yr_prior = area_ha, year),
  
  by = c("site", "year"))



left_join(
  filter(area_dat, lc == "Abandoned (>=5)", year == 2017) %>%
    select(site, year, area_abn = area_ha),
  filter(area_dat, lc == "Cropland", year == 2017 - 5) %>%
    select(site, cropland_5_yr_before = area_ha),
  by = c("site"))
  
  
  select()


# plot area abandoned as a proportion of the amount of cropland at the start of the time series:
ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(area_abn_ha_2017/cropland_area_1987)), 
                     x = area_abn_ha_2017/cropland_area_1987)) + 
  geom_col() +
  theme_classic() + 
  labs(x = "Proportion of cropland in 1987 that is abandoned", y = "Site")



```


```{r total-area-panel}
# how much land is abandoned by the end of the time series?
area_dat %>% 
  filter(lc == "Abandoned (>=5)",
         year == 2017) %>%
  ggplot(mapping = aes(y = site, x = area_ha/(10^6))) + 
  geom_col()


# plot the area abandoned in 2017:
ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(area_abn_ha_2017)), 
                     x = area_abn_ha_2017/(10^6))) + 
  geom_col() +
  theme_classic() + 
  labs(x = "Area Abandoned (millions ha)", y = "Site")


# plot area abandoned as a proportion of the total site area:
ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(area_abn_ha_2017/total_site_area_ha_2017)),
                     x = area_abn_ha_2017/total_site_area_ha_2017)) + 
  geom_col() +
  theme_classic() + 
  labs(x = "Proportion of total site area abandoned", y = "Site")


# plot area abandoned as a proportion of the amount of cropland at the start of the time series:
ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(area_abn_ha_2017/cropland_area_1987)), 
                     x = area_abn_ha_2017/cropland_area_1987)) + 
  geom_col() +
  theme_classic() + 
  labs(x = "Proportion of cropland in 1987 that is abandoned", y = "Site")



# panel plot

area_a <-
  ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(area_as_prop_total_crop)), 
                     x = area_abn_ha_2017/(10^3))) + 
  geom_col() +
  theme_classic() + 
  labs(#x = expression("Area abandoned ">="5 years \nas of 2017 (10"^{3}*" ha)"),
    x = "Area abandoned as of 2017\n(10\u00b3 ha)",
       y = "Site") + 
  scale_y_discrete(expand = c(0.02, 0),
                   labels = c("belarus" = "Vitebsk, Belarus /\nSmolensk, Russia",
                              "bosnia_herzegovina" = "Bosnia &\n Herzegovina",
                              "chongqing" = "Chongqing, China",
                              "goias" = "Goi치s, Brazil",
                              "iraq" = "Iraq",
                              "mato_grosso" = "Mato Grosso,\nBrazil",
                              "nebraska" = "Nebraska /\nWyoming, USA",
                              "orenburg" = "Orenburg, Russia /\nUralsk, Kazakhstan",
                              "shaanxi" = "Shaanxi/Shanxi,\nChina",
                              "volgograd" = "Volgograd, Russia",
                              "wisconsin" = "Wisconsin, USA"))

# plot area abandoned at any point between 1987-2017 (thousands ha):
area_b <-
  ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(area_as_prop_total_crop)), 
                     x = area_ever_abn_ha/(10^3))) + 
  geom_col() +
  theme_classic() + 
  labs(x = "Area abandoned at any point \nbetween 1987-2017 (10\u00b3 ha)", y = "Site") + 
  theme(axis.text.y = element_blank(), axis.title.y = element_blank(),
        plot.margin = margin(3, 8, 3, 15))

# plot area abandoned as a proportion of the total cropland extent:
area_c <- ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(area_as_prop_total_crop)),
                     x = area_as_prop_total_crop)) + 
  geom_col() +
  theme_classic() + 
  labs(x = "Area abandoned as of 2017 \n as a proportion of \ntotal cropland extent", y = "Site") + 
  theme(axis.text.y = element_blank(), axis.title.y = element_blank(),
        plot.margin = margin(3, 6, 3, 15))


# plot area abandoned as a proportion of the amount of cropland at the start of the time series:
area_d <-
  ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(area_as_prop_total_crop)), 
                     x = area_ever_abn_ha/1e3)) + 
  geom_col() +
  theme_classic() + 
  labs(x = "Area abandoned at any point\nbetween 1987-2017 (10\u00b3 ha)", y = "Site") + 
  theme(axis.text.y = element_blank(), axis.title.y = element_blank(),
        plot.margin = margin(3, 6, 3, 15))




# save panel plot

ggsave(plot = plot_grid(area_a, area_b, area_c, area_d,
                        nrow = 1, ncol = 4, 
                        align = "h", axis = "l",
                        # hjust = 0,
                        rel_widths = c(1.5, 1, 1, 1),
                        labels = "auto"
                        ),
       filename = paste0(p_plots, run_label, "/area_abn_panel", run_label, ".pdf"), 
    width = 10, height = 4, units = "in"
)

```



# Mean proportion of abandoned land that is recultivated

```{r prop-recultivated}
# see chunk: area-abn-summary
area_recultivated_df %>% arrange(proportion_recultivated)

area_summary_df %>% names

ggplot(data = area_summary_df,
       mapping = aes(y = fct_reorder(site, desc(proportion_recultivated)), 
                     x = proportion_recultivated)) + 
  geom_col() +
  theme_classic() + 
  labs(x = "Proportion of abandoned lands \nrecultivated by 2017", y = "Site") + 
  theme(#axis.text.y = element_blank(), axis.title.y = element_blank(),
        plot.margin = margin(3, 6, 3, 15))


# averaging across site to be consistent with summary_stats_all_sites
area_summary_df %>% select(site, proportion_recultivated) %>% arrange(proportion_recultivated)

area_summary_df %>% 
  summarise(mean_proportion = mean(proportion_recultivated))


```


## how does this change by threshold?

```{r recultivation-by-threshold}
# see chunk: area-abn-summary
area_recultivated_df

area_recult_threshold <- lapply(c(5, 7, 10), function(i) {
  persistence_dat %>% 
  left_join(.,
            persistence_dat %>% filter(age == i) %>% 
              select(site, year_abn, initial_area_abn_alt_thr = area_ha), 
            by = c("site", "year_abn")) %>%
  filter(year == 2017, age >= i) %>% # this restricts to only land abandoned for at least 5, 7, or 10 years
  group_by(site) %>%
  summarise(total_area_abn_remaining_2017 = sum(area_ha),
            total_initial_area_abn = sum(initial_area_abn_alt_thr),
            total_area_abn_recultivated_2017 = 
              total_initial_area_abn - 
              total_area_abn_remaining_2017) %>%
  mutate(proportion_recultivated = total_area_abn_recultivated_2017/total_initial_area_abn,
         abn_threshold = i) 
}) %>% 
  bind_rows() %>%
  left_join(., 
            filter(., abn_threshold == 5) %>% 
              arrange(proportion_recultivated) %>% 
              mutate(order = 1:n()) %>% select(site, order)
            )




# summing up the total area abandoned as of 2017, and the total area abandoned at one point
area_summary_df %>% select(site, area_abn_ha_2017, area_ever_abn_ha) %>%
  summarise(total_area_abn_2017 = sum(area_abn_ha_2017),
            total_area_ever_abn = sum(area_ever_abn_ha)) / 10^6

# now, summing up the total cumulative area of all land remaining abandoned as of 2017.
persistence_dat %>%
  filter(year == 2017, age >= 5) %>%
  group_by(site) %>%
  summarise(total_area_abn_remaining_2017 = sum(area_ha)) %>% ungroup() %>%
  summarise(sum_across_sites = sum(total_area_abn_remaining_2017)) # ok, this matches...

area_dat %>% filter(lc == "Abandoned (>=5)", year == 2017) %>% .$area_ha %>% sum()
            
# note to future Chris: the sum of the "initial area abandoned" values is higher than the "area ever abandoned" because some pixels were abandoned multiple times, and therefore show up more than once in the intial area abandoned. 
area_recult_threshold %>% 
  group_by(abn_threshold) %>%
  # filter(abn_threshold == 5) %>%
  summarise(sum_abn_2017 = sum(total_area_abn_remaining_2017) / 10^6,
            sum_init_abn = sum(total_initial_area_abn) / 10^6) 

# area_summary_df %>% select(site, proportion_recultivated) %>% arrange(proportion_recultivated)


round(area_summary_df %>% summarise(total_ever_abn_Mha = sum(area_ever_abn_ha)/1e6), digits = 2)









# ----------------------------------------------------------- #
# save the summary file
# ----------------------------------------------------------- #
write_csv(area_recult_threshold, file = paste0(p_dat_derived, run_label, "/", "area_recult_threshold", run_label, ".csv"))
# area_recult_threshold <- read_csv(file = paste0(p_dat_derived, run_label, "/", "area_recult_threshold", run_label, ".csv"))



# ----------------------------------------------------------- #
# save plot
# ----------------------------------------------------------- #

gg_recultivation <-
  ggplot(data = area_recult_threshold,
       mapping = aes(y = fct_reorder(site, desc(order)), 
                     x = proportion_recultivated,
                     group = as_factor(abn_threshold), fill = as_factor(abn_threshold))) + 
  geom_col(position = position_dodge(), width = 0.6) +
  theme_classic() + 
  labs(x = "Proportion of abandoned lands \nrecultivated by 2017", y = "Site",
       fill = "Abandonment \nthreshold") + 
  theme(#axis.text.y = element_blank(), axis.title.y = element_blank(),
        plot.margin = margin(3, 6, 3, 15),
        legend.position = "top")

ggsave(plot = gg_recultivation,
       filename = paste0(p_plots, run_label, "/recultivation_rates_by_threshold", run_label, ".pdf"), 
       width = 4.5, height = 4.5, units = "in")

```


# Proportion of abandoned land in each land cover class

See "4_lc_of_abn.R"
```{r}
abn_lc_count_2017 <- read_csv(file = paste0(p_dat_derived, run_label, "/", "abn_lc_count_2017", run_label, ".csv"))
abn_prop_lc_2017 <- read_csv(file = paste0(p_dat_derived, run_label, "/", "abn_prop_lc_2017", run_label, ".csv"))

```


# Comparing annual trajectory to two snapshots in time

```{r 2yr-abn-method}
# ---------------------------------------------------------------- #
# 1. load land cover rasters
# ---------------------------------------------------------------- #
# prepared input rasters (derived by Chris)
site_input_raster_files <- list.files(paste0(p_dat_derived, "input_rasters"), full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = TRUE)

lct <- lapply(seq_along(site_input_raster_files), function(i) {rast(site_input_raster_files[i])})
names(lct) <- site_df$site

# rename raster layers:
for (i in 1:11) {
  if (names(lct[i]) == "nebraska") {
    names(lct[[i]]) <- paste0("y", 1986:2018)
  } else {
    if (names(lct[i]) == "wisconsin") {
      names(lct[[i]]) <- paste0("y", 1987:2018)
    } else {
      # everything else, just 1987:2017
      names(lct[[i]]) <- paste0("y", 1987:2017)
    }}}


# ---------------------------------------------------------------- #
# 2-4 all together:
# ---------------------------------------------------------------- #

abn_2yr_mask <- lapply(1:11, 
                  function(i) {
  # 2. Extract only 2017 & 1987
  lct_87_17_tmp <- lct[[i]] %>% 
    subset(., c("y1987", "y2017"),
           filename = paste0(p_dat_derived, "abn_2yr/", site_df$site[i], "_87_17.tif"),
           overwrite=TRUE
           )
  
  # 3. reclassify the rasters, so that it's just cropland in 1987 (0-1), and just cropland in 2017 (0-1)
  lct_87_17_tmp <- classify(lct_87_17_tmp, 
           rcl = tribble(
             ~"is", ~"becomes", 
             NA, NA,
             0, NA,
             1, NA,
             2, 0,
             3, 1,
             4, 0),
           filename = paste0(p_dat_derived, "abn_2yr/", site_df$site[i], "_87_17_rcl.tif"),
           overwrite=TRUE)
  
  # 4. Subtract the two (1987 - 2017), so that pixels that were cropland (1) in 1987, but not in 2017 (0) (i.e. are "abandoned" by this definition) have a value of 1 - 0 = 1.
  # Pixels that are cropland in both will be 1 - 1 = 0 (as will pixels that are non cropland in both 0 - 0 = 0)
  # Pixels that are cropland in 2017 (1) but not in 1987 (0) will have a value of 0 - 1 = -1
  subtract <- lct_87_17_tmp$y1987 - lct_87_17_tmp$y2017
  
  terra::writeRaster(subtract, 
                     filename = paste0(p_dat_derived, "abn_2yr/", 
                                       site_df$site[i], "_87_17_sub.tif"),
                     overwrite=TRUE)
  
  # 5. Reclassify into 0-1 abandonment mask
  mask <- classify(subtract, rcl = 
                     tribble(
                       ~"is", ~"becomes", 
                       -1, NA_real_,
                       0, NA_real_,
                       1, 1),
                   filename = paste0(p_dat_derived, "abn_2yr/", site_df$site[i], "_abn_2yr_mask.tif"),
                   overwrite=TRUE
                   )
  mask
  }
  )

names(abn_2yr_mask) <- site_df$site
plot(abn_2yr_mask$shaanxi)

# ---------------------------------------------------------------- #
# 6. calculate the area abandoned at each site
# ---------------------------------------------------------------- #

abn_2yr_area_ha <- sapply(1:11, 
                          function(i) {
  size <- cellSize(abn_2yr_mask[[i]], unit = "ha", mask = TRUE)
  # product <- abn_2yr_mask[[i]] * size
  area_ha <- global(size, fun = "sum", na.rm = TRUE)
  as.numeric(area_ha)
  })


```


```{r abn_cc_mask}
# ---------------------------------------------------------------- #
# 5.5. Calculate new area abandoned using terra methods
# ---------------------------------------------------------------- #

# load abandonment age rasters
# abandonment age maps (produced by Chris)
age_files <- list.files(paste0(p_dat_derived, "age_rasters/", run_label), 
                        full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = FALSE)

age_t <- lapply(seq_along(age_files), function(i) {rast(age_files[i])})
names(age_t) <- site_df$site
for (i in seq_along(age_t)) {names(age_t[[i]]) <- paste0("y", 1987:2017)} # remember: these are just 1987:2017

# area in 2017
freq(age_t$shaanxi$y2017)

# make abn mask
abn_cc_2017_mask <- lapply(1:11, function(i) {
  classify(age_t[[i]]$y2017, 
           # takes way longer to change values to 0 than to NA_real_
           rcl = tibble("is" = 0:30, becomes = if_else(is < 5, NA_real_, 1)), 
           filename = paste0(p_dat_derived, "abn_cc/", site_df$site[i], "_abn_cc_2017_mask.tif"),
                   overwrite=TRUE)
           })

names(abn_cc_2017_mask) <- site_df$site
plot(abn_cc_2017_mask$shaanxi)

# calculate area abandoned in 2017
abn_cc_2017_area_ha <- sapply(1:11, 
                         function(i) {
  size <- cellSize(abn_cc_2017_mask[[i]], unit = "ha", mask = TRUE)
  # product <- size * abn_cc_mask[[i]]
  area_ha <- global(size, fun = "sum", na.rm = TRUE)
  as.numeric(area_ha)
  })

abn_cc_2017_area_ha %>% sum()/1e6

# ---------------------------------------------------------------- #
# 6. Compare to area abandoned ever, and the area abandoned in 2017
# ---------------------------------------------------------------- #

area_summary_df %>% 
  select(site, area_abn_ha_2017) %>% 
  mutate(area_ha_2017_terra = abn_cc_2017_area_ha#,
         #area_ha_2017_2yr = abn_area_2017_2yr
         ) %>%
  mutate(percent_diff = 100*(area_ha_2017_terra - area_abn_ha_2017)/area_abn_ha_2017)
```


```{r overlap}
# ---------------------------------------------------------------- #
# 7. Calculate overlap between two abandonment maps
# ---------------------------------------------------------------- #


abn_2yr_mask <- lapply(1:11, function(i) {rast(paste0(p_dat_derived, "abn_2yr/", site_df$site[i], "_abn_2yr_mask.tif"))})
names(abn_2yr_mask) <- site_df$site

abn_cc_2017_mask <- lapply(1:11, function(i) {rast(paste0(p_dat_derived, "abn_cc/", site_df$site[i], "_abn_cc_2017_mask.tif"))})
names(abn_cc_2017_mask) <- site_df$site


# Add the two abandonment maps to each other, and calculate the Jaccard Similarity
# J = intersection of A and B / union of A and B
# sum of cells that = 2 / sum of cells > 0

jaccard_similarity <- sapply(1:11, function(i) {
  # both masks are 1 for abandoned (in 2017) and NA for not abandoned.
  # adding to an NA value yields NA, so this is now the intersection, 
  # where cells where both masks show abandonment have a value of 
  # 1 + 1 = 2
  intersection <- abn_2yr_mask[[i]] + abn_cc_2017_mask[[i]]
  
  terra::writeRaster(intersection, 
                     filename = paste0(p_dat_derived, "abn_2yr_cc_intersection/", 
                                       site_df$site[i], "_abn_2yr_cc_intersection.tif"),
                     overwrite=TRUE)
  
  
  intersection_area <- intersection %>% 
    cellSize(., unit = "ha", mask = TRUE) %>% 
    global(., fun = "sum", na.rm = TRUE) %>%
    as.numeric()
  
  a_area <- abn_2yr_mask[[i]] %>% 
    cellSize(., unit = "ha", mask = TRUE) %>% 
    global(., fun = "sum", na.rm = TRUE) %>%
    as.numeric()
  
  b_area <- abn_cc_2017_mask[[i]] %>% 
    cellSize(., unit = "ha", mask = TRUE) %>% 
    global(., fun = "sum", na.rm = TRUE) %>%
    as.numeric()
  
  # add area calculation for both a and b, so you can do j =  int / (a + b - int)
  jaccard <- intersection_area / (a_area + b_area - intersection_area)
  
  as.numeric(jaccard)
})

jaccard_similarity
```


```{r check-jaccard-with-shaanxi}
# double check with shaanxi -- checks out.


# reclassify both to 0 and 1.
freq(abn_2yr_mask$shaanxi)
freq(abn_cc_2017_mask$shaanxi)

t_a <- classify(abn_cc_2017_mask[[9]], 
           # takes way longer to change values to 0 than to NA_real_
           rcl = tribble(
                       ~"is", ~"becomes", 
                       NA_real_, 0,
                       1, 1), 
           filename = paste0(p_dat_derived, "abn_2yr_cc_intersection/test/", site_df$site[9], "_abn_cc_2017_mask_01.tif"),
                   overwrite=TRUE)

t_b <- classify(abn_2yr_mask[[9]], 
           # takes way longer to change values to 0 than to NA_real_
           rcl = tribble(
                       ~"is", ~"becomes", 
                       NA_real_, 0,
                       1, 1), 
           filename = paste0(p_dat_derived, "abn_2yr_cc_intersection/test/", site_df$site[9], "_abn_2yr_mask_01.tif"),
                   overwrite=TRUE)

plot(t_b)
# add them
t_add <- t_a + t_b
plot(t_add)

t_union <- classify(t_add, 
           # takes way longer to change values to 0 than to NA_real_
           rcl = tribble(
                       ~"is", ~"becomes", 
                       0, NA_real_,
                       1, 1,
                       2, 1), 
           filename = paste0(p_dat_derived, "abn_2yr_cc_intersection/test/", site_df$site[9], "_t_union.tif"),
                   overwrite=TRUE)

t_intersection <- classify(t_add,
           # takes way longer to change values to 0 than to NA_real_
           rcl = tribble(
                       ~"is", ~"becomes", 
                       0, NA_real_,
                       1, NA_real_,
                       2, 1), 
           filename = paste0(p_dat_derived, "abn_2yr_cc_intersection/test/", site_df$site[9], "_t_intersection.tif"),
                   overwrite=TRUE)

t_union_area <- t_union %>% 
    cellSize(., unit = "ha", mask = TRUE) %>% 
    global(., fun = "sum", na.rm = TRUE) %>%
    as.numeric()

t_intersection_area <- t_intersection %>% 
    cellSize(., unit = "ha", mask = TRUE) %>% 
    global(., fun = "sum", na.rm = TRUE) %>%
    as.numeric()

t_intersection_area / t_union_area


# reclassify to 0 and 1

abn_2yr_overestimation
```


```{r 2yr-overestimation}
abn_2yr_overestimation <- 
  data.frame(site = site_df$site,
             area_ha_cc = abn_cc_2017_area_ha,
             area_2yr = abn_2yr_area_ha
             ) %>%
  mutate(percent_diff = 100 * (area_2yr - area_ha_cc) / area_ha_cc,
         jaccard = jaccard_similarity)



# ----------------------------------------------------------- #
# save the summary file
# ----------------------------------------------------------- #
write_csv(abn_2yr_overestimation, file = paste0(p_dat_derived, run_label, "/", "abn_2yr_overestimation", run_label, ".csv"))
# abn_2yr_overestimation <- read_csv(file = paste0(p_dat_derived, run_label, "/", "abn_2yr_overestimation", run_label, ".csv"))

```


```{r 2yr-overestimation-plot}
# ----------------------------------------------------------- #
# plot
# ----------------------------------------------------------- #
abn_2yr_overestimation <- 
  read_csv(file = paste0(p_dat_derived, run_label, "/", 
                         "abn_2yr_overestimation", run_label, ".csv"))



install.packages("ggforce")
library(ggforce)


ggplot(data = abn_2yr_overestimation #%>% filter(site != "mato_grosso")
       , 
       mapping = aes(x = fct_reorder(site, desc(percent_diff)), y = percent_diff)) + 
  geom_col() +
  # coord_flip() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 330, vjust = 1, hjust = 0)) +
  scale_x_discrete(labels = c("belarus" = "Vitebsk, Belarus /\n Smolensk, Russia",
                              "bosnia_herzegovina" = "Bosnia & Herzegovina",
                              "chongqing" = "Chongqing, China",
                              "goias" = "Goi치s, Brazil",
                              "iraq" = "Iraq",
                              "mato_grosso" = "Mato Grosso, Brazil",
                              "nebraska" = "Nebraska/Wyoming, USA",
                              "orenburg" = "Orenburg, Russia /\n Uralsk, Kazakhstan",
                              "shaanxi" = "Shaanxi/Shanxi, China",
                              "volgograd" = "Volgograd, Russia",
                              "wisconsin" = "Wisconsin, USA")) #+ 
  # facet_zoom(ylim = c(-35, 25))
```

```{r gt-table}
install.packages("gt")
library(gt)

abn_2yr_overestimation <- 
  read_csv(file = paste0(p_dat_derived, run_label, "/", 
                         "abn_2yr_overestimation", run_label, ".csv")) %>%  
  arrange(percent_diff) %>% 
  mutate(
    # area_ha_cc = area_ha_cc %>% round(digits = 0) %>% prettyNum(big.mark = ","),
         # area_2yr = area_2yr %>% round(digits = 0) %>% prettyNum(big.mark = ","),
         # percent_diff = percent_diff %>% round(digits = 2) %>% paste0(., "%"),
         # jaccard = jaccard %>% round(digits = 2)
         ) %>% 
  left_join(., site_df %>% select(site, description), by = "site")


abn_2yr_overestimation %>% 
  select(description, area_ha_cc, area_2yr, percent_diff, jaccard) %>%

  knitr::kable(., 
             col.names = c("Site", "Area (annual)", "Area (2017-1987)", 
                           "Percent Difference", "Jaccard Similarity"),
             align = "lrrrr", format = "simple",
             caption = "Cropland abandonment (in Mha) as of 2017 as identified using a) our annual time series and a five-year abandonment definition and b) the difference between only two years.") 



gt_2yr <- abn_2yr_overestimation %>%
  select(description, area_ha_cc:jaccard) %>%
  gt() %>%
  tab_header(title = "Table 1. Cropland abandonment (in Mha) as of 2017 as identified using a) our annual time series and a five-year abandonment definition and b) the difference between only two years.") %>%
  tab_options(heading.align = "left") %>%
  cols_label(
    description = "Site", 
    area_ha_cc = "Area (annual, as of 2017)", 
    area_2yr = "Area (2017-1987)", 
    percent_diff = "Percent Difference", 
    jaccard = "Jaccard Similarity") %>%
  cols_align(align = "left", columns = description) %>%
  cols_align(align = "right", columns = c("area_ha_cc", "area_2yr", "percent_diff", "jaccard")) %>%
  fmt_percent(columns = percent_diff, decimals = 2, scale_values = FALSE) %>%
  fmt_number(., columns = c("area_ha_cc", "area_2yr"), use_seps = TRUE, sep_mark = ",", decimals = 0) %>%
  fmt_number(., columns = c("jaccard"), use_seps = TRUE, sep_mark = ",", decimals = 2)

gt_2yr

gtsave(gt_2yr, filename = paste0(p_plots, run_label, "/", 
                         "table_1_abn_2yr_overestimation.png"))

# webshot::install_phantomjs()


```

