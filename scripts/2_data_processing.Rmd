---
title: "R Notebook"
output: html_notebook
editor_options:
  chunk_output_type: console
bibliography: /Users/christophercrawford/Google Drive/Library/library.bib
---
R notebook for loading and processing the land cover time-series raster data from @Yin2020.


```{r initialize}
source("/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/scripts/0_start.R")

# define color palette for plotting:
# 1. Non-veg
# 2. Woody veg
# 3. Crop
# 4. Grassland
plot_cols <- c("gray80", # gray, 1. Non-veg
               terrain.colors(9)[1], # dark green, 2. Woody veg
               terrain.colors(9)[5], # gold, 3. Crop
               terrain.colors(9)[3] # light green, 4. Grassland
               )
plot_cols_new <- c("gray80", # gray, 1. Non-veg
               terrain.colors(9)[5], # gold, 2 (formerly 3) Crop
               terrain.colors(9)[3], # light green, 3 (formerly 4) Grassland
               terrain.colors(9)[1]  # dark green, 4 (formerly 2) Woody veg
               )

plot_breaks <- c(0, 1, 2, 3, 4)

# show_col(terrain.colors(20))
# show_col(topo.colors(20))
# show_col(cm.colors(20))
# 
# show_col(plot_cols)
# show_col(plot_cols[c(1, 3, 2)])
```

```{r load-data}
# Land use class codes:
#       1. Non-vegetated area (e.g. water, urban, barren land)
#       2. Woody vegetation
#       3. Cropland 
#       4. Herbaceous land (e.g. grassland)

bs <- brick(paste0(p_dat, "Abandonment/belarus_small.tif"))
names(bs) <- paste0("y", 1987:2017)
bs_dt <- as.data.table.raster(bs)

bt <- brick(paste0(p_dat_derived, "belarus_subset.tif"))
names(bt) <- paste0("y", 1987:2017)
bt_dt <- as.data.table.raster(bt)

object_size(bs_dt)
object_size(bt_dt)


# GEE
b_files <- list.files(paste0(p_dat, "Abandonment/belarus_tiles/"))

# just belarus files, but not necessary
# b_files <- list.files(paste0(p_dat, "Abandonment/belarus_tiles/")) %>%
#   grep("belarus", ., value = TRUE)

b1 <- brick(paste0(p_dat, "Abandonment/belarus_tiles/", b_files[1]))
s <- brick(paste0(p_dat_derived, "input_rasters/shaanxi.tif"))

s
plot(s[[1]])
ncell(b1)
ncell(s)
res(s)
res(b1)
nlayers(b1)
nlayers(s)
raster::area(s[[1]])
22592862 * res(s)[1] * res(s)[2]
34668544 * res(b1)[1] * res(b1)[2]


res(b1)[1] * 110 * 1000 # about 30 m checks out
res(s)[1] * 110 * 1000 # about 30 m checks out
b_tiles

plot(s[[1]], main = "Shaanxi 1987", breaks = c(0, plot_cols$breaks), col = plot_cols$color)

b_tiles <- lapply(1:6, function(i) {
    brick(paste0(p_dat, "Abandonment/belarus_tiles/", b_files[i]))})
names(b_tiles) <- b_files

names(b_tiles[[6]])

# Shaanxi is much much smaller than Belarus
ncell(s) # 94.4 M
ncell(b87_r) # 22.59 M
# they have the same resolution
res(s)
res(b_tiles)




# as data.tables
dt <- as.data.table.raster(s)
object_size(dt)
dt <- dt_s
names(dt) <- gsub("andcover", "y", names(dt))
ncol(dt)
dt[, .N, by = .(y1987)] # one year


fwrite(dt, file = paste0(p_dat_derived, "shaanxi.csv"))
dt <- fread(input = paste0(p_dat_derived, "shaanxi.csv"))
```

```{r load-data-derived}


b_age <- fread(input = paste0(p_dat_derived, "belarus_age.csv"))
s_age <- fread(input = paste0(p_dat_derived, "shaanxi_age.csv"))


b_length <- fread(input = paste0(p_dat_derived, "belarus_length.csv"))
s_length <- fread(input = paste0(p_dat_derived, "shaanxi_length.csv"))


b_max_length <- fread(input = paste0(p_dat_derived, "belarus_max_length.csv"))
s_max_length <- fread(input = paste0(p_dat_derived, "shaanxi_max_length.csv"))

# rasters
s_age_r <- brick(paste0(p_dat_derived, "shaanxi_age.tif"))
b_age_r <- brick(paste0(p_dat_derived, "belarus_age.tif"))



```

```{r set-site-params}
# Make data.frame containing site names, labels, original land cover codes, and noting whether to 1) merge layers into a stack, 2) update land cover codes, or 3) trim extra years

# Primary sites
# 1. Shaanxi - He
# 2. Belarus (Smolensk) - He
# 3. Chongqing - Yanhua (not great -fields are small, mountainous, and lots of clouds) - look at the data to see. 
# 4. Goias - Ben
# 5. Mato Grasso - Amintas
# 6. Nebraska - Seth
# 7. Wisconsin - David
# 
# ok
# 8. Volgograd - Natalia
# 9. Orenburg - Natalia
# 10. Bosnia & Herzegovina (medium)
# 11. Iraq (medium good, low accuracy over years, but good single accuracy)
# 
# exclude 
# 12. Nepal - Johanna
# 13. Sardinia - Kasia
# 14. Uganda - Niwaeli

# CAREFUL!!!!! Land Cover codes are different for each file:
# Land use class codes: (for He's site, Shaanxi and Belarus)
#       1. Non-vegetated area (e.g. water, urban, barren land)
#       2. Woody vegetation
#       3. Cropland 
#       4. Herbaceous land (e.g. grassland)
# 
# Also be careful of years: Nebraska runs from 1986-2018, Wisconsin 1987:2018. All other sites run 1987-2017.

# Shaanxi (China):      1 others;     2 forest,     3 cropland;     4 grassland
# Belarus / Russia:     1 others;     2 forest,     3 cropland;     4 grassland
# Goias (Brazil):       1 others;     2 forest,     3 cropland;     4 grassland
# Mato Grosso (Brazil): 1 others;     2 forest;     3 cropland;     4 grassland
# Bosnia & Herzegovina: 1 others;     2 forest;     3 cropland;     4 grassland
# Chongqing (China):    1 others;     2 forest;     3 cropland;     4 grassland

# Iraq:                 1 others;     2 cropland;   3 forest;       4 grassland
# Nebraska (US):        1 cropland;   2 forest;     3 others;       4 grassland
# Orenburg (Russia):    1 others;     2 cropland;   3 grassland;    4 forest
# Volgograd (Russia):   1 others;     2 cropland;   3 grassland;    4 forest
# Wisconsin (US):       1 cropland;   2 grassland;  3 forest;       4 others

# list of all sites
site_list <- c("belarus", "bosnia_herzegovina", "chongqing", 
               "goias", "iraq", "mato_grosso", 
               "nebraska", "orenburg", "shaanxi", 
               "volgograd", "wisconsin")


site_label_list <- c("_b", "_bh", "_c", 
                     "_g", "_i", "_mg", 
                     "_n", "_o", "_s", 
                     "_v", "_w")

description <- c("Eastern Belarus/Smolensk, Russia",
               "Bosnia & Herzegovina", 
               "Chongqing Province, China",
               "Goiás, Brazil", 
               "Iraq", 
               "Mato Grosso, Brazil", 
               "Nebraska, USA", 
               "Orenburg, Russia", 
               "Shaanxi/Shanxi Provinces, China", 
               "Volgograd, Russia", 
               "Wisconsin, USA")

site_merge_layers <- site_list[c(3, 4, 5, 7, 8, 9, 10)]
c("chongqing", "goias", "iraq", "nebraska", "orenburg", "shaanxi", "volgograd")

site_update_lc <- site_list[c(5, 7, 8, 10, 11)]
c("iraq", "nebraska", "orenburg", "volgograd", "wisconsin")


# make a data.frame outlining site names, labels, whether to update land cover, whether to merge, whether to trim years, original land cover codes etc. 
site_df <- data.frame(site = site_list,
                      label = site_label_list) %>% 
  mutate(merge_layers = ifelse(site %in% 
                                 c("chongqing", "goias", "iraq", 
                                   "nebraska", "orenburg", "shaanxi", "volgograd"), 
                               "Yes", "No"),
         update_lc = ifelse(site %in% 
                              c("iraq", "nebraska", "orenburg", 
                                "volgograd", "wisconsin"), 
                            "Yes", "No"),
         trim_years = ifelse(site %in% 
                               c("nebraska", "wisconsin"), 
                             "Yes", "No"),
         other = 1, 
         woody_veg = 2,
         cropland = 3,
         grassland = 4,
         description = c("Eastern Belarus/Smolensk, Russia",
               "Bosnia & Herzegovina", 
               "Chongqing Province, China",
               "Goiás, Brazil", 
               "Iraq", 
               "Mato Grosso, Brazil", 
               "Nebraska, USA", 
               "Orenburg, Russia", 
               "Shaanxi/Shanxi Provinces, China", 
               "Volgograd, Russia", 
               "Wisconsin, USA")
         )

# Update land cover classes for the following sites:
# Iraq:             1 others;     2 cropland;   3 forest;       4 grassland
# Nebraska:         1 cropland;   2 forest;     3 others;       4 grassland
# Russia Orenburg:  1 others;     2 cropland;   3 grassland;    4 forest
# Russia Volgograd: 1 others;     2 cropland;   3 grassland;    4 forest
# Wisconsin:        1 cropland;   2 grassland;  3 forest;       4 others

site_df[site_df$site == "iraq", 
        c("other", "cropland", "woody_veg", "grassland")] <- 1:4

site_df[site_df$site == "nebraska", 
        c("cropland", "woody_veg", "other", "grassland")] <- 1:4

site_df[site_df$site == "orenburg", 
        c("other", "cropland", "grassland", "woody_veg")] <- 1:4

site_df[site_df$site == "volgograd", 
        c("other", "cropland", "grassland", "woody_veg")] <- 1:4

site_df[site_df$site == "wisconsin", 
        c("cropland", "grassland", "woody_veg", "other")] <- 1:4

site_df



# save site_df
write_csv(site_df, path = paste0(p_dat_derived, "site_df.csv"))
```


```{r load-all-sites}
# ---------------------------------------------------
# load final tifs 
# ---------------------------------------------------

# year of first abandonment maps
yoa_files <- list.files(paste0(p_dat, "Abandonment/year_of_abandonment/"))
age_files <- list.files(paste0(p_dat_derived, "age_rasters"), full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = FALSE)

# map_files <- list.files(paste0(p_dat, "Abandonment/final_maps/"))
site_input_raster_files <- list.files(paste0(p_dat_derived, "input_rasters"), full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = TRUE)


r <- lapply(seq_along(site_input_raster_files), function(i) {
  # brick(paste0(p_dat_derived, "input_rasters/", site_input_raster_files[i]))
  brick(site_input_raster_files[i])
  }
  )

# names(r) <- site_input_raster_files
names(r) <- site_df$site
r
for (i in 1:11) {print(nlayers(r[[i]]))}
for (i in 1:11) {
  print(names(r[i]))
  print(names(r[[i]]))
}


# rename raster layers:
for (i in 1:11) {
  if (names(r[i]) == "nebraska") {
    names(r[[i]]) <- paste0("y", 1986:2018)
  } else {
    if (names(r[i]) == "wisconsin") {
      names(r[[i]]) <- paste0("y", 1987:2018)
    } else {
      # everything else, just 1987:2017
      names(r[[i]]) <- paste0("y", 1987:2017)
    }
  }
}

for (i in 1:11) {
  print(names(r[i]))
  print(names(r[[i]]))
  }

```


```{r site-area}
# plot total site area:

plot(c(ncell(b), ncell(s), sapply(seq_along(r), FUN = function(i) ncell(r[[i]]))))
layer <- r[[1]][[1]]
layer %>% raster::area() %>% cellStats(., "sum") # 47331.03 km2

tic()
r[[1]][[1]] %>% raster::area() %>% cellStats(., "sum")
toc()

tic()
site_area <- sapply(seq_along(r), FUN = function(i) {
  r[[i]][[1]] %>% raster::area() %>% cellStats(., "sum")
  }
  )
toc()


num_cells <- sapply(seq_along(r), FUN = function(i) ncell(r[[i]]))
num_cells
names(r)
num_cells[1:7]
names(r)[1:7]
site_df$site[2:8]
site_df

site_df_w_size <- site_df %>%
  mutate(ncell = num_cells,
         area = site_area)

write_csv(site_df_w_size, path = paste0(p_dat_derived, "site_df_w_size.csv"))
site_df_w_size <- read_csv(file = paste0(p_dat_derived, "site_df_w_size.csv"))

area_b1_s

# 
gg_site_ncell <- ggplot(data = site_df_w_size) + 
  theme_classic() +
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  geom_col(mapping = aes(x = reorder(site, ncell), y = ncell/(10^6))) + 
    labs(title = "Number of Cells per Site", x = "Site", y = expression("Number of Cells (10"^{6}*")"))


gg_site_area <- ggplot(data = site_df_w_size) + 
  theme_classic() +
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  geom_col(mapping = aes(x = reorder(site, area), y = area)) + 
  labs(title = "Site Area", x = "Site", y = expression("Area  (km"^{2}*")"))

gg_site_ncell
gg_site_area

# save
png(filename = paste0(p_output, "plots/site_area.png"), 
    width = 7, height = 5, units = "in", res = 400)
print(gg_site_area)
dev.off()


b
plot(b[[1]])

plot(test)
ncell(test)
# GEE

# just belarus files, but not necessary
# b_files <- list.files(paste0(p_dat, "Abandonment/belarus_tiles/")) %>%
#   grep("belarus", ., value = TRUE)

b1 <- brick(paste0(p_dat, "Abandonment/belarus_tiles/", b_files[1]))
s <- brick(paste0(p_dat_derived, "input_rasters/shaanxi.tif"))
s

plot(s[[1]], main = "Shaanxi 1987", breaks = c(0, plot_cols$breaks), col = plot_cols$color)

b_tiles <- lapply(1:6, function(i) {
    brick(paste0(p_dat, "Abandonment/belarus_tiles/", b_files[i]))})
names(b_tiles) <- b_files


# useful, but not necessary:

# filling things in conditionally, using dplyr or just base R
site_df[site_df$update_lc == "No", c("other", "woody_veg", "cropland", "grassland")] <- 1:4

site_df <- site_df %>% 
  mutate(other = ifelse(update_lc == "No" , 1, other),
         woody_veg = ifelse(update_lc == "No" , 2, woody_veg),
         cropland = ifelse(update_lc == "No" , 3, cropland),
         grassland = ifelse(update_lc == "No" , 4, grassland)
         )

```

```{r combine-years-brick}
# 1. if necessary combine individual years into a single brick (Chongqing, Goias, Iraq, Nebraska, Orenburg, and Volgograd)
# 2. write out the combined file back to the original folder, if it didn't exist already
# 3. update the land cover codes for those sites that follow different conventions, so that all match the following:
# Land use class codes: (for He's site, Shaanxi and Belarus)
#       1. Non-vegetated area (e.g. water, urban, barren land)
#       2. Woody vegetation
#       3. Cropland 
#       4. Herbaceous land (e.g. grassland)


# 4. write out final input raster to paste0(p_dat_derived, "input_rasters/"), to the 

# sites
site_df

# set site
site <- site_merge_layers[2]
site <- "wisconsin"
i

folder_paths <- list.dirs(path = paste0(p_dat, "Abandonment/raw_rasters"), 
                       full.names = TRUE, recursive = FALSE)
  
folder_names <- sapply(seq_along(folder_paths), FUN = function(i) {
  folders_l <- unlist(strsplit(folder_paths[[i]], "[/]"))
  folders_l <- folders_l[length(folders_l)]
  }
  )

merge_files <- lapply(site_merge_layers, FUN = function(i) {
      list.files(paste0(p_dat, "Abandonment/raw_rasters/", i), full.names = TRUE)
    })

names(merge_files) <- site_merge_layers
for (i in 1:6) {
  print(paste0(length(merge_files[[i]]), ": ", names(merge_files[i])))
  }

site_df[site_df$merge_layers == "Yes", "site"]



964/60 # 16 minutes. Better upload the data and go from there. 
cc_merge_rasters(site = "wisconsin", site_df = site_df)




gsub("X5_Volg_172_026_landcover", "y", names(v))

l <- lapply(merge_files, function(i) raster(i))

merge_files[[1]][1]
length(merge_files)
```


```{r testing-recode-lc}
# cc_recode_rasters <- function(site, site_df, input_path, output_path){
w_og <- brick(paste0(p_dat, "Abandonment/raw_rasters/wisconsin/centralWI_landCover_87_17.tif"))
w <- brick(paste0(p_dat_derived, "input_rasters/test/wisconsin.tif"))
w_raw_merged <- brick(paste0(p_dat_derived, "input_rasters/raw_merged/wisconsin_raw.tif"))

names(w_og)
names(w)
names(w_raw_merged)

freq(w_og[[1]])
#      value    count
# [1,]     0    55327 # 0
# [2,]     1 27011502 # cropland
# [3,]     2  7793180 # grassland
# [4,]     3 33690461 # forest
# [5,]     4  2323550 # others

# updating LC to: 1 others;     2 forest,     3 cropland;     4 grassland
# wisconsin og codes: 1 cropland;   2 grassland;  3 forest;       4 others
site_df %>% filter(site == "wisconsin")

freq(w[[1]])
#      value    count
# [1,]    11 27011502 # looks like the same as the 1s in the og raster
# [2,]    12  7793180 # looks like the recoding just didn't work! 
# [3,]    13 33690461
# [4,]    14  2323550
# [5,]    NA    55327

freq(w_raw_merged[[1]])
#      value    count
# [1,]     0    55327 # 0 
# [2,]     1 27011502 # cropland
# [3,]     2  7793180
# [4,]     3 33690461
# [5,]     4  2323550

identical(w, w_og)
p_dat
p_dat_derived

site <- "wisconsin"
site_df
input_path <- paste0(p_dat_derived, "input_rasters/raw_merged/")



tic("load input raster")
input_raster <- brick(paste0(input_path, site, "_raw.tif"))
toc(log = TRUE)

# crop to a small test size
plot(input_raster[[1]], main = "Year 1", col = plot_cols$color, breaks = c(0, plot_cols$breaks))

ext_1 <- drawExtent(show = TRUE, col = "red")
plot(input_raster[[1]], main = "Year 1, subset 1", col = plot_cols$color, breaks = c(0, plot_cols$breaks), ext = ext_1)

ext_2 <- drawExtent(show = TRUE, col = "red")
plot(input_raster[[1]], main = "Year 1, subset 2", col = plot_cols$color, breaks = c(0, plot_cols$breaks), ext = ext_2)

# crop
input_raster <- crop(input_raster, ext_2)
plot(input_raster[[1]], main = "Year 1, subset 2", col = plot_cols$color, breaks = c(0, plot_cols$breaks))
freq(input_raster[[1]])

# test_save <- input_raster
plot(test_save)

# input_raster <- test_save
writeRaster(input_raster, 
            filename = paste0("/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/data_derived/input_rasters/func_test/", site, "_raw.tif"),
            overwrite = TRUE)



# test the function again:
# write out the testing small subset of wisconsin:
cc_recode_rasters(site = site,  # wisconsin
                  site_df = site_df, 
                  input_path = "/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/data_derived/input_rasters/func_test/", 
                  output_path = "/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/data_derived/input_rasters/func_test/")


w_t <- brick(paste0(p_dat_derived, "input_rasters/func_test/", site, ".tif"))
freq(w_t[[1]])
freq(test_save[[1]])
freq(input_raster[[1]]) 
```

```{r testing-recode-lc-dt}

test_r <- brick(paste0(p_dat_derived, "input_rasters/func_test/", site, "_raw.tif"))



# test the function again:
# write out the testing small subset of wisconsin:
cc_recode_rasters(site = site,  # wisconsin
                  site_df = site_df, 
                  input_path = "/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/data_derived/input_rasters/func_test/", 
                  output_path = "/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/data_derived/input_rasters/func_test/")

# testing the cc_recode_lc_dt() function
test_r <- brick(paste0(p_dat_derived, "input_rasters/func_test/", site, "_raw.tif"))
names(test_r) <- paste0("y", 1987:2018)
dt <- as.data.table.raster(test_r)
dt <- cbind(dt[, 1:2], dt[, 3:length(dt)] + 10)
dt


dt[, .N, by = y1987][order(y1987)] # get freq again

dt1 <- cc_recode_lc_dt(dt = dt, site = site, site_df = site_df)
dt
dt[, .N, by = y1987][order(y1987)] # get freq again
dt1[, .N, by = y1987][order(y1987)] # get freq again
site_df[site_df$site == site,]


test_raw <- brick(paste0(p_dat_derived, "input_rasters/func_test/", site, "_raw.tif"))
plot(test_raw[[1]])

cc_r_to_dt(site = site, path = paste0(p_dat_derived, "input_rasters/func_test/"))

cc_filter_abn_dt(site = site,
                 path = paste0(p_dat_derived, "input_rasters/func_test/"),
                 label = "_blip1",
                 clean_blips = TRUE)

cc_save_dt_as_raster(site = site, type = "_age_blip1", 
                     input_path = paste0(p_dat_derived, "input_rasters/func_test/"),
                     output_path = paste0(p_dat_derived, "input_rasters/func_test/"))
                             
test_recoded <- brick(paste0(p_dat_derived, "input_rasters/func_test/", site, ".tif"))
test_age <- brick(paste0(p_dat_derived, "input_rasters/func_test/", site, "_age_blip1.tif"))
site_df
plot(test_raw[[1]])
plot(test_recoded[[1]], col = plot_cols$color)
plot(test_age[[1]])
```


```{r test-full-analysis-w-wisc}
source('~/Google Drive/_Projects/abandonment_trajectories/scripts/util/_util_dt_filter_functions.R')
site <- "wisconsin"
p_dat_derived

# set paths:
p_input_rasters <- paste0(p_dat_derived, "input_rasters/func_test/")  # "/scratch/network/clc6/abandonment_trajectories/data_derived/input_rasters/"
p_output <- p_output          # "/scratch/network/clc6/abandonment_trajectories/output/"
p_raw_rasters_path <- p_input_rasters #"/scratch/network/clc6/abandonment_trajectories/raw_rasters/"


# test out the script, then work on merging the data.tables
site_df <- read.csv(file = paste0(p_dat_derived, "site_df.csv"))

ws_raw <- brick(paste0(p_input_rasters, site,"/", site, "_raw.tif"))

plot(ws_raw[[1]], main = "raw")


# 0. Merge raw raster layers
cat("0. Merge raw raster layers", fill = TRUE)
tic("Merge rasters")
cc_merge_rasters(site = site, site_df = site_df, input_path = p_raw_rasters_path)
toc(log = TRUE)

ws_raw_merged <- brick(paste0(p_input_rasters, site, "_raw.tif"))
cellStats(ws_raw - ws_raw_merged, stat = "sum") # all 0 - they are identical.
plot(ws_raw_merged[[1]], main = "raw, merged")


# 1. Convert raw rasters into data.tables (including renaming and recoding)
cat("1. Converting raw rasters into data.tables (including renaming and recoding): ", site, fill = TRUE)
cc_r_to_dt(site = site, 
           input_path = p_raw_rasters_path, 
           output_path = p_input_rasters, 
           site_df = site_df)

ws_raw <- fread(input = paste0(p_input_rasters, site, "_raw.csv"))
ws <- fread(input = paste0(p_input_rasters, site, ".csv"))
ws_raw
ws

# 2. Process raw data.tables in order to calculate the length of agricultural abandonment periods.
      # Steps include:
      # 1) filtering to just abandonment cells, 
      # 2) filling recultivation blips based on a threshold,
      # 3) calculating age, and 4) extracting lengths, all the while writing out files.

cat("2. Filter data.tables for abandonment raw rasters to data.tables: ", site, fill = TRUE)

cc_filter_abn_dt(site = site,
                 path = p_input_rasters,
                 blip_label = blip_label,
                 clean_blips = TRUE)

ws_age <- fread(input = paste0(p_input_rasters, site, "_age", blip_label, ".csv"))
ws_diff <- fread(input = paste0(p_input_rasters, site, "_diff", blip_label, ".csv"))
ws_length <- fread(input = paste0(p_input_rasters, site, "_length", blip_label, ".csv"))
ws_blips_count <- fread(input = paste0(p_input_rasters, site, "_blips_count", blip_label, ".csv"))


ws
ws_age
ws_age[y1987 > 0, ]
ws_diff
ws_length
ws_blips_count

# 3 Calculate maximum age, serial
cat("3. Calculate maximum age, in serial:", site, fill = TRUE)
cc_calc_max_age(directory = p_input_rasters, 
                site = site, 
                blip_label = blip_label,
                label = label)

ws_max_length <- fread(input = paste0(p_input_rasters, site, "_max_length", blip_label, ".csv"))



# 4. save various data.tables as rasters:
cat("4. Saving data.tables as rasters: ", site, fill = TRUE)

dt_types <- c(
  "", 
  paste0("_age", blip_label)
)

cat("types of data.tables to save as rasters:", fill = TRUE)
print(dt_types)

for (i in dt_types) {
  cc_save_dt_as_raster(site = site, 
                       type = i, 
                       input_path = p_input_rasters, 
                       output_path = p_input_rasters)
}

ws_age_r <- brick(paste0(p_input_rasters, site, "_age", blip_label, ".tif"))
ws_r <- brick(paste0(p_input_rasters, site, ".tif"))

plot(ws_raw_merged[[1]], main = "raw, merged")
plot(ws_r[[1]], main = "recoded")
plot(ws_age_r[[31]], main = "age, 2017")



ws
ws_age
# 
# # Add in NA rows, by joining x and y columns from the original land cover data.table to the age_dt
# ws_age <- merge(ws[, .(x, y)], ws_age, all = TRUE, by = c("x", "y"), sort = FALSE)
# ws_age
# ws_age_all
# 
# object_size(ws_age)
# object_size(ws_age_all)
# 
# # convert age dt to raster
# ws_age_r <- dt_to_raster(ws_age, crs("+proj=longlat +datum=WGS84 +no_defs"))
# plot(ws_age_all_r$y2017, colNA = "red")
# plot(ws_age_r$y2017, colNA = "red")
# 
# object_size(ws_age_all_r)




# 5. Summarize the abandonment datatables into dataframes for plotting purposes
cat("5. Summarizing abandonment data.tables: ", site, fill = TRUE)

cc_summarize_abn_dts(
  input_path = p_input_rasters,
  output_path = p_input_rasters,
  site = site,
  blip_label = blip_label,
  outfile_label = paste0(blip_label, "_w"),
  abandonment_threshold = 5,
  include_all = TRUE
)



# plotting:
cc_save_area_persistence_plots(input_path, 
                               site_label = "_w",
                               blip_label = blip_label,
                               outfile_label,
                               subtitle = "Wisconsin test", 
                               subtitle_all = paste0(subtitle, ", all abandonment"), 
                               save_all = TRUE)



```

```{r load-data-products}
ws_raw_merged <- brick(paste0(p_input_rasters, site, "_raw.tif"))
cellStats(ws_raw - ws_raw_merged, stat = "sum") # all 0 - they are identical.
plot(ws_raw_merged[[1]], main = "raw, merged")



ws_raw <- fread(input = paste0(p_input_rasters, site, "_raw.csv"))
ws <- fread(input = paste0(p_input_rasters, site, ".csv"))
ws_raw
ws



ws_age <- fread(input = paste0(p_input_rasters, site, "_age", blip_label, ".csv"))
ws_diff <- fread(input = paste0(p_input_rasters, site, "_diff", blip_label, ".csv"))
ws_length <- fread(input = paste0(p_input_rasters, site, "_length", blip_label, ".csv"))
ws_blips_count <- fread(input = paste0(p_input_rasters, site, "_blips_count", blip_label, ".csv"))

# compare abandonment age to 2017 w 2018
ws_age_17 <- copy(ws_age)
ws_length_17 <- copy(ws_length)
ws_age_17
ws_age
ws_length[length >= 5, mean(length)]
ws_length_17[length >= 5, mean(length)]

ws
ws_age
ws_age[y1987 > 0, ]
ws_diff
ws_length
ws_blips_count



ws_max_length <- fread(input = paste0(p_input_rasters, site, "_max_length", blip_label, ".csv"))




ws_age_r <- brick(paste0(p_input_rasters, site, "_age", blip_label, ".tif"))
ws_r <- brick(paste0(p_input_rasters, site, ".tif"))
ws_r_1 <- raster(paste0(p_input_rasters, site, ".tif"))
plot(ws_r_1)
plot(ws_r[[1]])

plot(ws_raw_merged[[1]], main = "raw, merged")
plot(ws_r[[1]], main = "recoded")
plot(ws_age_r[[31]], main = "age, 2017")



ws
ws_age
```


```{r explore-prepped-rasters}
site_df

w <- brick("/Users/christophercrawford/Google Drive/_Projects/data/Abandonment/raw_rasters/wisconsin/centralWI_landCover_87_17.tif")
w
names(w) # wisconsin actually has 32 layers, including 2018.

rasters <- lapply(site_list[-c(1, 7, 9)], function(site) {
  brick(paste0(p_dat_derived, "input_rasters/test/input_rasters/", site, ".tif"))
  }
  )
list.files(paste0(p_dat_derived, "input_rasters/test/input_rasters"), full.names = TRUE)
names(rasters) <- site_list[-c(1, 7, 9)]

names(rasters)
for (i in seq_along(rasters)) {print(nlayers(rasters[[i]]))}



test <- read.csv(paste0(p_dat, "Abandonment/raw_rasters/", site, ".csv"))
unlist(test, use.names = F) == names(raster_stack)


# test that the recoding worked
freq(raster_stack[[1]])

```

```{r iraq}
# testing the function with iraq. 

i_og <- brick(paste0(p_dat, "Abandonment/raw_rasters/iraq/centralWI_landCover_87_17.tif"))
i <- brick(paste0(p_dat_derived, "input_rasters/test/iraq.tif"))
i_raw_merged <- brick(paste0(p_dat_derived, "input_rasters/raw_merged/iraq_raw.tif"))

names(i)
names(i_raw_merged)


freq(i_raw_merged[[1]])
freq(i[[1]])

# updating LC to: 1 others;     2 forest,     3 cropland;     4 grassland
# iraq og codes: 1 others;   2 cropland;  3 forest;       4 grassland
site_df %>% filter(site == "iraq")



list.files(paste0(p_dat_derived, "input_rasters/func_test/"))

i2 <- brick(paste0(p_dat_derived, "input_rasters/func_test/iraq.tif"))

i_new <- brick(paste0(p_dat_derived, "input_rasters/func_test/iraq.tif"))
names(i2)

plot(i[[1]], maxpixels = 50000)
plot(i2[[1]], maxpixels = 50000)



freq(i[[1]])
freq(i2[[1]])
freq(i_raw_merged[[1]])

freq(i_new[[1]])


```



```{r simple-plots}
show_col(plot_cols) # (topleft = 1, topright = 2, bottomleft = 3, bottomright = 4)
# gray,         1. Non-veg
# dark green,   2. Woody veg
# gold,         3. Crop
# light green,  4. Grassland

plot(b87_r, main = "Belarus 1987", breaks = c(0, plot_cols$breaks), col = plot_cols$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols$name, 
       fill = plot_cols$color)

plot(bs$smolensk1987, add = T, legend = F, col = "blue")
plot(bt$smolensk1987, add = T, legend = F, col = "red")
bs

plot(bs$smolensk1987, main = "Subset: Belarus 1987", 
     breaks = c(0, plot_cols$breaks), col = plot_cols$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols$name, 
       fill = plot_cols$color)

plot(bt$smolensk1987, main = "Subset Subset: Belarus 1987", 
     breaks = c(0, plot_cols$breaks), col = plot_cols$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols$name, 
       fill = plot_cols$color)

# --------------
# animate
# --------------
# https://www.rdocumentation.org/packages/raster/versions/3.1-5/topics/animate

animate(bt, pause = 0.5, zlim = c(1, 4), maxpixels=5000, n=1,
        breaks = c(0, plot_cols$breaks), col = plot_cols$color)

```


```{r final-processing-workflow-w-tictoc}
# script for computing cluster

library(raster)
library(data.table)
library(devtools)
library(tictoc)

# devtools::install_github("ldemaz/dtraster")
library(dtraster)

tic("Full script")

file <- "/Users/christophercrawford/Google Drive/_Projects/data/Abandonment/belarus_small.tif"
name <- "shaanxi"
path <- p_dat_derived

# load custom filtering functions
source("scripts/util/_util_dt_filter_functions.R")


tic("load raster")
r <- brick(file)

nlayers(r) # 31 years in the time series
names(r) <- paste0("y", 1:nlayers(r))
toc()



# load as a data.table
tic("load data.table")
dt <- as.data.table.raster(r)
toc()

# update names of data.table, if not already updated
names(dt) <- gsub("andcover", "y", names(dt))

# write out data.table as a csv
fwrite(dt, file = paste0(path, name, ".csv"))


# ----------------------
# start heavy processing

tic("update land cover classes")
cc_update_lc(dt, crop_code = 0, noncrop_code = 1)
toc()

tic ("remove NAs")
dt <- na.omit(dt)
toc()

tic("filter non abandonment pixels")
dt <- cc_remove_non_abn(dt)
toc()


tic("calculate age")
cc_calc_age(dt)
toc()


tic("erase non abandonment periods")
cc_erase_non_abn_periods(dt)
toc()


tic("write out cleaned abandonment age data.table")
fwrite(dt, file = paste0(path, name, "_age.csv"))
toc()
path

tic("make diff")
dt_diff <- cc_diff_dt(dt)
toc()

# write out dt_diff
tic("write out dt_diff")
fwrite(dt_diff, file = paste0(path, name, "_diff.csv"))
toc()


tic("extract length")
length <- cc_extract_length(dt_diff)
toc()


# write out length
length <- data.table(length = length)
fwrite(length, file = paste0(path, name, "_length.csv"))

# write out 

# explore some stats:
length[, .N, by = length]
length[, mean(length)] # mean time abandoned if using no threshold
length[length >= 5, mean(length)] # mean time abandoned, if using 3 year abandonment definition threshold


# final toc()
toc()
```

```{r shaanxi-processing}
# script for computing cluster

library(raster)
library(data.table)
library(devtools)
library(tictoc)

# devtools::install_github("ldemaz/dtraster")
library(dtraster)
path_in <- "/Users/christophercrawford/Google Drive/_Projects/data/Abandonment/eefull/"
path_out <- p_dat_derived

# shaanxi run
name <- "shaanxi"
file <- paste0(path_in, name, ".tif")

# load custom filtering functions
source("scripts/util/_util_dt_filter_functions.R")

# load raster
r <- brick(file)

nlayers(r) # 31 years in the time series
names(r) <- gsub("andcover", "y", names(r))
# names(r) <- paste0("y", 1986 + 1:nlayers(r))


# load as a data.table
dt <- as.data.table.raster(r)

# write out data.table as a csv
fwrite(dt, file = paste0(path_out, name, ".csv"))


# # read in data.table directly
# dt <- fread(file = paste0(path_out, name, ".csv"))
# nrow(dt) # pre processing 22,592,862
# nrow(dt) # 8,290,074 # post processing
# 
# # update names of data.table, if not already updated
# names(dt) <- gsub("andcover", "y", names(dt))


# ----------------------
# start heavy processing 

tic()
# update land cover classes
cc_update_lc(dt, crop_code = 0, noncrop_code = 1)

# remove NAs
dt <- na.omit(dt)

# filter non abandonment pixels
dt <- cc_remove_non_abn(dt)

# calculate age
cc_calc_age(dt)

# erase non abandonment periods
cc_erase_non_abn_periods(dt)

# write out cleaned abandonment age data.table
fwrite(dt, file = paste0(path_out, name, "_age.csv"))

# make diff
dt_diff <- cc_diff_dt(dt)

# write out dt_diff
fwrite(dt_diff, file = paste0(path_out, name, "_diff.csv"))

# extract length
length <- cc_extract_length(dt_diff)

# write out length
length <- data.table(length = length)
fwrite(length, file = paste0(path_out, name, "_length.csv"))



# explore some stats:
length[, .N, by = length]
length[, mean(length)] # mean time abandoned if using no threshold
length[length >= 5, mean(length)] # mean time abandoned, if using 3 year abandonment definition threshold

toc()
```

```{r save-age-rasters}

# as a function

age_r <- cc_save_dt_as_raster(name = "shaanxi")
names(age_r) <- paste0("y", 1987:2017)
plot(age_r$y2017, main = "Age of abandonment in 2017")

age_r <- brick("/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/data_derived/shaanxi_age_1.tif")
identical(age_r, age_r1)

cellStats(age_r[[31]] - age_r1[[31]], "sum")


# works fine for shaanxi, but running into issues with belarus... see below


# -------------
# development

dt <- fread(file = paste0(path_out, name, "_age.csv"))

s2017 <- dt[, .(x, y, y2017)]

# convert age dt to raster
age_r <- dt_to_raster(dt, crs(s))


plot(age_r$y2017, main = "Age of Abandonment, 2017")
rasterVis::levelplot(age_r$y2017)
# animate
names(age_r)
animate(age_r, pause = 0.3, main = paste0("Abandonment Age, ", 1987:2017), maxpixels = 500000, n = 1)

names(age_r)
# write raster
writeRaster(age_r, filename = paste0(p_dat_derived, name, "_age.tif"))
names(age_r)

# reload, and rename
age_r <- brick(paste0(p_dat_derived, name, "_age.tif"))
names(age_r) <- paste0("y", 1987:2017)

# just 2017
age_2017_r <- dt_to_raster(dt[, .(x, y, y2017)], crs(s), filename = paste0(p_dat_derived, name, "_age_2017.tif"))


plot(age_r$y2017, main = "Age of abandonment in 2017")


# final code
r <- dt_to_raster(dt, crs("+proj=longlat +datum=WGS84 +no_defs"))
writeRaster(r, filename = paste0(directory, name, "_age.tif"))
brick(paste0(directory, name, "_age.tif"))
```

```{r merging-belarus-chunks}
# -------------------------------
# merge original belarus rasters

b <- merge(b_tiles[[1]], 
                 b_tiles[[2]],
                 b_tiles[[3]],
                 b_tiles[[4]],
                 b_tiles[[5]],
                 b_tiles[[6]])
names(b) <- paste0("y", 1987:2017)
tic()
writeRaster(b, filename = paste0(p_dat_derived, "belarus.tif"))
toc()

plot(b$y1987, col = plot_cols$color, breaks = c(0, plot_cols$breaks), main = "merged")
plot(b87_r, col = plot_cols$color, breaks = c(0, plot_cols$breaks), main = "1987 direct")
plot(b87_r - b$y1987)

cellStats(b$y1987 - b87_r, "sum")



# -------------------------------
# save Belarus 1 as a raster:
# b1_age_r <- cc_save_dt_as_raster(name = "belarus1")  

# manually
b1_age_r1 <- dt_to_raster(b1_age[1:2000000], crs("+proj=longlat +datum=WGS84 +no_defs"))
b1_age_r2 <- dt_to_raster(b1_age[2000001:4000000], crs("+proj=longlat +datum=WGS84 +no_defs"))

plot(b1_age_r1$y2017)
plot(b1_age_r2$y2017, add = T)

# -------------------------------
# test merging belarus chunks
merge_test <- merge(b1_age_r1, b1_age_r2)
merge_test
ncell(merge_test)
ncell(b1_age_r1) + ncell(b1_age_r2)
plot(merge_test$layer.31)
plot(extent(b1_age_r1), add = T, col = "black")
plot(extent(b1_age_r2), add = T, col = "black")
b1_age_r3 <- dt_to_raster(b1_age[1:4000000], crs("+proj=longlat +datum=WGS84 +no_defs"))
cellStats(merge_test - b1_age_r3, "sum") # these are the same, and it looked like it worked just fine, subtracting sequentially.


# try merging a full brick
b11 <- dt_to_raster(b1_age[1:100000][order(x),], crs("+proj=longlat +datum=WGS84 +no_defs"))
b12 <- dt_to_raster(b1_age[100001:200000][order(x),], crs("+proj=longlat +datum=WGS84 +no_defs"))
plot(b12$y2017)
test <- dt_to_raster(b1_age[1:200][order(x),], crs("+proj=longlat +datum=WGS84 +no_defs"))

writeRaster(b1_age_r, filename = paste0(directory, "belarus1", "_age.tif"))
plot(b1_age_r$y2017)

# reload, and assign names
b1_age_r <- brick(paste0(directory, "belarus1", "_age.tif"))
names(b1_age_r) <- paste0("y", 1987:2017)

plot(b1_age_r$y2017, main = "Age of abandonment in 2017")

```

```{r belarus-processing}

# belarus runs, for loop
run <- 1 # change this for each belarus run

# initial test
tic()
cc_process_rasters(input_raster_file = paste0(p_dat, "Abandonment/belarus_tiles/", b_files[1]),
                     name = paste0("belarus", 1), 
                     path_out = p_dat_derived,
                     gsub_pattern = "smolensk")
toc()

tic()
for(run in 1:6) {
  cc_process_rasters(input_raster_file = paste0(p_dat, "Abandonment/belarus_tiles/", b_files[run]),
                     name = paste0("belarus", run), 
                     path_out = p_dat_derived,
                     gsub_pattern = "smolensk")
}
toc()




# -------------------------------
# load and check the belarus data
b1_dt <- fread(input = paste0(p_dat_derived, "belarus1.csv"))
b1_diff <- fread(input = paste0(p_dat_derived, "belarus1_diff.csv"))

b1_age <- fread(input = paste0(p_dat_derived, "belarus1_age.csv"))
b2_age <- fread(input = paste0(p_dat_derived, "belarus2_age.csv"))
b3_age <- fread(input = paste0(p_dat_derived, "belarus3_age.csv"))
b4_age <- fread(input = paste0(p_dat_derived, "belarus4_age.csv"))
b5_age <- fread(input = paste0(p_dat_derived, "belarus5_age.csv"))
b6_age <- fread(input = paste0(p_dat_derived, "belarus6_age.csv"))


# save rasters:
cc_save_dt_as_raster(name = "belarus1") # not enough memory

dt <- fread(file = paste0(p_dat_derived, "belarus1_age.csv"))
shaanxi_age <- fread(file = paste0(p_dat_derived, "shaanxi_age.csv"))
nrow(dt)
nrow(shaanxi_age)
r <- dt_to_raster(dt, crs("+proj=longlat +datum=WGS84 +no_defs"))
writeRaster(r, filename = paste0(p_dat_derived, "belarus1_age.tif"))

env_size(ls())
plot(r)

# ------------------------------
# merge and save 2017 age layer as a raster
# test merge
b_age_2017 <- rbindlist(list(b1_age[, .(x, y, y2017)],
                            b2_age[, .(x, y, y2017)],
                            b3_age[, .(x, y, y2017)],
                            b4_age[, .(x, y, y2017)],
                            b5_age[, .(x, y, y2017)],
                            b6_age[, .(x, y, y2017)])
                       )

fwrite(b_age_2017, file = paste0(p_dat_derived, "belarus_age_2017.csv"))

b_age_2017_r <- dt_to_raster(b_age2017, crs("+proj=longlat +datum=WGS84 +no_defs"))
plot(b_age_2017_r, main = "Belarus, 2017 - age of abandoned croplands")
plot(extent(b_tiles[[1]]), add = T, col = "black")
plot(extent(b_tiles[[2]]), add = T, col = "black")
plot(extent(b_tiles[[3]]), add = T, col = "black")
plot(extent(b_tiles[[4]]), add = T, col = "black")
plot(extent(b_tiles[[5]]), add = T, col = "black")
plot(extent(b_tiles[[6]]), add = T, col = "black")

extent(b_tiles[[1]])

writeRaster(b_age2017_r, filename = paste0(p_dat_derived, "belarus_age_2017.tif"))
b_age2017_r <- raster(paste0(p_dat_derived, "belarus_age_2017.tif"))



b1_length <- fread(input = paste0(p_dat_derived, "belarus1_length.csv"))

b_length


env_size(ls())

# ------------------------------- #
# ultimately I processed the merged Belarus raster file in one go on adroit, using the script: 
# /Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/scripts/cluster/process_calc_age_belarus.R
# ------------------------------- #


```

```{r inspect-adroit-belarus}
# check cluster output to make sure it worked correctly

# merge individual lengths

b1_length <- fread(input = paste0(p_dat_derived, "belarus1_length.csv"))
b2_length <- fread(input = paste0(p_dat_derived, "belarus2_length.csv"))
b3_length <- fread(input = paste0(p_dat_derived, "belarus3_length.csv"))
b4_length <- fread(input = paste0(p_dat_derived, "belarus4_length.csv"))
b5_length <- fread(input = paste0(p_dat_derived, "belarus5_length.csv"))
b6_length <- fread(input = paste0(p_dat_derived, "belarus6_length.csv"))

b_length_merge <- rbindlist(list(b1_length,
                                 b2_length,
                                 b3_length,
                                 b4_length,
                                 b5_length,
                                 b6_length))

# load the full belarus length file
b_length <- fread(input = paste0(p_dat_derived, "belarus_length.csv"))
# the order is off, because of the way the length extraction code works, extracting each year's column individually, and rbinding those.


# check to see if they're identical
identical(b_length[order(length)], b_length_merge[order(length)])


# initial stats on length, Belarus


# explore some stats:
s_length <- fread(input = paste0(p_dat_derived, "shaanxi_length.csv"))
s_length
b_length
s_length[, .N, by = length]
b_length[, .N, by = length]

object_size(b_length)
s_length[, site := "shaanxi"]
b_length[, site := "belarus"]

length_all <- rbindlist(list(s_length, b_length))
object_size(length_all)

dat <- length_all[, .(mean_length = mean(length)), by = site]
dat2 <- length_all[length >= 5, .(mean_length_thr5 = mean(length)), by = site]
dat <- merge(dat, dat2, by = "site", sort = FALSE)
dat

# max length
```

```{r histograms}
# plot histograms
# beware... because of the way the bins are determined, the default histogram automatically lumps 1 and 2 together. better to first distill the data and use ggplot 
hist(s_length[[1]], main = "Histogram of Length of Time Abandoned \n Shaanxi/Shanxi Provinces, China", xlab = "Time (years)")

hist(b_length[[1]])

hist(length_all[site == "shaanxi", length], main = "Histogram of Abandonment Period Lengths \n Shaanxi/Shanxi Provinces, China", xlab = "Time (years)")

hist(length_all[site == "belarus", length], main = "Histogram of Abandonment Period Lengths \n Belarus/Russia", xlab = "Time (years)")

hist(b_length[[1]], main = "Histogram of Abandonment Period Lengths \n Belarus/Russia", xlab = "Time (years)")
toc()

hist(b_length[[1]], main = "right = TRUE")
hist(b_length[[1]], right = FALSE, main = "right = FALSE")


# to use with ggplot, first distill the data

b_distill <- b_length[, .(freq = .N), by = length]
b_distill[, site := "belarus"]
s_distill <- s_length[, .(freq = .N), by = length]
s_distill[, site := "shaanxi"]

distill <- rbind(b_distill, s_distill)

b_max_distill <- b_max_length[, .(freq = .N), by = max_length]
b_max_distill[, site := "belarus"]
s_max_distill <- s_max_length[, .(freq = .N), by = max_length]
s_max_distill[, site := "shaanxi"]
max_distill <- rbind(b_max_distill, s_max_distill)

# ggplots
# both site histograms
dat

length_plot <- ggplot(data = distill) + 
  labs(title = "Histogram of all periods of abandonment") +
  geom_col(mapping = aes(x = length, y = freq), fill = "gray50") +
  facet_grid(rows = vars(site), scales = "free") +
  geom_vline(xintercept=5, linetype="dashed", 
             color = "red", size = 0.75) +
  geom_vline(xintercept=20, linetype="dashed", color = "dark green", size = 0.75) +
  theme_classic()

# max_length
max_length_plot <- ggplot(data = max_distill) + 
  labs(title = "Histogram of max abandonment length per pixel") +
  geom_col(mapping = aes(x = max_length, y = freq), fill = "gray50") +
  facet_grid(rows = vars(site), scales = "free") +
  geom_vline(xintercept=5, linetype="dashed", 
             color = "red", size = 0.75) +
  geom_vline(xintercept=20, linetype="dashed", color = "dark green", size = 0.75) +
  theme_classic()


length_plot
max_length_plot
dat




# just belarus
ggplot(data = b_distill) + 
  geom_col(mapping = aes(x = length, y = freq), fill = "black") +
  theme_classic()

ggplot(data = b_length, aes(length)) + 
  geom_histogram() +
  theme_classic() # took forever!! Beware...
```


```{r calc-max-age}
# calculate the maximum length of time abandoned for each pixel:
# not sure this code works yet... try with a smaller dt first. 
dt <- b1_age[1:100000]
dt
tic()
dt[, max_length := max(.SD), .SDcols = -c("x", "y"), by = .(x, y)]
toc() # 14.56 sec
getDTthreads() # ? no speed up ?

# testing function: it works!
dt1 <- b1_age[1:100000]
cc_calc_max_age(dt1, name = "belarus1")
identical(dt[, .(x,y,max_length)], dt1)
dt1 <- fread(input = paste0(p_dat_derived, "belarus1_max_length.csv"))

286.417 * nrow(b1_age)/nrow(dt) / 60 # 41 minutes, 40 minutes for the full dataset

max1 <- dt_to_raster(dt[, .(x, y, max_length)], crs("+proj=longlat +datum=WGS84 +no_defs"))

# one can also directly calculate this using raster::calc(), which ends up being faster.
tic()
max <- calc(b1_age_r1, fun = function(r){max(r, na.rm = TRUE)})
toc()
plot(max) # 130.958 sec
warnings()

cellStats(max1 - max, "sum")
plot(max1)
plot(max)
```


```{r parallel-dt}


```



```{r animation}
name <- "shaanxi"
age_r <- brick(paste0(p_dat_derived, name, "_age.tif"))
names(age_r) <- paste0("y", 1987:2017)
# plot(age_r$y2017)

# first, with animate package
saveGIF(animate(age_r, 
                main = paste0(
                  "Abandonment Age, ", 
                  capwords(name), " ", 
                  1987:2017), 
                maxpixels = 500000, 
                n = 1), 
        movie.name = paste0(
          p_dat_derived, name, "_age_animation.gif")
        )

# now, with magick
age_r_gif <- image_read(paste0(p_dat_derived, name, "_age_animation.gif"))
age_r_gif <- image_animate(age_r_gif)
image_write(shaanxi_age_gif, paste0(p_dat_derived, name, "_age_animation.gif"))


# make it into a function:

# take an animation made with raster::animate(), and save it as a GIF with animation::saveGIF()
cc_save_gif <- function(raster, 
                        titles = names(raster), 
                        file_out, 
                        npixels = 5000,
                        frames_per_second = 5) {
  
  # use animation::saveGIF() to save raster::animate()
  saveGIF(animate(raster, main = titles, maxpixels = npixels, n = 1), 
          movie.name = file_out)
  
  gif <- image_animate(image_read(file_out), fps = frames_per_second)
  image_write(gif, file_out)
}


# run the function:

# name <- "shaanxi"
name <- "belarus"
age_r <- brick(paste0(p_dat_derived, name, "_age.tif"))
names(age_r) <- paste0("y", 1987:2017)
plot(age_r$y2017)

tic()
cc_save_gif(raster = age_r, 
            npixels = 500000, 
            titles = paste0("Abandonment Age, ", 
                            capwords(name), " ", 1987:2017),
            frames_per_second = 5,
            file_out = paste0(p_dat_derived, name, "_age_animation.gif"))
toc()

```

```{r plot-length}
length
dt[, .N, by = andcover1987]
# out of 
11550730 + # 1 (grassland or woody vegetation)
  8135598 # 0 (crop) 
19686328 # 19 M cells (19,686,328)
dt # 8,290,074 of them were abandoned at some point (even just fallowed)
nrow(dt)/19686328 * 100 # 42.11 %

summary(length[[1]])
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 1.000   2.000   4.000   6.617  10.000  30.000

length[length >= 3, summary(length)]
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 3.000   4.000   7.000   9.596  14.000  30.000 

length[length >= 5, summary(length)]
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 5.00    6.00   10.00   12.01   15.00   30.00

object_size(length)
object_size(dt)
object_size(dt_diff)

hist(length[[1]], main = "Histogram of Length of Time Abandoned \n Shaanxi/Shanxi Provinces, China", xlab = "Time (years)")


# rasters:
plot(s[[1]], main = "Shaanxi 1987", breaks = c(0, plot_cols$breaks), col = plot_cols$color)
plot(s[[31]], main = "Shaanxi 2017", breaks = c(0, plot_cols$breaks), col = plot_cols$color)


```
```{r plot-trajectory-per-pixel}
ncell(bt)
# subset the data.table, for plotting
sub <- bs_dt[1:10, -c(1,2)]
sub[, pixel := c(1:10)]

sub <- dt[1:10, -c(1,2)]
sub

names(sub) <- gsub("y", "", names(sub))
sub[, pixel := c(1:10)]



sub_melt <- melt(sub, id.vars = "pixel", 
                 variable.name = "year", 
                 value.name = "land_use", na.rm = TRUE)

sub_melt$year <- gsub("y", "", sub_melt$year)

str(sub_melt)

# set colors for plotting
show_col(terrain.colors(9))

lc_cols <- scale_color_manual(name = "Land Cover",
                     labels = c("1" = "1. Non-veg",
                                "2" = "2. Woody veg",
                                "3" = "3. Crop",
                                "4" = "4. Grassland"),
                     values = c("1" = "gray80",
                                "2" = terrain.colors(9)[1], # dark green
                                "3" = terrain.colors(9)[5], # gold
                                "4" = terrain.colors(9)[3] # light green
                                )
                     ) 

# this plot shows the land-use trajectories of 10 individual pixels.
gg_10_px_traj <- ggplot(data = sub_melt, 
                        mapping = aes(x = year, y = land_use, group = pixel)) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  geom_line(mapping = aes(color = factor(land_use)), size = 2) +
  facet_grid(rows = vars(pixel), scales = "free_x", switch = "x") + 
  ylim(1, 4) + lc_cols

gg_10_px_traj
#       1. Non-vegetated area (e.g. water, urban, barren land)
#       2. Woody vegetation
#       3. Cropland 
#       4. Herbaceous land (e.g. grassland)


```


## Investigate cluster data products
```{r check-blips}

b_blips <- fread(input = paste0(p_dat_derived, "belarus1_length.csv"))

list.files(p_dat_derived) %>% grep("*blips_count_b1.csv", ., value = TRUE)

site
s_blips <- fread(file = paste0(p_dat_derived, site, "_blips_count_b1.csv"))

blips_df <- lapply(1:11, FUN = function(x) {
  site <- site_df$site[x] # set site:
  site_label <- site_df$label[x] # set label
  
  dat_temp <- fread(file = paste0(p_dat_derived, site, "_blips_count_b1.csv"))
  dat_temp <- pivot_longer(dat_temp, cols = c("one", "two", "three"), 
                           names_to = "threshold", values_to = "count")
  })

names(blips_df) <- site_df$site
blips_df <- blips_df %>% bind_rows(.id = "site")

# plot blips:
png(filename = paste0(p_output, "plots/recultivation_temp_filter_blips.png"), 
    width = 9, height = 5, units = "in", res = 400)

ggplot(data = blips_df, # filter(blips_df, site == "shaanxi"), 
       mapping = aes(x = year, y = count/(10^5), 
                     group = threshold, color = threshold)) + 
  labs(title = "Temporal Filter for short-term recultivation", 
       y = "Count (100,000)", x = "Year", color = "Threshold \n(Years)",
       caption = "Passing temporal filter on recultivation: 1-0-1, 1-0-0-1, vs. 1-0-0-0-1") + 
  geom_point(size = 1.5, alpha = 0.7) + 
  facet_wrap(vars(site), scales = "free_y") + 
  theme(legend.position = )

dev.off()

```

## Develop new temporal filter

```{r create-test-dt}
# create a test dt
numcol <- 31
dt <- cc_create_bin(numcol = numcol)
dt
names(dt) <- paste0("y", 1986 + 1:numcol)
dt[, ':='(x = 7, y = 8)] # add x and y columns
setcolorder(dt, c("x", "y", paste0("y", 1986+1:numcol))) #, instead of doing x <- x[, neworder, with=FALSE]
# note: dplyr methods also work:
# select(dt, x, y, everything())
dt
```


```{r load-test-dt}
# load test dt:
# dt <- copy(bs_dt)
# cc_update_lc(dt, crop_code = 0, noncrop_code = 1)  # update land cover classes
# dt <- na.omit(dt)   # remove NAs
# nrow(dt) # 21587
# dt <- cc_remove_non_abn(dt)   # filter non abandonment pixels (i.e. those that are either all crop or all noncrop)
# nrow(dt) # 17674

# Count number of periods of recultivation that fall below a continuous recultivation threshold.

# s_dt
s_dt <- fread(input = paste0(p_dat_derived, "shaanxi.csv"))
names(s_dt) <- gsub(pattern = "andcover", replacement = "y", names(s_dt))
cc_update_lc(s_dt, crop_code = 0, noncrop_code = 1)  # update land cover classes
s_dt <- na.omit(s_dt)   # remove NAs
nrow(s_dt) # 17,477,812 rows

tic()
s_dt <- cc_remove_non_abn(s_dt)   # filter non abandonment pixels (i.e. those that are either all crop or all noncrop)
nrow(s_dt) # 8,290,074 rows
toc()
```


```{r new-temporal-filter-count}
# -------------------------------------------------------------------------- #
# Count
# -------------------------------------------------------------------------- #
cc_temporal_filter_count <- function(dt) {
  
  # check that dt starts with x & y
  if (length(grep("[xy]$", names(dt))) > 0) {
    if (!identical(names(dt)[1:2], c("x", "y"))) {
      stop("x and y must be the first two columns in the data.table")
    } else {
      start <- 4
    }
  } else {
    start <- 2
  }
  
  # for each column, determine the number of number of rows that match the following pattern:
  five_yr_count <- sapply(5:(ncol(dt) - 2), function(i) {
      dt[get(names(dt)[i-2]) == 1 & 
           get(names(dt)[i-1]) == 1 & 
           get(names(dt)[i]) == 0 & 
           get(names(dt)[i+1]) == 1 & 
           get(names(dt)[i+2]) == 1, .N]
    }
    )

  # for each column, return the row indices that match the following pattern, iterating across all columns
  affected_rows_5 <- lapply(5:(ncol(dt) - 2), function(i) {
      dt[get(names(dt)[i-2]) == 1 & 
           get(names(dt)[i-1]) == 1 & 
           get(names(dt)[i]) == 0 & 
           get(names(dt)[i+1]) == 1 & 
           get(names(dt)[i+2]) == 1, which = TRUE] # which = TRUE returns the row indices
    }
    ) %>% unlist() %>% unique() # then condense the list into a single vector and remove duplicates
  
  # do the same, but for the eight year moving window filter, counting from the first 0 position
  eight_yr_count <- sapply(6:(ncol(dt) - 4), function(i) {
      dt[get(names(dt)[i-3]) == 1 & # index here has to start at 3
           get(names(dt)[i-2]) == 1 & 
           get(names(dt)[i-1]) == 1 & 
           get(names(dt)[i]) == 0 & 
           get(names(dt)[i+1]) == 0 & 
           get(names(dt)[i+2]) == 1 & 
           get(names(dt)[i+3]) == 1 & 
           get(names(dt)[i+4]) == 1, .N]
    }
    )
  
  affected_rows_8 <- lapply(6:(ncol(dt) - 4), function(i) {
      dt[get(names(dt)[i-3]) == 1 & # index here has to start at 3
           get(names(dt)[i-2]) == 1 & 
           get(names(dt)[i-1]) == 1 & 
           get(names(dt)[i]) == 0 & 
           get(names(dt)[i+1]) == 0 & 
           get(names(dt)[i+2]) == 1 & 
           get(names(dt)[i+3]) == 1 & 
           get(names(dt)[i+4]) == 1, which = TRUE]
    }
    ) %>% unlist() %>% unique()
  
  # construct data.frame
  cases_df <- data.frame(
      year = 1:length(grep("x$|y$", invert = T, names(dt))) - 1 + 1987,
      five_yr = c(rep.int(0, 2), five_yr_count, rep.int(0, 2)),
      eight_yr = c(rep.int(0, 3), eight_yr_count, rep.int(0, 4)))
  
  nrow_affected <- data.frame(
    filter = c("five_yr", "eight_yr", "either"),
    nrow_affected = c(length(affected_rows_5),
                      length(affected_rows_8),
                      length(unique(c(affected_rows_5, affected_rows_8)))
                      )
    )
  
    # return the lists
    list(cases_df = cases_df,
         affected_rows_5 = affected_rows_5, 
         affected_rows_8 = affected_rows_8,
         nrow_affected = nrow_affected)
}

```


```{r new-temporal-filter}
# -------------------------------------------------------------------------- #
# New temporal filter (February 19th, 2021)
# -------------------------------------------------------------------------- #
cc_temporal_filter <- function(dt, replacement_value = 1) {
  
  # check that dt starts with x & y
  if (length(grep("[xy]$", names(dt))) > 0) {
    if (!identical(names(dt)[1:2], c("x", "y"))) {
      stop("x and y must be the first two columns in the data.table")
    } else {
      start <- 4
    }
  } else {
    start <- 2
  }
  
  # ---------------------------------------------------------- #
  # five year moving window: 
  # fill 1-1-0-1-1
  for (i in 5:(ncol(dt) - 2)) {
    dt[get(names(dt)[i-2]) == 1 &  # subset to 1-1-0-1-1
        get(names(dt)[i-1]) == 1 & 
        get(names(dt)[i]) == 0 & 
        get(names(dt)[i+1]) == 1 & 
        get(names(dt)[i+2]) == 1,
      
       names(dt)[i] := replacement_value # update value
       ]
  }
  
  # ---------------------------------------------------------- #
  # eight year moving window filter:
  # fill 1-1-1-0-0-1-1-1
  for (i in 6:(ncol(dt) - 4)) { # index here has to start at 3
    dt[get(names(dt)[i-3]) == 1 & # subset to 1-1-1-0-0-1-1-1
           get(names(dt)[i-2]) == 1 & 
           get(names(dt)[i-1]) == 1 & 
           get(names(dt)[i]) == 0 & 
           get(names(dt)[i+1]) == 0 & 
           get(names(dt)[i+2]) == 1 & 
           get(names(dt)[i+3]) == 1 & 
           get(names(dt)[i+4]) == 1, 
       
       c(names(dt)[i], 
         names(dt)[i+1]) := replacement_value # update value
       ]
  }
}
```

```{r test-new-filter}

# pick up here: doesn't seem to be working. I don't know if it the filter filling and counting actually works. 

# count
tic()
counts_df <- cc_temporal_filter_count(dt)
toc()

counts_df %>% group_by() %>% summarise(sum_5 = sum(five_yr), sum8 = sum(eight_yr))
sum(counts_df$five_yr)
colSums(counts_df)

# filter
tic()
cc_temporal_filter(dt, replacement_value = -7)
toc()
dt[]


# testing with s_dt
tic()
cc_temporal_filter(dt = s_dt, replacement_value = -7)
toc() # 9.902 seconds

s_dt[y1996 == "-7", .N]

s_dt[get("y1996") == -7 | get("y1997") == -7, .N]
s_dt[get("y1996") == -7, .N]
s_dt[get("y1997") == -7, .N]

tic()
counts_sdf <- cc_temporal_filter_count(dt = s_dt)
toc() # 11.129 seconds

# how many cases are found by the 5 and 8 year filters?
counts_sdf %>% group_by() %>% summarise(sum_5 = sum(five_yr), sum8 = sum(eight_yr)) 
nrow(s_dt) # after the initial filtering steps, 8.3 m rows. Before that it's 17.5 m pixels
# so, it's between
counts_sdf %>% group_by() %>% 
  summarise(sum_5 = sum(five_yr), sum8 = sum(eight_yr)) /
  # nrow(s_dt) * 100
  17500000 * 100



# count the number of pixels that are affected:
# two options for this:
# 1. [I used this version] I can run the count function to return the indices of the matching rows, iterate across all columns, concatenate the list into a single vector, then run unique() to reduce that vector to just the rows affected in *any* year. I do this for the five year and the eight year vector, return them in a list, which I can then combine and use to calculate the number of rows affected by the filter, using length().

# 2. Alternatively, I could do either of the following things: I can run the temporal filter filling with something like -7, then count the number of rows that are affected by counting the number of rows where one of the columns matches -7.

tic() # I can do this, but it takes a while: 
counts <- apply(s_dt, 1, function(row) any(row == -7))
sum(counts)
toc() # 23.714 seconds

tic() # this is much much faster, though less efficient to code, of course. 
s_dt[y1987 == -7 | y1988 == -7 | y1989 == -7 | y1990 == -7 | 
       y1991 == -7 | y1992 == -7 | y1993 == -7 | y1994 == -7 | y1995 == -7 | 
       y1996 == -7 | y1997 == -7 | y1998 == -7 | y1999 == -7 | y2000 == -7 | 
       y2001 == -7 | y2002 == -7 | y2003 == -7 | y2004 == -7 | y2005 == -7 | 
       y2006 == -7 | y2007 == -7 | y2008 == -7 | y2009 == -7 | y2010 == -7 | 
       y2011 == -7 | y2012 == -7 | y2013 == -7 | y2014 == -7 | y2015 == -7 | 
       y2016 == -7 | y2017 == -7, .N]
toc() # something like 2 seconds.
1954756 / 17500000 * 100 # this filter affects 11% of the pixels in this 

tic()
counts_sdf <- cc_temporal_filter_count(dt = s_dt)
toc() # 22.3 sec

c(counts_sdf$affected_rows_5, counts_sdf$affected_rows_8) %>% unique() %>% length()

s_dt[counts_sdf$affected_rows_5, ]

# old: 

# Fill short periods of recultivation that fall below a continuous recultivation threshold.
cc_fill_blips(dt, recultivation_threshold = recultivation_threshold, 
              replacement_value = recultivation_replacement_value)

  # notes:
  # This function fills short periods of recultivation that fall below a recultivation threshold.
  # It recodes from crop back to non-crop, based on how many continuous years 
  # of crop classification are required by the threshold.
  # This cleaning step should occur before calculating the age.
  # Use as follows:
  # cc_fill_blips(dt)


# after passing the temporal filter, I run the following functions:

cc_calc_age(dt)  # calculate age
cc_erase_non_abn_periods(dt)  # erase non abandonment periods (i.e. those that start the time series as non-crop)

```

```{r final-filtering steps}

# count first
tic()
count_test <- cc_temporal_filter_count(dt = s_dt)
toc()
count_test$nrow_affected

# run the filter:
tic()
cc_temporal_filter(dt = s_dt, replacement_value = 1)
toc()


# then the next steps
tic()
cc_calc_age(dt = s_dt)  # calculate age
toc() # 9 seconds

tic()
cc_erase_non_abn_periods(dt = s_dt)
toc() # 1 second


# just dt
dt <- cc_remove_non_abn(dt)   # filter non abandonment pixels (i.e. those that are either all crop or all noncrop)
count_test <- cc_temporal_filter_count(dt)
count_test$nrow_affected
cc_temporal_filter(dt, replacement_value = 1)
cc_calc_age(dt)  # calculate age
cc_erase_non_abn_periods(dt)


```


### filtering edge cases

Text for the manuscript's methods section.

To be more conservative about misclassification of pixels, we also applied modified versions of these five- and eight-year moving window filters to the start of the times series, to address short periods of cropland that may be misclassified.
By conservatively assuming the years immediately prior to our time series to be classified as non-cropland, we are able to use our moving window filters to exclude additional cases where a one or two year period of cropland may not represent stable cultivation.
This has the effect of applying a partial threshold on the number of consecutive years of cropland needed at the start of the time series in order to confidently signify agricultural activity, which are required in order to represent abandonment rather than the continuation of previously uncultivated non-cropland.
These modified filters for the start of the time series affected only a small area, totaling less than X% of pixels at each site.

No special actions were taken on the end of the time series, with the possible effect of erroneously indicating recultivation right at the end of the time series, making our estimates of the length of time abandoned conservative. 
These edge patterns were very uncommon, however, affecting fewer than X% of pixels at each site. 

Also note: we focused on filtering short-term periods of cropland among long periods of non-cropland, because we are only concerned with instances of misclassifications of cropland. 
Misclassified short term periods of non-cropland in the middle of cropland do not affect the identification of abandonment, because these would merely represent short-term fallow periods, and therefore are excluded by our five year abandonment threshold.
We decided to address the edge cases at the start of the time series, rather than the end of the time series, because we prefer to be conservative in excluding lands that may be consistently noncrop lands from our estimate of abandoned lands.
In contrast, the edge cases at the end of the time series only affect our estimate of the length of time abandoned, because one or two year periods of cropland, if misclassified, may erroneously mark recultivation in the final years of the time series.
However, we decline to address any potential misclassifications here in order to take the more conservative approach with regards to recultivation.

```{r count-edge-cases}
# -------------------------------------------------------------------------- #
# count edge cases
# -------------------------------------------------------------------------- #

# only count the occurrences at the end, do not fill them
cc_temporal_filter_count_edge_cases <- function(dt){
  
  # ---------------------------------------------------------- #
  # five year filter, edge cases
  
  # ------ start ------ #
  partial5_start_1 <- 
    dt[y1987 == 0 & 
       y1988 == 1 & 
       y1989 == 1, which = TRUE]
  
  partial5_start_2 <- 
    dt[y1987 == 1 & 
       y1988 == 0 & 
       y1989 == 1 &
       y1990 == 1, which = TRUE]
  
  # ------ end ------ #
  partial5_end_1 <- 
    dt[y2015 == 1 & 
       y2016 == 1 & 
       y2017 == 0, which = TRUE]
  
  partial5_end_2 <- 
    dt[y2014 == 1 & 
       y2015 == 1 & 
       y2016 == 0 & 
       y2017 == 1, which = TRUE]
  
  # ---------------------------------------------------------- #
  # eight year filter, edge cases
  
  # ------ start ------ #
  partial8_start_1 <- 
    dt[y1987 == 0 & 
       y1988 == 1 & 
       y1989 == 1 &
       y1990 == 1, which = TRUE]
  
  partial8_start_2 <- 
    dt[y1987 == 0 & 
       y1988 == 0 & 
       y1989 == 1 & 
       y1990 == 1 &
       y1991 == 1, which = TRUE]
  
  partial8_start_3 <- 
    dt[y1987 == 1 & 
       y1988 == 0 & 
       y1989 == 0 & 
       y1990 == 1 &
       y1991 == 1 &
       y1992 == 1, which = TRUE]
  
  partial8_start_4 <- 
    dt[y1987 == 1 & 
       y1988 == 1 & 
       y1989 == 0 & 
       y1990 == 0 &
       y1991 == 1 &
       y1992 == 1 & 
       y1993 == 1, which = TRUE]
  
  # ------ end ------ #
  partial8_end_1 <- 
    dt[y2014 == 1 & 
       y2015 == 1 & 
       y2016 == 1 & 
       y2017 == 0, which = TRUE]
  
  partial8_end_2 <- 
    dt[y2013 == 1 & 
       y2014 == 1 & 
       y2015 == 1 & 
       y2016 == 0 & 
       y2017 == 0, which = TRUE]
  
  partial8_end_3 <- 
    dt[y2012 == 1 & 
       y2013 == 1 & 
       y2014 == 1 & 
       y2015 == 0 & 
       y2016 == 0 & 
       y2017 == 1, which = TRUE]
  
  partial8_end_4 <- 
    dt[y2011 == 1 & 
       y2012 == 1 & 
       y2013 == 1 & 
       y2014 == 0 & 
       y2015 == 0 & 
       y2016 == 1 & 
       y2017 == 1, which = TRUE]
  
  # ---------------------------------------------------------- #
  # count the total number of pixels affected by any of the edge cases:
  
  # ------ start ------ #
  num_pixels_affected_start <- 
  dt[(y1987 == 0 & 
      y1988 == 1 & 
      y1989 == 1) | 
     
     (y1987 == 1 & 
      y1988 == 0 & 
      y1989 == 1 &
      y1990 == 1) |
     
     (y1987 == 0 & 
      y1988 == 1 & 
      y1989 == 1 &
      y1990 == 1) |
     
     (y1987 == 0 & 
      y1988 == 0 & 
      y1989 == 1 & 
      y1990 == 1 &
      y1991 == 1) |
     
     (y1987 == 1 & 
      y1988 == 0 & 
      y1989 == 0 & 
      y1990 == 1 &
      y1991 == 1 &
      y1992 == 1) |
     
     (y1987 == 1 & 
      y1988 == 1 & 
      y1989 == 0 & 
      y1990 == 0 &
      y1991 == 1 &
      y1992 == 1 & 
      y1993 == 1), 
   .N]
  
  
  # ------ end ------ #
  num_pixels_affected_end <- 
  dt[(y2015 == 1 & 
      y2016 == 1 & 
      y2017 == 0) |
     
     (y2014 == 1 & 
      y2015 == 1 & 
      y2016 == 0 &
      y2017 == 1) |
     
     (y2014 == 1 & 
      y2015 == 1 & 
      y2016 == 1 & 
      y2017 == 0) |
     
     (y2013 == 1 & 
      y2014 == 1 & 
      y2015 == 1 & 
      y2016 == 0 & 
      y2017 == 0) |
     
     (y2012 == 1 & 
      y2013 == 1 & 
      y2014 == 1 & 
      y2015 == 0 & 
      y2016 == 0 & 
      y2017 == 1) | 
     
     (y2011 == 1 & 
      y2012 == 1 & 
      y2013 == 1 & 
      y2014 == 0 & 
      y2015 == 0 & 
      y2016 == 1 & 
      y2017 == 1), 
   .N]
  
  # ------ either start or end cases ------ #
  num_pixels_affected_either <- 
  dt[
    # five year window, start
     (y1987 == 0 &  
      y1988 == 1 & 
      y1989 == 1) |
       
     (y1987 == 1 & 
      y1988 == 0 & 
      y1989 == 1 &
      y1990 == 1) |
     
    # five year window, end
     (y2015 == 1 &
      y2016 == 1 & 
      y2017 == 0) |
     
     (y2014 == 1 & 
      y2015 == 1 & 
      y2016 == 0 &
      y2017 == 1) |
     
    # eight year window, start
     (y1987 == 0 & 
      y1988 == 1 & 
      y1989 == 1 &
      y1990 == 1) |
     
     (y1987 == 0 & 
      y1988 == 0 & 
      y1989 == 1 & 
      y1990 == 1 &
      y1991 == 1) |
     
     (y1987 == 1 & 
      y1988 == 0 & 
      y1989 == 0 & 
      y1990 == 1 &
      y1991 == 1 &
      y1992 == 1) |
     
     (y1987 == 1 & 
      y1988 == 1 & 
      y1989 == 0 & 
      y1990 == 0 &
      y1991 == 1 &
      y1992 == 1 & 
      y1993 == 1) |
     
    # eight year window, end
     (y2014 == 1 &
      y2015 == 1 & 
      y2016 == 1 & 
      y2017 == 0) |
     
     (y2013 == 1 & 
      y2014 == 1 & 
      y2015 == 1 & 
      y2016 == 0 & 
      y2017 == 0) |
     
     (y2012 == 1 & 
      y2013 == 1 & 
      y2014 == 1 & 
      y2015 == 0 & 
      y2016 == 0 & 
      y2017 == 1) | 
     
     (y2011 == 1 & 
      y2012 == 1 & 
      y2013 == 1 & 
      y2014 == 0 & 
      y2015 == 0 & 
      y2016 == 1 & 
      y2017 == 1), 
   .N]
  
  c(partial5_start_1, partial5_start_2,
              partial8_start_1, partial8_start_2, partial8_start_3, partial8_start_4,
              partial5_end_1, partial5_end_2,
              partial8_end_1, partial8_end_2, partial8_end_3, partial8_end_4) %>% unique %>% length
  
  # ---------------------------------------------------------- #
  # construct data.frame
  edge_case_counts <- data.frame(
    filter = rep(c(rep("five", 2), rep("eight", 4)), 2),
    edge = c(rep("start", 6), rep("end", 6)),
    pattern = c(
      c("|011", "|1011", 
        "|0111", "|00111", "|100111", "|1100111"),
      c("110|","1101|", 
        "1110|", "11100|", "111001|", "1110011|")),
    type = "cases",
    value = c(partial5_start_1, partial5_start_2,
              partial8_start_1, partial8_start_2, partial8_start_3, partial8_start_4,
              partial5_end_1, partial5_end_2,
              partial8_end_1, partial8_end_2, partial8_end_3, partial8_end_4))
  
  edge_pixels_affected <- data.frame(
    filter = "both",
    edge = c("start", "end", "either"),
    type = "pixels_affected",
    value = c(num_pixels_affected_start, num_pixels_affected_end, num_pixels_affected_either)
    ) %>%
    mutate(percent_affected = value/nrow(dt))
  
  
  pixel_count <- data.frame(
    type = "pixel_count",
    value = nrow(dt)
  )
  
  # return the data.frames bound together:
  bind_rows(edge_case_counts, edge_pixels_affected, pixel_count)
}

count_df <- cc_temporal_filter_count_edge_cases(dt)

tic()
count_edge_cases_bs_dt <- cc_temporal_filter_count_edge_cases(dt)
toc()

env_size(ls())

```


```{r filter-edge-cases}
cc_temporal_filter_edge_cases <- function(dt, replacement_value = 1) {
  # note: this filter only addresses edge cases at the start of the time series.
  
  # ---------------------------------------------------------- #
  # five year moving window
    dt[y1987 == 0 & 
       y1988 == 1 & 
       y1989 == 1, 
       c("y1987") := replacement_value]
  
    dt[y1987 == 1 & 
       y1988 == 0 & 
       y1989 == 1 &
       y1990 == 1, 
      c("y1988") := replacement_value]

  # ---------------------------------------------------------- #
  # eight year filter, edge cases
    dt[y1987 == 0 & 
       y1988 == 1 & 
       y1989 == 1 &
       y1990 == 1, 
       c("y1987") := replacement_value]
  
    dt[y1987 == 0 & 
       y1988 == 0 & 
       y1989 == 1 & 
       y1990 == 1 &
       y1991 == 1, 
       c("y1987", "y1988") := replacement_value]
  
    dt[y1987 == 1 & 
       y1988 == 0 & 
       y1989 == 0 & 
       y1990 == 1 &
       y1991 == 1 &
       y1992 == 1, 
       c("y1988", "y1989") := replacement_value]
  
    dt[y1987 == 1 & 
       y1988 == 1 & 
       y1989 == 0 & 
       y1990 == 0 &
       y1991 == 1 &
       y1992 == 1 & 
       y1993 == 1, 
       c("y1989", "y1990") := replacement_value]
}
```

```{r test-edge-functions}
# pick up here: doesn't seem to be working. I don't know if it the filter filling and counting actually works. 

tic()
cc_temporal_filter_count_edge_cases(dt = s_dt)
toc()


tic()
cc_temporal_filter_edge_cases(dt, replacement_value = 99)
toc()
dt[]

count_df <- cc_temporal_filter_count_edge_cases(dt)

env_size(ls())


```

