---
title: "Spatial Predictors of Abandonment and Recultivation"
author: "Christopher L. Crawford"
date: "2/1/2021"
output: html_document
editor_options: 
  chunk_output_type: console
bibliography: [/Users/christophercrawford/Google Drive/Library/library.bib]
---
```{r load-packages-functions, eval = TRUE, echo = FALSE, include = FALSE}

source("/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/scripts/0_start.R")
# source("cc_functions.R")
# source("cc_libraries.R")
# source("cc_pathnames.R")

```

```{r load-files, include = FALSE}
# set run:
run_label <- "_2021_03_13"

# Additional paths --------------------------------------------------- #
p_plots <- "/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/output/plots/"

# load general spatial data on site locations --------------------------------------------------- #
site_df <- read.csv(file = paste0(p_dat_derived, "site_df.csv"))
site_sf <- st_read(paste0(p_dat_derived, "site_sf.shp"))


# load data for shaanxi maps --------------------------------------------------- #

# load data for decay models --------------------------------------------------- #

# AIC, for SI
# mod_AIC <- read.csv(file = paste0(p_dat_derived, "mod_AIC.csv"))

# load data for spatial regression --------------------------------------------------- #


# for use on cluster:
# p_dat <- "/scratch/network/clc6/abandonment_trajectories/data_derived/"
# p_dat_derived <- "/scratch/network/clc6/abandonment_trajectories/data_derived/"
# p_output <- paste0("/scratch/network/clc6/abandonment_trajectories/output/")
list.files(p_dat_derived)
list.files(p_dat)



```


```{r load-site-rasters, include = FALSE}
# -------------------- rasters, individual --------------------- #

# Land use class codes:
#       1. Non-vegetated area (e.g. water, urban, barren land)
#       2. Woody vegetation
#       3. Cropland 
#       4. Herbaceous land (e.g. grassland)

# testers:
bs <- brick(paste0(p_dat, "Abandonment/belarus_small.tif"))
bt <- brick(paste0(p_dat_derived, "belarus_subset.tif"))
names(bs) <- paste0("y", 1987:2017)
names(bt) <- paste0("y", 1987:2017)


# raw rasters
s <- brick(paste0(p_dat_derived, "input_rasters/shaanxi.tif"))
b <- brick(paste0(p_dat_derived, "input_rasters/belarus.tif")) # merged version

# age
s_age_r <- brick(paste0(p_dat_derived, "shaanxi_age.tif"))
b_age_r <- brick(paste0(p_dat_derived, "belarus_age.tif"))

# max_length
s_max_length_r <- brick(paste0(p_dat_derived, "shaanxi_max_length.tif"))
b_max_length_r <- brick(paste0(p_dat_derived, "belarus_max_length.tif"))

# update year names 1987 - 2017
names(s) <- paste0("y", 1987:2017)
names(b) <- paste0("y", 1987:2017)
names(s_age_r) <- paste0("y", 1987:2017)
names(b_age_r) <- paste0("y", 1987:2017)




# ------------------------------------------------------------ #
# --------------- list of all sites -------------------------- #


# prepared input rasters (derived by Chris)
site_input_raster_files <- list.files(paste0(p_dat_derived, "input_rasters"), full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = TRUE)

site_r
site_df
site_r <- lapply(seq_along(site_input_raster_files), function(i) {brick(site_input_raster_files[i])})
names(site_r) <- site_df$site

# rename raster layers:
for (i in 1:11) {
  if (names(site_r[i]) == "nebraska") {
    names(site_r[[i]]) <- paste0("y", 1986:2018)
  } else {
    if (names(site_r[i]) == "wisconsin") {
      names(site_r[[i]]) <- paste0("y", 1987:2018)
    } else {
      # everything else, just 1987:2017
      names(site_r[[i]]) <- paste0("y", 1987:2017)
    }}}

site_r
```


```{r load-age-rasters, include = FALSE}
# abandonment age maps (produced by Chris)
age_files <- list.files(paste0(p_dat_derived, "age_rasters/", run_label), full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = FALSE)


age_r <- lapply(seq_along(age_files), function(i) {brick(age_files[i])})
names(age_r) <- site_df$site
for (i in seq_along(age_r)) {names(age_r[[i]]) <- paste0("y", 1987:2017)} # remember: these are just 1987:2017


# year of first abandonment maps (from He)
yoa_files <- list.files(paste0(p_dat, "Abandonment/year_of_abandonment/"))
```

```{r load-max-age-rasters}
max_age_files <- list.files(paste0(p_dat_derived, "/max_age/", run_label), full.names = TRUE) %>% 
  grep(".tif", ., value = TRUE)
max_age_r <- lapply(seq_along(max_age_files), function(i) {
  tmp <- brick(max_age_files[i])
  names(tmp) <- "max_age"
  tmp
  })

names(max_age_r) <- site_df$site

max_age_r

plot(max_age_r$shaanxi)
abn_bin_r_all <- max_age_r$shaanxi
abn_bin_r <- max_age_r$shaanxi

# optional: make a binary "abandoned or not" layer, 
# though this can probably more easily and flexibly done with data.table
abn_bin_r_all[abn_bin_r_all > 0] <- 1

abn_bin_r[abn_bin_r < 5] <- 0 # exclude short-term fallowing:
abn_bin_r[abn_bin_r < 5] <- NA
hist(values(abn_bin_r))

abn_bin_r[abn_bin_r >= 5] <- 1

plot(max_age_r$shaanxi)

hist(values(max_age_r$shaanxi))
hist(values(abn_bin_r))


hist(values(max_age_r$shaanxi))
plot(abn_bin_r_all)
plot(abn_bin_r)



plot(abn_bin_r)
```


```{r levelplots}
max_age_rs <- max_age_r$shaanxi
max_age_rs[max_age_rs < 5] <- NA # exclude short-term fallowing:

age_in_2017_s <- age_r$shaanxi$y2017
age_in_2017_s[age_in_2017_s < 5] <- NA

# removing the large white space around the plots
lattice.options(
  layout.heights=list(bottom.padding=list(x=0), top.padding=list(x = 0)),
  layout.widths=list(left.padding=list(x=0), right.padding=list(x=0))
)

levelplot(max_age_rs, margin = list(FUN = 'median'), #contour=TRUE, 
          par.settings = viridisTheme)

levelplot(max_age_rs, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = RdBuTheme)
levelplot(max_age_rs, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = infernoTheme)
levelplot(max_age_rs, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = plasmaTheme)

p1 <- levelplot(max_age_rs, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = YlOrRdTheme,
          main = "Max. abandonment duration")


p_2017 <- levelplot(age_in_2017_s, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = YlOrRdTheme,
          main = "Abandonment length as of 2017")


max_age_values <- values(max_age_rs) %>% 
  as_tibble() %>% 
  filter(!is.na(max_age)) %>% 
  group_by(max_age) %>% summarise(freq = n())

age_in_2017_values <- values(age_in_2017_s) %>% 
  as_tibble() %>% 
  filter(!is.na(value)) %>% 
  group_by(value) %>% summarise(freq = n())

p_hist_max <- ggplot(data = max_age_values, aes(max_age)) + 
  geom_col(mapping = aes(x = max_age, y = freq), fill = "gray70") + 
  theme_classic()

p_hist_2017 <- ggplot(data = age_in_2017_values, aes(value)) + 
  geom_col(mapping = aes(x = value, y = freq), fill = "gray70") + 
  theme_classic()

ggsave(plot = plot_grid(p1, p_hist_max, ncol = 1, nrow = 2, rel_heights = c(1, 0.4)),
       filename = paste0(p_plots, run_label, "/spatial_reg/", 
                         "max_age_duration_w_dist", run_label, site_df$label[9], ".pdf"), 
       width = 6, height = 8.5, units = "in")

ggsave(plot = plot_grid(p_2017, p_hist_2017, ncol = 1, nrow = 2, rel_heights = c(1, 0.4)),
       filename = paste0(p_plots, run_label, "/spatial_reg/", 
                         "age_in_2017_duration_w_dist", run_label, site_df$label[9], ".pdf"), 
       width = 6, height = 8.5, units = "in")


hist(values(max_age_rs), main = "Abandonment length distribution", xlab = "Abandonment duration (years)")

levelplot(max_age_rs, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = BuRdTheme)
levelplot(max_age_rs, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = RdBuTheme)
levelplot(max_age_rs, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = GrTheme)
levelplot(max_age_rs, margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = BTCTheme)#(rev = TRUE))


levelplot(max_age_rs, #margin = list(FUN = 'mean'), #contour=TRUE, 
          par.settings = rev(brewer.pal(n = 9, 'YlGnBu')))
dev.off()
display.brewer.all()

summary(values(max_age_rs))


levelplot(site_r$shaanxi[[1:8]])




# as a function, for each site:
year_or_max <- 2015
site_index <- 9

cc_age_levelplot_hist()

for(i in 1:11) {cc_age_levelplot_hist(site_index = i, year_or_max = "max")}
for(i in 1:11) {cc_age_levelplot_hist(site_index = i, year_or_max = "2017")}


```


```{r load-site-data.tables, include = FALSE}
# -------------------------- data.tables --------------------------- #
b_age <- fread(input = paste0(p_dat_derived, "belarus_age.csv"))
names(b_age)
s_age <- fread(input = paste0(p_dat_derived, "shaanxi_age.csv"))


b_length <- fread(input = paste0(p_dat_derived, "lengths/", "belarus_length_b1.csv"))
s_length <- fread(input = paste0(p_dat_derived, "lengths/", "shaanxi_length_b1.csv"))

b_max_length <- fread(input = paste0(p_dat_derived, "lengths/", "belarus_max_length_b1.csv"))
s_max_length <- fread(input = paste0(p_dat_derived, "lengths/", "shaanxi_max_length_b1.csv"))


# all max_age_dts
max_age_dt_files <- list.files(paste0(p_dat_derived, "/max_age/", run_label), full.names = TRUE) %>%
  grep(".csv", ., value = TRUE)

s_max_age_dt <- fread(input = max_age_dt_files)




# original data
s_dt <- fread(input = paste0(p_dat_derived, "input_data.tables/shaanxi.csv"))
names(s_dt) # <- gsub(pattern = "andcover", replacement = "y", names(s_dt))

b_dt <- fread(input = paste0(p_dat_derived, "input_data.tables/belarus.csv")) # caution - huge file! 8.4 GB at least. 
b_dt <- fread(input = paste0(p_dat_derived, "input_data.tables/belarus.csv"),
              select = 3,
              nrows = 200) # caution - huge file! 8.4 GB at least. 
nrow(b_dt)

env_size(ls())


# -------------------------- summarized data.frames --------------------------- #
indx <- 9
site <- site_df$site[indx] # set site:
site_label <- site_df$label[indx] # set label
blip_label <- "_b1"
load(file = paste0(p_output, "abn_dat_products", blip_label, site_label, ".rds"), verbose = TRUE)

# loads:
area_b1_s
persistence_list_b1_s
abn_area_change_b1_s

# note, on 3/4/21 I made the following changes:
# replace abn_area_change with turnover
# replace abn_area_diff with abn_diff


```

```{r simple-plots}

# -------------------------- plot raw data --------------------------- #
plot(site_r$shaanxi$y1987, main = "Shaanxi 1987", breaks = c(0, plot_cols1$breaks), col = plot_cols1$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols1$name, 
       fill = plot_cols1$color)

plot(b$y2017, main = "Belarus 2017", breaks = c(0, plot_cols$breaks), col = plot_cols$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols$name, 
       fill = plot_cols$color)


plot(bs$y1987, main = "Belarus small 1987", breaks = c(0, 1:4), col = plot_cols)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = names(plot_cols)[1:4], fill = plot_cols[1:4])

plot(bs$y1987, main = "Belarus small 1987", breaks = c(0, plot_cols1$breaks), col = plot_cols1$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols1$name, 
       fill = plot_cols1$color)

# ---------------------- plot abandonment age ---------------------- #
plot(b_age_r$y2017, main = "Belarus Age of Abandonment 2017")
plot(b_age_r[[28:31]])

```

# Spatial predictors of abandonment length and recultivation

*Need: read through papers, sort out my contribution.*
Insert context based on papers by @Estel2015 (recultivation, timing), @Estel2018, @Dara2018 (timing, recultivation, northern Kazakhstan), @Alcantara2013, @Lesiv2018 (methods of mapping), @Smaliychuk2016 (recultivation, predictors, Ukraine), @Prishchepov2013 (predictors), @Baumann2011 (), @Pazur2020 (Slovakia, predictors), @Levers2018a (predictors), @PerpinaCastillo2021 (predictors, model), @Meyfroidt2016 (drivers, tradeoffs, recultivation, timing, Russia/Ukraine/Kazakhstan), @Crouzeilles2020 (Atlantic Forest, predictors)



Question 3: what factors best predict abandonment trajectories?

a. What predicts which pieces of land are abandoned for the longest periods of time? In other words, are some areas more likely to experience more durable abandonment?
    i. Predicting the *max age* of a pixel [or *age in 2017*] using spatial predictor variables like population, slope, elevation, soil, etc.

b. What predicts recultivation? Are less suitable lands recultivated more quickly? Are more recently abandoned lands more frequently recultivated? In other words, does the probability that a piece of abandoned land will be recultivated depend on how long it has been abandoned for?
    i. My sense, from the abandonment decay plots, is that the longer a piece of land is abandoned for (i.e. the greater the greater the *age*), the less likely it is to be recultivated. This will involve predicting recultivation with factors like current age of abandonment, and the other variables included in the primary regression, etc. How will I signify "recultivation" in the dataset? Options include:
        1. data for each transition, each transition from abandoned -> not_abandoned is pulled out, and the age is recorded. This will require some fancy DT wrangling.
        2. all periods of abandonment, including instances when abandoned land remains abandoned (and the age it is), with the cohort, the year, the age, etc.). Each year after a piece of land is defined as abandoned. So, let's say I have a pixel that is in 1995 and stays abandoned for a total of 12 years. This would result in 9 total observations.

c. Taking two steps back - what predicts which pixels of agricultural land are abandoned?

```{r, echo = FALSE}
example_df <- data.frame(cohort = 1995,
           year = 2000:2012,
           age = 5:17,
           abn = c(rep("yes", 8), rep("no", 5)),
           recultivated = c(rep("no", 8), rep("yes", 5)))

example_df[1:9, ]
```

# Predictor variables:

## Brainstorm:

1. Agricultural suitability
    a. *Growing Degree Days* (the cumulative number of degrees above growing threshold accumulated over the course of a growing season. 18 - 10 [threshold] * the number of days at that temp.). See [the University of Wisconsin's website](https://nelson.wisc.edu/sage/data-and-models/atlas/maps.php?datasetid=31&includerelatedlinks=1&dataset=31) for a good description of how GDD works. I plan to make use of GDD above base of 5 degrees C, [from the ENVIREM dataset](http://envirem.github.io/).  
    b. *Soil Quality*: 
        + [ISRIC World Soil Grids](https://www.isric.org/explore/soilgrids), at a resolution of 250 m. Used by @Levers2018a.
        + [Harmonized World Soil Database](https://daac.ornl.gov/SOILS/guides/HWSD.html), which has a resolution of ~ 5.5 km (0.05 degrees). (I plan to use soil organic carbon, soil pH, and soil fertility)
    c. FAO's Global Agro-Ecological Zones (GAEZ), which includes both general natural resource, soil, terrain, slope, elevation, and other types of biophysical data, typically at the scale of 5 arc minutes (~10km at the equator), as well as crop specific suitability maps (e.g. for rain-fed winter wheat). Specifically:
        i. Agro-ecological zones (categories such as: steep terrain, dry/good soils, dry/poor soils, sub-humid/good soils...)
        ii. Soil types
        iii. Workability (categories such as: no constraints, moderate constraints, severe constraints...)
        iv. And more.
    d. [Global inherent land quality map](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/use/worldsoils/?cid=nrcs142p2_054029)
    e. Agricultural opportunity cost (Naidoo & Iwamura 2007)
    f. Travel time to major cites - [Year 2000](https://forobs.jrc.ec.europa.eu/products/gam/), [Year 2015](https://map.ox.ac.uk/research-project/accessibility_to_cities/)
    
2. Environmental factors
    a. Temperature and precipitation (*use GDD, see above, as a nice distillation*). [Possibly helpful how-to](https://www.benjaminbell.co.uk/2018/01/extracting-data-and-making-climate-maps.html)
        i. [Terraclimate](http://www.climatologylab.org/terraclimate.html)
        ii. [Bioclim](https://www.worldclim.org) - ~1km, 1970-2000, [website](https://www.worldclim.org/data/worldclim21.html),
        iii. CHELSA (Swiss Federal Institute for Forest, Snow and Landscape Research WSL) ~1 km, 1979-2013, [CHELSA website](https://chelsa-climate.org/), [Peer reviewed paper, Scientific Data, 2017](https://www.nature.com/articles/sdata2017122)
        iv. Climate Hazards group Infrared Precipitation with States ([CHIRPS](https://www.nature.com/articles/sdata201566))
    b. *Slope, elevation, ruggedness*, and other terrain variables:
        + see what is on GEE!
        + *Ruggedness (Terrain Ruggedness Index)* is a metric of elevation differences between neighboring cells, first derived by @Riley1999. It calculates the "the difference in elevation values from a center cell and eight cells directly surrounding it. Then, the eight elevation differences are squared and averaged. The square root of this average results is a TRI measurement for the center cell" ([see more here](https://community.esri.com/t5/water-resources-blog/terrain-ruggedness-index-tri-and-vector-ruggedness-measurement/ba-p/884340)). Other people use the "vector ruggedness measure," one of the variables supplied by @Amatulli2018.
        + @Amatulli2018 (~1 km, [see earthenv.org](http://www.earthenv.org/topography)), which has a lot of different variables at 1km (elevation, slope, aspect, eastness, northness, roughness, terrain roughness index, topographic position index, vector ruggedness measure)
        + SRTM ~90m, 3 arc seconds (~ 3 / 60 / 60 * 110 * 1000 = `r 3/60/60 * 110 * 1000` at equator) from [EarthEnv](http://www.earthenv.org/DEM)
        + 3 arc second DEM from Jonathan de Ferranti (de Ferranti, J. Digital Elevation Data. Viewfinder Panoramas http://www.viewfinderPanoramas.org/dem3.html (2015). Used in development of WorldPop.
    c. Surrounding landcover, i.e. proximity to woody veg/grassland
        + Distance to grassland
        + Distance to forest
        + Proportion of pixel that is abandoned. If the pixels are aggregated to a coarser scale, from 30m x 30m to 1km x 1km ($1 km^2$), this is the proportion of pixels within that $1 km^2$ that were abandoned at all. This is similar to "Distance to permanently fallowed areas" variable used by @Levers2018a. 
        + Distance to pixels that had experienced abandonment at any point prior to that year.
        
3. Socioeconomic variables:
    a. Population, either from SEDAC (GPW, GRUMP, etc.), WorldPop, or [UN DESA’s World Urbanization Prospects](https://esa.un.org/unpd/wup/)
        + Population rates of change
        + Proportion of population in elderly age class (or average age of population)
        + Population in working age
        + Birth rates
    b. GDP?
    c. Land use decision making, @Malek2020. [download dataset here](https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/JEDNM5). 10 km resolution.

4. Farm management factors:
    a. Field size, from Fritz et al. 2015. This was found by @Levers2018a to be a significant factor (though not the most significant)

### predictors used by other papers:

@Levers2018a explored the following predictors:
1. Area equipped for irrigation
2. Field size.
3. Average livestock density
4. Average yields from grain crops
5. Aridity index (mean annual precip. / mean annual potential evapotranspiration)
6. Growing degree days
7. Soil cation exchange (soil fertility)
8. Distance to forested areas
9. Distance to permanent fallow areas (i.e. areas that were fallow for most of the time series between 2001-2012)
10. Soil organic carbon (overall soil health).
11. Soil pH value.
12. Terrain ruggedness (TRI)
13. Access - travel time to cities with more than 50,000 inhabitants
14. Population density
15. Change in population density from 2001-2006, 2007-2012. 
16. Average unemployment ratio.

@Levers2018a also used a method that allowed the coefficient on each predictor to vary spatially, meaning that something like field size could have a positive effect in the UK, but a negative one in the Alps. In my case, I'll allow for this by allowing for site-level fixed effects. 

@Levers2018a found that the factors that seemed to be the best predictors were (in order):
1. Growing degree days (which varied through space).
2. Field size (which strongly varied through space)
3. Distance to permanently fallowed land.
4. Unemployment
5. Soil pH
6. Soil organic carbon
7. Change in population density
8. Yields.

Note: Pazur et al. (2020, Land) did this for two periods: 1985-2000, 2000-2010, calculating
A. *Percent change in population density* (pop_dens(t+1) - pop_dens(t))/pop_dens(t)
B. age index (pop over 65/pop under 15 * 100)
C. migration (total migration / population for periods 1985-2000, 2000-2010)
D. Proportion of population in working age (working age / total pop) - working age population is defined as those aged 15 to 64 by OECD
E. birth rates.


### Population data sources

SEDAC - Columbia University's CIESIN (Center for International Earth Science Information Network)  
* Gridded Population of the World (GPW v4.11) years *2000, 2005, 2010, 2015, 2020*, ~ 1 km resolution, for 
  + [population density (# people per km$^2$)](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11). 
  + [population counts](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count-rev11)
  + [density adjusted to match UN country totals](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-adjusted-to-2015-unwpp-country-totals-rev11)
  + [counts adj to UN](https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count-adjusted-to-2015-unwpp-country-totals-rev11)
  + [see collection overview (this is SEDAC's flagship data product)](https://beta.sedac.ciesin.columbia.edu/data/collection/gpw-v4)

* Global Rural-Urban Mapping Project (GRUMP) v1, years *1990, 1995, 2000*, at ~ 1 km resolution
  + [population density (population per km$^2$)](https://sedac.ciesin.columbia.edu/data/set/grump-v1-population-density)
  + [population counts](https://beta.sedac.ciesin.columbia.edu/data/set/grump-v1-population-count)

* Global Population Density Grid Time Series back-casts: *1970, 1980, 1990, 2000*, ~ 1km
  + [population density](https://sedac.ciesin.columbia.edu/data/set/popdynamics-global-pop-density-time-series-estimates)
  + [population counts](https://sedac.ciesin.columbia.edu/data/set/popdynamics-global-pop-count-time-series-estimates)

* Global Estimate Net Migration Grids, for *1970, 1980, 1990, 2000*, ~ 1km
  + [download here](https://sedac.ciesin.columbia.edu/data/set/popdynamics-global-est-net-migration-grids-1970-2000)

* SSP Future projections: decadal estimates or projections of urban, rural, and total population at ten-year intervals between *2000-2100* [download from SEDAC here](https://beta.sedac.ciesin.columbia.edu/data/set/popdynamics-1-km-downscaled-pop-base-year-projection-ssp-2000-2100-rev01), based on @Jones2016.


UN DESA  
- future projections of population growth and urbanization from UN DESA’s World Urbanization Prospects [see here](https://esa.un.org/unpd/wup/). Note, this is not a raster, just a spreadsheet with country totals.


WorldPop: high resolution (~100m, 1 km), annually from *2000-2020* - [download at WorldPop.org](https://www.worldpop.org/project/categories?id=3), [scientific data paper](https://www.nature.com/articles/sdata20171).  
* Download individual countries, at either 100m or 1km resolution.
* Like GPW, they have raw counts as well as those that have been adjusted to match UN population estimates from 2019.
* Note: "constrained" vs. "unconstrained" just refers to whether the top-down datasets have been constrained based on satellite image derived maps of the built environment. This data is only available for the year 2020, so I'm going to use the "unconstrained top-down" dataset so that I can use multiple years.
* Top-down vs. bottom-up refers to whether estimates are downscaled from accurate national statistics onto a grid (top-down), or derived from local estimates at particular sample locations scaled up to a grid (bottom-up). I'm using the "top-down" datasets.

#### Pros and Cons:

* WorldPop may be more accurate than GPW, [at least in places like China](https://link.springer.com/article/10.1007/s11111-020-00366-2). However, it only exists for 2000-2020. 
* On the other hand, SEDAC's datasets (GPW/GRUMP) cover the full period from 1970-2020, with consistency across datasets that allows for comparison. 
* Decision: due to the fact that WorldPop only covers the time period from 2000-2020, I will use SEDAC's datasets. 


Other:  
- Human Footprint maybe? No - just use the direct population density.


## My chosen predictors

### Environmental factors
*1. Climate, as proxied by Growing Degree Days above 0 deg C* (cumulative number of degrees above a threshold accumulated over the course of a growing season), data from ENVIREM (http://envirem.github.io/)
- ENVIREM also has GDD 5, Terrain Roughness Index (TRI), Topgraphic Wetness Index (TWI), annualPET, etc.
- See [the University of Wisconsin's website](https://nelson.wisc.edu/sage/data-and-models/atlas/maps.php?datasetid=31&includerelatedlinks=1&dataset=31) for a good description of how GDD works

*2. Precipitation, annual (in mm)*, with data from 

*3. Terrain*, using data from SRTM 30 m via Google Earth Engine (https://developers.google.com/earth-engine/datasets/catalog/USGS_SRTMGL1_003), manipulated with raster::terrain(). Multiple variables include:
a. Elevation
b. Slope
c. Terrain Ruggedness Index (TRI)
d. Topographic Wetness Index

*4. Soil quality*, using data from ISRIC SoilGrids (via Google Earth Engine: https://git.wur.nl/isric/soilgrids/soilgrids.notebooks/-/blob/master/markdown/access_on_gee.md). Specific variables are summed across the topsoil, defined as depth 0-30 cm:
a. Organic carbon stock (OCS)
b. Cation exchange capacity (CEC) at pH7 
c. pH in H2O (phh2o) 

*5. Surrounding landscape*, as measured by the distance from a given pixel to it’s nearest neighbor in to the following groups (alternatively, I could calculate the proportion of surrounding neighborhood, e.g. 1 km2, that is in the following classes):
a) abandoned land
b) forest
c) grassland
d) non-crop land (forest or grassland)

### Agricultural factors

*1. Yield*
a. Current default source is Yield in terms of tons/ha in the year 2000, at a resolution of 10 km x 10 km, from Earth Stat: http://www.earthstat.org/harvested-area-yield-175-crops/. I plan to use data for four major crops (maize, soybean, rice, and wheat), though they have data for 175 crops. (They have Yield (tons per hectare, for 175 crops, average during the 1997-2003 era, and also have Production (tons), Harvested area (proportion, and in ha)).

b. Iizumi & Sakai (2020) also provide annual yield data for 1981-2016, though at a coarser resolution (0.5 degree, ~ 55 km x 55 km). https://www.nature.com/articles/s41597-020-0433-7  

*2. Rate of yield change* (as percent / year over the period 1961-2008, at a resolution of 10 km x 10 km, from Earth Stat: http://www.earthstat.org/yield-trends-changes-maize-soybean-rice-wheat/), for four major crops (maize, soybean, rice, and wheat). They also have yield change as a categorical variable, with 6 classifications: 1 - yields never improved, 2 - yields stagnating, 3 - yields collapsed, 4 - yields improving rapidly, 5 - yields improving moderately, 6 - yields improving slowly. Could also calculate this with the Iizumi & Sakai (2020) dataset.

*3. Fertilizer application rates* for major crops (in kg / ha for the year 2000, at resolution of 10 km x 10 km, from Earth Stat: http://www.earthstat.org/nutrient-application-major-crops/) - they have N, P, and K applied in terms of kg per hectare for 17 major crops, but I’ll focus again on maize, soybean, wheat, and riche. (They also have total N, P, and K fertilizer applied on landscape in kg).

*4. Field size* (Fritz et al. 2015, Global Change Biology: https://onlinelibrary.wiley.com/doi/abs/10.1111/gcb.12838), download through https://application.geo-wiki.org/Application/. 

*5. Share of area equipped for irrigation (%)*, at a resolution of ~10 km, Siebert et al. 2015: https://mygeohub.org/publications/8/2 

### Socioeconomic factors

*1. Population and demography:*
a. Change in population density, as a percent change in people / km. This will be calculated between multiple time periods, with the primary variable being the change between 1980-2020. Derived from SEDAC’s Gridded Population of the World dataset (GPW v4.11), which has years 2000, 2005, 2010, 2015, 2020, at ~ 1 km resolution: https://beta.sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11. For backcast population density in 1970, 1980, 1990, and 2000, see: https://sedac.ciesin.columbia.edu/data/set/popdynamics-global-pop-density-time-series-estimates 

b. Median age class in 2010 (~ 1 km) - derived from GPW v4.11, Basic Demographic Characteristics for marker year 2010.

c. Proportion of population in working age group (15-64), ~ 1 km. Derived from (GPW v4.11).

d. Net Migration in terms of in-migration minus out-migration per 1km pixel, for three periods 1970-80, 1980-90, and 1990-2000, ~1 km resolution: https://sedac.ciesin.columbia.edu/data/set/popdynamics-global-est-net-migration-grids-1970-2000 

e. Net migration as a proportion of the total population in final year of period (derived from population counts in the associated decades from Time Series Back-cast: https://sedac.ciesin.columbia.edu/data/set/popdynamics-global-pop-count-time-series-estimates 

*2. GDP*
a. Change in GDP per capita (in terms of PPP, Purchasing Power Parity), between 1990-2015, at resolution of ~ 10 km (300 arc-sec). Derived from annual data for 1990 through 2015 from Kummu et al. 2018: https://www.nature.com/articles/sdata20184.

b. Change in total GDP (PPP) between 1990 - 2015 (resolution of ~ 1 km or 30 arcsec), derived from Kummu et al. 2018: https://www.nature.com/articles/sdata20184. (Data on total GDP for years 1990, 2000, and 2015 at 1 km resolution)

*3. Travel time to major cities* (> 50,000 people or >1,500 people per km2) in year 2015 (resolution of ~ 1 km), from Oxford MAP project (https://developers.google.com/earth-engine/datasets/catalog/Oxford_MAP_accessibility_to_cities_2015_v1_0).  

*4. Land use decision making* (Malek et al. 2020): six categories of decision-making: 1) The survivalist, 2) The subsistence-oriented smallholder, 3) Market-oriented smallholder, 4) Professional commercialist, 5) Professional intensifier, 6) Eco-agriculturalist. Data from Malek et al. 2020, Global Environmental Change (https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/JEDNM5). 




# Prep predictor data

```{r predictor-files}
p_predictors <- "/Users/christophercrawford/Google Drive/_Projects/data/Abandonment/predictors/"

predictor_files_all <- list.files(p_predictors, full.names = TRUE) 


predictor_files_s <- predictor_files_all %>% 
  grep(paste0(site_df$label[9], ".tif$"), ., value = TRUE)

```


```{r merge-split files}
# Merge raster layers ----

cc_merge_rasters(site = site, 
                 site_df = site_df, 
                 input_path = p_raw_rasters
                 # ^^ this folder must contain folders with site names, 
                 # with either bricks or multiple raster layer files inside
                 )

```

```{r crop-to-sites}
site_r # rasters

pop_density_1970 <- brick(paste0(p_predictors, "pop/pop_density_backcasts/popdynamics-global-pop-density-time-series-estimates_1970.tif"))


```





## Environmental

```{r gdd}
gdd_eurasia <- brick("/Users/christophercrawford/Google Drive/_Projects/data/Abandonment/predictors/gdd/Eurasia_current_30arcsec_geotiff_set2/current_30arcsec_growingDegDays0.tif")

gdd_eurasia

# crop to site location:
gdd_s <- crop(gdd_eurasia, max_age_r$shaanxi)

# resample to match resolution and extent:
gdd0 <- cc_crop_resample_r(input_r = gdd_eurasia)
names(gdd0) <- "gdd0"
plot(gdd0)

# save
writeRaster(gdd0, 
            filename = paste0(p_predictors, "prepped/gdd0", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
gdd0 <- raster(paste0(p_predictors, "prepped/gdd0", site_df$label[9], ".tif"))


gdd_s_ngb <- raster::resample(x = gdd_s, y = max_age_r$shaanxi, method = "ngb")
names(gdd_s_ngb) <- "gdd0"

compareRaster(gdd0, max_age_r$shaanxi)

# save raster:



# other methods of resampling, including with disaggregate
res_factor <- res(gdd_s)[1] / res(max_age_r$shaanxi)[1]

gdd_s_hi <- disaggregate(gdd_s, fact = res_factor)
gdd_s_hi <- crop(gdd_s_hi, max_age_r$shaanxi) # crop again

# resample to match resolution and extent, etc.
gdd_s_bil_hi <- raster::resample(x = gdd_s_hi, y = max_age_r$shaanxi, method = "bilinear")
gdd_s_ngb_hi <- raster::resample(x = gdd_s_hi, y = max_age_r$shaanxi, method = "ngb")
gdd_s_bil <- raster::resample(x = gdd_s, y = max_age_r$shaanxi, method = "bilinear")


# plot the different results
par(mfrow = c(2,3))
plot(gdd_s, main = "original")
plot(gdd_s_bil_hi, main = "bilinear, disagg first")
plot(gdd_s_ngb_hi, main = "ngb, disagg first")
plot(gdd_s_bil, main = "bilinear")
plot(gdd_s_ngb, main = "ngb")


# go with ngb, without resampling first

ncell(gdd_s_bil_hi)
ncell(gdd_s_ngb_hi)
ncell(gdd_s_ngb)
ncell(gdd_s_bil)
ncell(max_age_r$shaanxi)

# histograms:
dev.off()
hist(gdd_s_bil_hi)
hist(gdd_s_ngb_hi)
hist(gdd_s_ngb)
hist(gdd_s_bil)

gdd_s_resample
max_age_r$shaanxi
ncell(max_age_r$shaanxi)
ncell(gdd_s_resample)

plot(gdd_s_resample)
plot(gdd_s_hi)
plot(gdd_s)


```

```{r precip}

extent(cropland_mask_r)

precip <- raster::getData(name = "worldclim", var = "bio", res = 0.5, 
                          lon = 110, lat = 38)

plot(precip$bio12_19)
plot(extent(cropland_mask_r), add = T)

# select just bioclim variable 12, average annual precipitation over the years 1970-2000
# https://www.worldclim.org/data/bioclim.html

precip <- cc_crop_resample_r(
  input_r = precip[[grep("bio12", 
                         names(precip), 
                         value = TRUE)]])

plot(precip)
compareRaster(precip, max_age_r$shaanxi)

# save file ----------------------------------------------- #
names(precip) <- "precip"

writeRaster(precip, 
            filename = paste0(p_predictors, "prepped/precip", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
precip <- brick(paste0(p_predictors, "prepped/precip", site_df$label[9], ".tif"))
names(precip) <- "precip"

```

```{r terrain}
# elevatr:
# install.packages("elevatr")
# library(elevatr)
# srtm1 <- elevatr::get_elev_raster(s, z = 12, clip = "locations")
# object_size(srtm1)
# plot(srtm1)

# srtm <- raster::getData(name = "SRTM", lon = 6, lat = 46)

elevation <- brick(grep("srtm", predictor_files_s, value = TRUE))
elevation <- crop(elevation, max_age_r$shaanxi)
plot(elevation)

terrain <- terrain(elevation$elevation, 
                   opt = c('slope', 'aspect', 'TRI', "TPI", "roughness"), 
                   unit='degrees')

terrain <- stack(elevation, terrain)
names(terrain) # <- c("elevation", "tri", "tpi", "roughness", "slope", "aspect")

plot(elevation)
ncell(elevation)

# save -------------------------------------------------- #
writeRaster(terrain, 
            filename = paste0(p_predictors, "prepped/terrain", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
terrain <- brick(paste0(p_predictors, "prepped/terrain", site_df$label[9], ".tif"))
names(terrain) <- c("elevation", "tri", "tpi", "roughness", "slope", "aspect")



plot(terrain)

ncell(terrain)
ncell(max_age_r$shaanxi)

compareRaster(terrain, max_age_r$shaanxi)
```

```{r soils}

soil_ocs <- brick(grep("soil_ocs", predictor_files_s, value = TRUE))
plot(soil_ocs)

soil_cec_all <- brick(grep("soil_cec", predictor_files_s, value = TRUE))
soil_ph_all <- brick(grep("soil_ph", predictor_files_s, value = TRUE))

# stack
names(soil_ocs)
names(soil_cec)
names(soil_ph)

names(soil_ocs) <- "soil_ocs"

plot(soil_cec_all[[1:3]])
plot(soil_ph_all[[1:3]])



# take mean of top 30 cm

cellStats(soil_ph, max)

tic()
soil_cec <- calc(soil_cec_all[[1:3]], fun = function(x) {mean(x, na.rm = TRUE)})
names(soil_cec) <- "soil_cec"
toc()

plot(soil_cec)
plot(soil_cec_all$cec_0.5cm_mean)


tic()
soil_ph <- calc(soil_ph_all[[1:3]], fun = function(x) {mean(x, na.rm = TRUE)})
names(soil_ph) <- "soil_ph"
toc()

soil_s <- brick(list(soil_ocs, soil_cec, soil_ph))


ncell(soil_s)
ncell(max_age_r$shaanxi)
res(soil_s)
res(max_age_r$shaanxi)

# crop
soil_s <- crop(soil_s, max_age_r$shaanxi)

compareRaster(soil_s, max_age_r$shaanxi)

# write out the soil file:
writeRaster(soil_s, 
            filename = paste0(p_predictors, "prepped/soil", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
soil_s <- brick(paste0(p_predictors, "prepped/soil", site_df$label[9], ".tif"))
names(soil_s) <- c("soil_ocs", "soil_cec", "soil_ph" )
```


### surrounding landscape
```{r lsm-nn}
# nearest neighbor distance:
# see:
# https://r-spatialecology.github.io/landscapemetrics/articles/articles/utility.html#get-nearest-neighbour

# run connected labeling for podlasie raster
patches <- get_patches(landscape, class = 1)[[1]]

# calculate the minimum distance between patches in a landscape
min_dist <- get_nearestneighbour(patches)

# create a function that would do the same with the raster package
nearest_raster_fun <- function(patches) {
    np_class <- patches %>%
        raster::values() %>%
        unique() %>%
        na.omit() %>%
        length()
    
    points_class <- patches %>%
        raster::rasterToPoints() %>%
        tibble::as.tibble() %>%
        purrr::set_names(c("x", "y", "id"))
    
    minimum_distance <- np_class %>%
        seq_len() %>%
        purrr::map_dbl(function(patch_ij) {
            patch_focal <- dplyr::filter(points_class, id == patch_ij)
            
            patch_others <-
                dplyr::filter(points_class, id != patch_ij)
            
            minimum_distance <-
                raster::pointDistance(patch_focal[1:2],
                                      patch_others[1:2],
                                      lonlat = FALSE) %>%
                min()
        })
    
    tibble::tibble(id = unique(sort(points_class$id)),
                   distance = minimum_distance)
    
}


# compare the two implementations
library(bench)
bench::mark(
    get_nearestneighbour(patches)[, 2:3],
    nearest_raster_fun(patches),
    iterations = 100, check = FALSE
)
#> # A tibble: 2 x 6
#>   expression                               min  median `itr/sec` mem_alloc
#>   <bch:expr>                           <bch:t> <bch:t>     <dbl> <bch:byt>
#> 1 get_nearestneighbour(patches)[, 2:3]  4.57ms  4.84ms     203.   273.21KB
#> 2 nearest_raster_fun(patches)          30.11ms 32.66ms      30.0    2.37MB
#> # … with 1 more variable: `gc/sec` <dbl>

# check if results are identical
get_nearestneighbour(patches)[, 2:3] == nearest_raster_fun(patches)
#>         id dist
#>  [1,] TRUE TRUE
#>  [2,] TRUE TRUE
#>  [3,] TRUE TRUE
#>  [4,] TRUE TRUE
#>  [5,] TRUE TRUE
#>  [6,] TRUE TRUE
#>  [7,] TRUE TRUE
#>  [8,] TRUE TRUE
#>  [9,] TRUE TRUE

```

## Ag

```{r yield}
yield_files <- list.files(paste0(p_predictors, "yields/"), recursive = TRUE, full.names = TRUE)

grep("YieldPerHectare.tif$", yield_files, value = TRUE)
yield_coarse <- raster::stack(grep("YieldPerHectare.tif$", yield_files, value = TRUE))
yield_coarse <- crop(yield_coarse, max_age_r$shaanxi)
plot(yield_coarse)

yield_per_ha <- raster::stack(grep("YieldPerHectare.tif$", yield_files, value = TRUE))

yield_per_ha <- cc_crop_resample_r(input_r = yield_per_ha)



plot(yield_per_ha)

ncell(yield_per_ha)
ncell(max_age_r$shaanxi)

compareRaster(yield_per_ha, max_age_r$shaanxi)

# save file ----------------------------------------------- #
names(yield_per_ha) # <- c("maize_YieldPerHectare", "rice_YieldPerHectare", "soybean_YieldPerHectare", "wheat_YieldPerHectare")

writeRaster(yield_per_ha, 
            filename = paste0(p_predictors, "prepped/yield_per_ha", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
yield_per_ha <- brick(paste0(p_predictors, "prepped/yield_per_ha", site_df$label[9], ".tif"))
names(yield_per_ha) <- c("maize_YieldPerHectare", "rice_YieldPerHectare", "soybean_YieldPerHectare", "wheat_YieldPerHectare")

```

```{r yield-change}
grep("YieldTrends", yield_files, value = TRUE)
list.files(paste0(p_predictors, "yields/"))

grep("YieldTrends", yield_files, value = TRUE) %>% 
  grep("percent", ., value = TRUE) %>% 
  grep(".tif$", ., value = TRUE)


yield_change <- stack(grep("YieldTrends", yield_files, value = TRUE) %>% 
  grep("percent", ., value = TRUE) %>% 
  grep(".tif$", ., value = TRUE))

# update names
names(yield_change) <- gsub("percentage_", "yield_change_", 
                            names(yield_change))

yield_change <- cc_crop_resample_r(input_r = yield_change)


compareRaster(yield_change, max_age_r$shaanxi)
plot(yield_change)

# save file ----------------------------------------------- #
names(yield_change) # <- c("yield_change_maize", "yield_change_rice", "yield_change_soy", "yield_change_wheat")

writeRaster(yield_change, 
            filename = paste0(p_predictors, "prepped/yield_change", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
yield_change <- brick(paste0(p_predictors, "prepped/yield_change", site_df$label[9], ".tif"))
names(yield_change) <- c("yield_change_maize", "yield_change_rice", "yield_change_soy", "yield_change_wheat")
```

```{r fertilizer}

fertilizer_files <- list.files(paste0(p_predictors, "yields/", "fertilizer"), full.names = TRUE) %>% 
  grep("Rate.tif$", ., value = TRUE)


fertilizer <- stack(fertilizer_files)
names(fertilizer) <- names(fertilizer) %>%
  gsub("Nitrogen", "N", .) %>%
  gsub("Phosphorus", "P", .) %>%
  gsub("Potassium", "K", .) %>%
  gsub("Application_Rate", "_app_rate", .)
  

fertilizer <- cc_crop_resample_r(input_r = fertilizer)

plot(fertilizer[[3]])


# save file ----------------------------------------------- #
names(fertilizer) # <- c("maize_N_app_rate", "maize_P_app_rate", "maize_K_app_rate", "rice_N_app_rate", "rice_P_app_rate", "rice_K_app_rate", "soybean_N_app_rate", "soybean_P_app_rate", "soybean_K_app_rate", "wheat_N_app_rate", "wheat_P_app_rate", "wheat_K_app_rate")

writeRaster(fertilizer, 
            filename = paste0(p_predictors, "prepped/fertilizer", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
fertilizer <- brick(paste0(p_predictors, "prepped/fertilizer", site_df$label[9], ".tif"))
names(fertilizer) <- c("maize_N_app_rate", "maize_P_app_rate", "maize_K_app_rate", "rice_N_app_rate", "rice_P_app_rate", "rice_K_app_rate", "soybean_N_app_rate", "soybean_P_app_rate", "soybean_K_app_rate", "wheat_N_app_rate", "wheat_P_app_rate", "wheat_K_app_rate")
```

```{r field-size}

field_size <- raster(paste0(p_predictors, "field_size/field_size_10_40_cropland.img"))

names(field_size) <- "field_size"
field_size <- cc_crop_resample_r(input_r = field_size)

plot(field_size)

ncell(field_size)


# save file ----------------------------------------------- #
names(field_size) # <- "field_size"

writeRaster(field_size, 
            filename = paste0(p_predictors, "prepped/field_size", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
field_size <- brick(paste0(p_predictors, "prepped/field_size", site_df$label[9], ".tif"))
names(field_size) <- "field_size"

```


```{r irrigation}
p_dat
hid_file <- paste0(p_dat, "Abandonment/predictors/irrigation/HID_v10/HID_aei_ha.nc")

library(ncdf4)
hid_info <- nc_open(hid_file)

names(hid_info$var)


hid <- brick("/Users/christophercrawford/Google Drive/_Projects/data/Abandonment/predictors/irrigation/HID_v10/HID_aei_ha.nc")

hid
names(hid)

# which layer should I use?  TBD. There are 8 different downscaled versions, of the version based on the subnational data. 

plot(hid$X1)

hid$X1
site_r$shaanxi$y2017
crs(site_r$shaanxi$y2017)

crs(hid$X1) <- crs(site_r$shaanxi$y2017)

plot(hid$X1)

plot(t(hid$X1))

plot(flip(t(hid$X1), direction = "x"))




plot(site_r$shaanxi$y2017)


```

## Socioeconomic

```{r population}
# need five variables:
# a. Change in population density (2020-1980): (pop_dens(2020) - pop_dens(1980))/pop_dens(1980)
# b. Median age class in 2010
# c. Proportion of population in working age group (15-64)
# d. Net Migration in terms of in-migration minus out-migration per 1km pixel, for three periods 1970-80, 1980-90, and 1990-2000,
# e. Net migration as a proportion of the total population in final year of period: net_migration_70_80 / pop_1980, net_migration_80_90 / pop_1990, etc.

gpw <- brick(grep("gpw", predictor_files_s, value = TRUE)) # this data is counts per km2, for the year 2010
pop_count <- brick(grep("pop_count", predictor_files_s, value = TRUE))
pop_density <- brick(grep("pop_density", predictor_files_s, value = TRUE))

gpw <- crop(gpw, max_age_r$shaanxi)
pop_count <- crop(pop_count, max_age_r$shaanxi)
pop_density <- crop(pop_density, max_age_r$shaanxi)

# update names:
names(gpw) <- names(gpw) %>%
  gsub("gpw_v4_basic_demographic_characteristics_rev11_|t_2010_cntm_30_sec_basic_demographic_characteristics", 
       "", .)

names(pop_count) <- names(pop_count) %>%
  gsub("gpw_v4_population_count_rev11_", "y", .) %>%
  gsub("_30_sec_population_count", "", .)

names(pop_density) <- names(pop_density) %>%
  gsub("gpw_v4_population_density_rev11_", "y", .) %>%
  gsub("_30_sec_population_density", "", .)

# plot(pop_count$y2020)

# load back cast pop density:
pop_files <- list.files(paste0(p_predictors, "pop"), recursive = TRUE, full.names = TRUE)
pop_files %>% 
  grep("density",., value = TRUE) %>%
  grep(".tif$",., value = TRUE) %>%
  grep("1980",., value = TRUE)
  
pop_density_backcast <- stack(pop_files %>% 
                            grep("density",., value = TRUE) %>%
                            grep(".tif$",., value = TRUE))
names(pop_density_backcast) <- names(pop_density_backcast) %>%
  gsub("popdynamics.global.pop.density.time.series.estimates", "pop_density_backcast", .)


# load migration
pop_migration <- stack(pop_files %>% 
                         grep("migr",., value = TRUE) %>%
                         grep(".tif$",., value = TRUE))

names(pop_migration) <- names(pop_migration) %>%
  gsub("X30arcsec.net.migration.", "net_migration_", .)

# crop

pop_density_backcast <- cc_crop_resample_r(input_r = pop_density_backcast)
pop_migration <- cc_crop_resample_r(input_r = pop_migration)

plot(pop_density_backcast[[1]])
plot(pop_migration[[1]])

# ------------------------------------------------------------
# a. proportional change in population density: (pop_dens(2020) - pop_dens(1980))/pop_dens(1980)
# ------------------------------------------------------------
plot(pop_density$y2020)
plot(pop_density_backcast$pop_density_backcast_1980)

pop_density_change_80_20 <- 
  (pop_density$y2020 - 
     pop_density_backcast$pop_density_backcast_1980) / 
  pop_density_backcast$pop_density_backcast_1980

names(pop_density_change_80_20) <- "pop_density_change_80_20"

plot(pop_density_change_80_20)

plot(pop_density_backcast$pop_density_backcast_1980)
plot(pop_density$y2020)
(2500- 1000 ) / 1000

# pop_density_change_all <- 
  # brick(
  #   lapply(2:5, function(layer) {
  #     ((pop_density[[layer]] - pop_density[[layer - 1]]) / pop_density[[layer - 1]]) * 100
  #     }
  #     )
  #   )
names(pop_density_change) <- paste0(names(pop_density)[2:5], "_pop_density_change")
plot(pop_density_change)




# ------------------------------------------------------------
# b. calculate median age class at each pixel in 2010:
# ------------------------------------------------------------

# select variables
gpw_age_classes <- names(gpw)[-c(19:20)]

# gee_bands_to_select <- sapply(gpw_age_classes, function(i) grep(i, names(gpw))) %>% as.numeric() - 1
# addl_bands <- sapply(c("a015_064b", "atotpopb"), function(i) grep(i, names(gpw))) %>% as.numeric() - 1


# select only specific age classes:
gpw_select <- gpw[[sapply(gpw_age_classes, function(i) grep(i, names(gpw)))]]

# calculate cumulative sum
gpw_cumulative_sum <- cumsum(gpw_select) # calc(gpw_select, fun = cumsum)

# for each layer in the brick, check if a pixel's value (the cumulative total number of people)
# is less than the median person (cumulative population / 2), then return 1 for TRUE and 0 for FALSE.
# Finally, sum across the brick to calculate, for each pixel, the number of age groups below the median. 
# This means that the next group is the median age group.

median_age_class <- sum(gpw_cumulative_sum < gpw_cumulative_sum[[18]]/2) + 1
names(median_age_class) <- "median_age_class"

plot(median_age_class) # where 7 refers to the 7th age group (one more than the sum), which is the median age group
gpw_age_classes[6:8] # 30-34 years old largely, though 


# ----------------
# alternatively, calculate with data.table (likely to be much faster)
gpw_dt <- gpw_select %>% as.data.table.raster()

# calculate the cumulative sums through age classes
for (i in 3:length(gpw_dt)) {
  gpw_dt[, paste0("cs_age_class_",i-2) := rowSums(.SD), .SDcols = names(gpw_dt)[c(3:i)]]
}

gpw_dt[, names(gpw_dt)[c(3:20)] := NULL] # remove the individual age class totals

# count the pixels for which the cumulative sum 
gpw_dt[cs_age_class_7 > cs_age_class_18/2, .N]

# for loop, counting down from the oldest age class:
# for each class, filter to those pixels with cumulative population greater than the median count at that pixel, 
# and assign a value corresponding to the age class.
# This ensures that the group column has the value corresponding to the median age class at each pixel.
for (i in 18:1) {
  gpw_dt[get(names(gpw_dt)[i+2]) > cs_age_class_18/2, age_class := i]
}
gpw_dt[, .N, by = age_class] # show number of pixels across different median age groups

median_age_class_dt <- dt_to_raster(gpw_dt[, .(x, y, age_class)], CRSobj = crs("+proj=longlat +datum=WGS84 +no_defs"))
plot(median_age_class_dt)




# ------------------------------------------------------------
# c. working age population (defined as those aged 15 to 64 (OECD))
# ------------------------------------------------------------
working_age_pop <- gpw[["a015_064b"]]/gpw[["atotpopb"]] # proportion of total population that is working age (15-64)
names(working_age_pop) <- "working_age_pop"


# ------------------------------------------------------------
# d. net_migration
# d. Net Migration in terms of in-migration minus out-migration per 1km pixel, for three periods 1970-80, 1980-90, and 1990-2000
# ------------------------------------------------------------
plot(pop_migration$net_migration_1970.1980)
names(pop_migration)

# ------------------------------------------------------------
# e. prop_migration
# e. Net migration as a proportion of the total population in final year of period: net_migration_70_80 / pop_1980, net_migration_80_90 / pop_1990, etc.
# ------------------------------------------------------------
names(pop_density_backcast)

pop_migration_prop_80 <- pop_migration$net_migration_1970.1980 / pop_density_backcast$pop_density_backcast_1980

pop_migration_prop_90 <- pop_migration$net_migration_1980.1990 / pop_density_backcast$pop_density_backcast_1990

pop_migration_prop_00 <- pop_migration$net_migration_1990.2000 / pop_density_backcast$pop_density_backcast_2000

pop_migration_prop <- brick(list(pop_migration_prop_80,
                                 pop_migration_prop_90,
                                 pop_migration_prop_00))
names(pop_migration_prop) <- c("net_migration_prop_1980", "net_migration_prop_1990", "net_migration_prop_2000")


# ------------------------------------------------------------------------------- #
# combine into a single brick, then turn into a data.table:

pop <- brick(
  list(pop_density_change_80_20, 
       median_age_class, 
       working_age_pop,
       pop_migration,
       pop_migration_prop
       )
)

names(pop)

# save file ----------------------------------------------- #
names(pop) # <- c("pop_density_change_80_20", "median_age_class", "working_age_pop", "net_migration_1970.1980", "net_migration_1980.1990", "net_migration_1990.2000", "net_migration_prop_1980", "net_migration_prop_1990", "net_migration_prop_2000")

writeRaster(pop, 
            filename = paste0(p_predictors, "prepped/pop", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
pop <- brick(paste0(p_predictors, "prepped/pop", site_df$label[9], ".tif"))
names(pop) <- c("pop_density_change_80_20", "median_age_class", "working_age_pop", "net_migration_1970.1980", "net_migration_1980.1990", "net_migration_1990.2000", "net_migration_prop_1980", "net_migration_prop_1990", "net_migration_prop_2000")


rm(pop_density, pop_count, pop_brick)
rm(pop_density_1980, pop_density_backcast, pop_density_change_80_20, pop_migration, pop_migration_prop_80, pop_migration_prop_90, pop_migration_prop_00)

rm(pop_migration_prop, median_age_class, working_age_pop)

env_size(ls())

plot(pop$net_migration_1970.1980)
plot(pop$net_migration_1980.1990)
plot(pop$net_migration_1990.2000)


plot(pop$pop_density_change_80_20, main = "Pop. Dens. Change (2020-1980)/1980")
plot(pop$net_migration_1970.1980, main = "Net migration '70-'80")
plot(pop$net_migration_1980.1990, main = "Net migration '80-'90")
plot(pop$net_migration_1990.2000, main = "Net migration '90-'00")


plot(pop$net_migration_prop_1980, main = "Net migration prop 1980")
plot(pop$net_migration_prop_1990, main = "Net migration prop 1990")
plot(pop$net_migration_prop_2000, main = "Net migration prop 2000")
plot(predictors_brick$gdp_per_capita_change, main = "GDP per capita change")

```



```{r gdp}
# two variables:
# a. Change in GDP per capita (in terms of PPP, Purchasing Power Parity), between 1990-2015, at resolution of ~ 10 km (300 arc-sec). Derived from annual data for 1990 through 2015 from Kummu et al. 2018: https://www.nature.com/articles/sdata20184.
# 
# b. Change in total GDP (PPP) between 1990 - 2015 (resolution of ~ 1 km or 30 arcsec), derived from Kummu et al. 2018: https://www.nature.com/articles/sdata20184. (Data on total GDP for years 1990, 2000, and 2015 at 1 km resolution)

gdp_files <- list.files(paste0(p_predictors, "kummu2018"), full.names = TRUE)
gdp_files %>% 
  grep("GDP_per_capita", ., value = TRUE) %>%
  grep("pedigree", ., value = TRUE, invert = TRUE)

library(ncdf4)
gdp_info <- nc_open(gdp_files %>% 
                      grep("GDP_per_capita", ., value = TRUE) %>%
                      grep("pedigree", ., value = TRUE, invert = TRUE))

gdp_per_capita
gdp_total

names(gdp_info$var)

# ------------------------------------------------------------
# a. proportional change in gdp per capita (PPP): (gdp_per_capita$y2015 - gdp_per_capita$y1990) / gdp_per_capita$y1990
# ------------------------------------------------------------
gdp_per_capita <- brick(gdp_files %>% 
                          grep("GDP_per_capita", ., value = TRUE) %>%
                          grep("pedigree", ., value = TRUE, invert = TRUE))

names(gdp_per_capita) <- gsub("X", "y", names(gdp_per_capita))

gdp_per_capita_change <- (gdp_per_capita$y2015 - gdp_per_capita$y1990)/gdp_per_capita$y1990

plot(gdp_per_capita$y1990)
plot(gdp_per_capita$y2015)
plot(gdp_per_capita_change)

# crop and stuff:
gdp_per_capita_change <- cc_crop_resample_r(input_r = gdp_per_capita_change)
plot(gdp_per_capita_change)

names(gdp_per_capita_change)
names(gdp_per_capita_change) <- "gdp_per_capita_change"


# ------------------------------------------------------------
# b. proportional change in gdp per capita (PPP): 
# ------------------------------------------------------------
# b. Change in total GDP (PPP) between 1990 - 2015 (resolution of ~ 1 km or 30 arcsec). (Data on total GDP for years 1990, 2000, and 2015 at 1 km resolution). Calculated as follows (gdp_total$y2015 - gdp_total$y1990)/gdp_total$y1990
gdp_total <- brick(gdp_files %>% grep("GDP_PPP_30arcsec", ., value = TRUE))
names(gdp_total) <- gsub("X", "y", names(gdp_total))

plot(gdp_total$y1990)
plot(gdp_total$y2015)

# crop and resample:
gdp_total <- cc_crop_resample_r(input_r = gdp_total)

gdp_total_change <- (gdp_total$y2015 - gdp_total$y1990) / gdp_total$y1990

plot(gdp_total_change)

names(gdp_total_change)
names(gdp_total_change) <- "gdp_total_change"

gdp <- brick(list(gdp_per_capita_change, gdp_total_change))

names(gdp) # <- c("gdp_per_capita_change", "gdp_total_change")
# save file ----------------------------------------------- #
names(gdp) # <- c("gdp_per_capita_change", "gdp_total_change")

writeRaster(gdp, 
            filename = paste0(p_predictors, "prepped/gdp", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
gdp <- brick(paste0(p_predictors, "prepped/gdp", site_df$label[9], ".tif"))
names(gdp) <- c("gdp_per_capita_change", "gdp_total_change")


```

```{r accessibility}
accessibility_2015 <- brick(grep("travel", predictor_files_s, value = TRUE))
ncell(accessibility_2015)

accessibility_2015 <- crop(accessibility_2015, max_age_r$shaanxi)
plot(accessibility_2015)

names(accessibility_2015)

compareRaster(accessibility_2015, max_age_r$shaanxi)

# save file ----------------------------------------------- #
writeRaster(accessibility_2015, 
            filename = paste0(p_predictors, "prepped/accessibility_2015", site_df$label[9], ".tif"),
            overwrite = TRUE)

# reload
accessibility_2015 <- brick(paste0(p_predictors, "prepped/accessibility_2015", site_df$label[9], ".tif"))

```

```{r land-use-decision-making}
lu_decision <- raster(paste0(p_predictors, "malek2020/categorical_types.tif"))
names(lu_decision) <- "lu_decision"
plot(lu_decision)

lu_decision <- cc_crop_resample_r(input_r = lu_decision)

plot(lu_decision)

# no values!

```







# Prep data for regression

```{r make-predictor-brick}

gdd0
terrain
soil_s

yield_per_ha
yield_change
fertilizer
field_size

pop
names(pop)
gdp
accessibility_2015

names(pop)
# ---------------------------------------------------- #
# make predictors brick
# ---------------------------------------------------- #
predictors_brick <- stack(list(max_age_r$shaanxi,
                               gdd0, precip,
                               terrain, #[[c("elevation", "slope", "tri")]], 
                               soil_s,
                               yield_per_ha, yield_change, 
                               fertilizer, 
                               field_size, 
                               pop, #[[c("pop_density_change_80_20", "median_age_class", "working_age_pop", "net_migration_1970.1980", "net_migration_1980.1990", "net_migration_1990.2000")]], 
                               gdp, 
                               accessibility_2015
                               ))

nlayers(predictors_brick)

# reset names:
names(predictors_brick) <- names(predictors_brick) %>% gsub("_s$", "", .)

plot(predictors_brick$soil_ocs)



# ---------------------------------------------------- #
# convert brick to data.table:
# ---------------------------------------------------- #
tic()
predictors_dt <- as.data.table.raster(predictors_brick)
toc() # takes 1220 seconds (20 minutes) for Shaanxi, which is the smallest size, by about 5 times
# better to simply extract points from the predictor brick, then using that directly.

object_size(predictors_dt)

names(predictors_dt) #<- c("x", "y", "max_age", "gdd0", "elevation", "slope", "tri",
# "soil_ocs", "soil_cec", "soil_ph",
# "maize_YieldPerHectare", "rice_YieldPerHectare", "soybean_YieldPerHectare",
# "wheat_YieldPerHectare", "yield_change_maize",
# "yield_change_rice", "yield_change_soy", "yield_change_wheat", "field_size",
# "pop_density_change_80_20", "median_age_class", "working_age_pop",
# "net_migration_1970.1980", "net_migration_1980.1990", "net_migration_1990.2000",
# "gdp_per_capita_change", "gdp_total_change", "accessibility_2015")


# save data.table
fwrite(predictors_dt, file = paste0(p_predictors, "prepped/predictor_dt", site_df$label[9],".csv"))

predictors_dt <- fread(input = paste0(p_predictors, "prepped/predictor_dt", site_df$label[9],".csv"))
names(predictors_dt)

nrow(predictors_dt)



# ---------------------------------------------------- #
# 2 response variables: 
# a) is a pixel abandoned or not (1 or 0), and 
# b) maximum time abandoned for each pixel
# ---------------------------------------------------- #

predictors_dt[max_age >= 5, abn_bin := 1
              ][max_age < 5, abn_bin := 0]

predictors_dt[, .N, by = abn_bin]

object_size(predictors_dt)

predictors_dt[!is.na(abn_bin), .N] # number of rows that are not NA

predictors_dt <- predictors_dt[!is.na(abn_bin), ]


predictors_dt


```


My sample should be which of the following?

1. Only land that is abandoned? What predicts how long is abandoned for?
2. Only land that could be abandoned (i.e. cropland at some point during the time series)? In other words, should we exclude land that stays in forest throughout the time series? Including consistently forested land might confuse the regression. Imagine that forests are already more likely to be in worse areas for farming... but if they show up as "not abandoned," then we might see these areas as being less likely to be abandoned, though that isn't really the case.


Workflow:
1. Add id column "key := 1:.N", then set as key for faster indexing. Or, can I just join by x and y?
2. Identify any pixels that contain cropland at any point in the time series.
3. Add a column indicating cropland_mask, and remove all other columns other than x, y, and cropland_mask
4. Join this to the abn_age_dt (or predictor_dt).
5. Remove the non cropland_mask rows
6. Set all rows in the cropland_mask that are *not* abandoned during the time series (i.e. age < 5, or NA), and set them to 0. 

```{r select-potentially-abandoned-land}
nrow(predictors_dt)
nrow(s_max_age_dt)
ncell(predictors_brick)
ncell(age_r$shaanxi)
ncell(max_age_r$shaanxi)

env_size(ls())

predictors_dt
object_size(s_dt)

s_max_age_dt

s_dt[, .N, by = y1987]

s_dt[y1987 == 3 | y1988 == 3, ]

# select rows containing cropland in any year, and give them a value of 1 in new column "cropland_mask"
tic()
s_dt[y1987 == 3 | y1988 == 3 | y1989 == 3 | 
       y1990 == 3 | y1991 == 3 | y1992 == 3 | y1993 == 3 | y1994 == 3 | 
       y1995 == 3 | y1996 == 3 | y1997 == 3 | y1998 == 3 | y1999 == 3 | 
       y2000 == 3 | y2001 == 3 | y2002 == 3 | y2003 == 3 | y2004 == 3 | 
       y2005 == 3 | y2006 == 3 | y2007 == 3 | y2008 == 3 | y2009 == 3 | 
       y2010 == 3 | y2011 == 3 | y2012 == 3 | y2013 == 3 | y2014 == 3 | 
       y2015 == 3 | y2016 == 3 | y2017 == 3, 
       cropland_mask := 1]
toc()

s_dt[cropland_mask == 1, ]

# remove all other columns:
s_dt[, paste0("y", 1987:2017) := NULL]
crop_dt <- copy(s_dt)
rm(s_dt)

crop_dt
predictors_dt

# checking the rows:
predictors_dt[max_age > 0, .N] # 7,376,930
predictors_dt[max_age >= 5, .N] # 5,158,673
s_max_age_dt[max_age >= 5, .N] # 5,158,673. Glad they match.
crop_dt[cropland_mask == 1, .N] # 12,856,128 rows are cropland at least for one year during the time series.


# merge cropland_mask column to the predictors_dt, based on the x and y coordinates, 
# saving only those rows in area_dt that match abn_age_dt and land_cover_dt, respectively:
nrow(predictors_dt)
nrow(crop_dt)

predictors_dt <- merge(x = predictors_dt, y = crop_dt, all.x = TRUE, 
                      by = c("x","y"), sort = FALSE)

predictors_dt

cropland_mask_r <- dt_to_raster(crop_dt, crs("+proj=longlat +datum=WGS84 +no_defs"))
plot(cropland_mask_r, col = "red")
plot(max_age_r$shaanxi, add = TRUE)

predictors_dt[cropland_mask > 0, .N] # 12,856,128
predictors_dt[max_age >= 5, .N] # 5,158,673
predictors_dt[, .N, by = max_age][order(max_age)]


# 5. Remove the non cropland_mask rows


# 6. Set all rows in the cropland_mask that are *not* abandoned during the time series (i.e. age = NA), and set their max_age = 0. 
predictors_dt[cropland_mask > 0 & is.na(max_age), max_age := 0]


```




```{r test-random-sample-grid}
sample_grid

test <- aggregate(max_age_r$shaanxi, fact = 10, fun = mean)
plot(test)
cellStats(max_age_r$shaanxi, summary)

ncell(max_age_r$shaanxi)
sampleRandom()

library(raster)
r <- raster(ncol = 10, nrow = 10, 
            # xmx = -80, xmn = -150, 
            # ymn = 20, ymx = 60    
            xmn = 0, xmx = 10, 
            ymn = 0, ymx = 10
            )
values(r) <- runif(ncell(r))

plot(r)
res(r)

grid <- raster(extent(r))
res(grid) <- 2
proj4string(grid)<- proj4string(r)
gridpolygon <- rasterToPolygons(grid)
gridpolygon_sf <- rasterToPolygons(grid) %>% st_as_sf

# random sample from sf polygons:
ptss_sf <- st_sample(gridpolygon_sf$geometry, size = rep(2, nrow(gridpolygon_sf)), type = "random")

plot(ptss_sf)
plot(gridpolygon_sf, add = T)

plot(r)
plot(gridpolygon, add = T)
plot(gridpolygon)

# pick random points per each grid cell and plot
set.seed(7234)
random_points <- gridpolygon@polygons %>%
  lapply(spsample, n = 1, type = "random") %>%
  lapply(st_as_sf) %>% bind_rows()


plot(r)
plot(random_points, add = T, pch = 3)

# extract raster values, to a data.frame
extracted_values <- raster::extract(x = r, y = random_points, 
                                    cellnumbers = TRUE, df = TRUE) %>%
  rename(value = layer)

# from this, I can either select a subset of a data.table directly, or
# copy the raster, set all unselected cells to NA, then convert that to a data.table, and remove NAs again. I think the first method is probably fastest.

# make sure the cell number is specified in the data.table 
r_dt <- as.data.table.raster(r)
r_dt[, cell := 1:.N]

r_dt[cell %in% extracted_values$cells, ] # select by cell number:



# select by raster
r_selection <- r
r_selection[!r_selection %in% extracted_values$value] <- NA
plot(r_selection)

r_select_dt <- as.data.table.raster(r_selection)
r_select_dt[!is.na(layer), ]
```


```{r random-sample-grid}
# ---------------------------------------------------- #
# try this for shaanxi province, at a scale of 1 km grid:
# ---------------------------------------------------- #
res(cropland_mask_r)
sapply(site_r, res)
cropland_mask_r
predictors_brick
res(predictors_brick)

# resolution in degrees to m
res(predictors_brick)[1] * 111 * 1000 # in shaanxi, it's probably closer to 98 km per degree. 

# converting resolution to a specified grid size: 30 m to 0.5 km (500 m) grid
500/30 # 16.667
# or a 2 km grid?
2000/30 # 66.67
raster::area(grid)

new_resolution <- res(cropland_mask_r)[1] * 500/30


# make grid at specified resolution, convert from raster to polygons
grid <- raster(extent(cropland_mask_r),
               crs = crs(cropland_mask_r),
               resolution = new_resolution)

grid_poly <- rasterToPolygons(grid)

# pick random points per each grid cell and plot
set.seed(4949)
tic()
random_points <- grid_poly@polygons %>%
  lapply(spsample, n = 1, type = "random") %>%
  lapply(st_as_sf) %>% bind_rows()
toc() # 544 seconds (9 min) at 0.5 km grid resolution


# extract raster values, to a data.frame
tic()
extracted_values <- 
  raster::extract(x = predictors_brick, 
                  y = random_points, 
                  cellnumbers = TRUE, df = TRUE) %>%
  as_tibble()
toc() # 139 seconds for the 0.5 km grid for full predictors_brick

# ----------------------------------------------------- #
# rather than converting the brick to data.tables, just leave it as a brick through the random sampling stage - it's much, much faster.  That does mean I'll have to add in the x and y coordinates manually, but that's easy
# ----------------------------------------------------- #
sample_df <- extracted_values %>%
  mutate(x = st_coordinates(random_points)[, "X"],
         y = st_coordinates(random_points)[, "Y"]) %>%
  select(x, y, everything())

# but this is the point x and y coordinate, which won't match exactly the data.table x and y...
tic()
xy_coord <- as.data.table.raster(cropland_mask_r)
toc()

xy_coord[extracted_values$cells, x]

# merge columns:
sample_df <- extracted_values %>%
  mutate(x = xy_coord[extracted_values$cells, x],
         y = xy_coord[extracted_values$cells, y],
         cropland_mask = xy_coord[extracted_values$cells, cropland_mask]) %>%
  select(x, y, cropland_mask, everything()) %>%
  as.data.table()
  
  


# using the data.table route... with the extracted_values data.frame, I can either select a subset of a data.table directly (making sure that the predictors_dt data.table has had the max_age updated based on potentially abandonable land (i.e. cropland at some point))
extracted_values_all$cells
extracted_values$cells

tic()
sampled_dt <- predictors_dt[extracted_values$cells, ]
toc() # 4 seconds to select


sampled_dt[, .N]
sampled_dt[max_age > 5, .N]
sampled_dt[!is.na(max_age), .N]

sample_df$x[1:6]
sampled_dt$x[1:6]

sample_df[1:6, 9]
sampled_dt[1:6, 7]
```


```{r random-sample-dt}
# hmm.... it takes a very long time. Might be worth writing a function to split the data.table into chunks, and randomly select one row from within that chunk
test <- predictors_dt[, .(x, y, slope)]

test[, x][1] + res(predictors_brick)[1]*3
# new resolution is:
res(cropland_mask_r)[1] * 100 #500/30

# so, I want to look within a window of x + res(cropland_mask_r)[1] * 500/30 and y + res(cropland_mask_r)[1] * 500/30

test[1, x]
for (i in 1:50) {
  test[x >= test[1, x] + new_resolution*(i-1) & 
       x < test[1, x] + new_resolution*(i) &
       y <= test[1, y] - new_resolution*(i-1) & 
       y > test[1, y] - new_resolution*(i), group := i]}

set.seed(2342)
dt_sample <- test[!is.na(group),][, selection := sample(.N, 1), by = group]
test[dt_]


dt_sample <- test[, sample(.I, 1), by = group]
dt_sample[[2]]

test_dt_r <- dt_to_raster(test[dt_sample[[2]], ], crs("+proj=longlat +datum=WGS84 +no_defs"))

test[dt_sample[[2]], ]
test[test[, sample(.I, 2), by = group][[2]],]


test[,.N, by = group]

# 272 cell in the range... is that how many cells should be in the new resolution?
(500/30)^2 * 5

test[, min(x)]


plot(random_points, add = T, pch = 3)
```


```{r aggregate-testing-predictors}
res(yield_coarse) / res(predictors_brick)

plot(yield_coarse)
plot(predictors_brick$maize_YieldPerHectare)

spatdat
spatdat <- aggregate(predictors_brick, fact = 100, fun = mean)

plot(spatdat$soil_ocs)
plot(spatdat$max_age)
plot(spatdat$gdd0)

plot(spatdat$maize_YieldPerHectare)
plot(spatdat$max_age)
plot(spatdat$net_migration_1990.2000)
names(spatdat)

gg_sp_coef_scaled


object_size(spatdat)
plot(spatdat)

spatdat_dt <- as.data.table.raster(spatdat)


# make into a data.table:
```

```{r distributions}

hist(spatdat$max_age)
hist()

hist(spatdat_dt[, max_age])



```

```{r plot-predictors}
predictors_brick

pdf(file = paste0(p_output, "plots/", run_label, "/spatial_reg/", "predictors_panel_3.pdf"),
      width = 10, height = 9)

par(mfrow = c(4,4),
    oma = c(0,0,0,1))

# plot(predictors_brick[[1:16]])
# plot(predictors_brick[[17:32]])
plot(predictors_brick[[33:45]])

dev.off()
```


# Run Regression

```{r logistic-regression}

```

```{r regression-sampled}
names(sampled_dt)


sample_df_scaled <- copy(sample_df)
sampled_dt_scaled <- copy(sampled_dt)

names(sampled_dt_scaled)

cols_to_scale <- 
  names(sample_df_scaled) %>%
  grep("^x$|^y$|max_age|cropland_mask|ID|cells", ., value = TRUE, invert = TRUE)

sampled_dt_scaled[, c(cols_to_scale) := lapply(.SD, scale_this), .SDcols = cols_to_scale]

sample_df_scaled[, c(cols_to_scale) := lapply(.SD, scale_this), .SDcols = cols_to_scale]

sp_lm_500m_sample <- lm(formula = max_age ~ x + y + 
                        gdd0 + precip +
                          elevation + slope + tri +
                        soil_ocs + soil_cec + soil_ph + 
                        maize_YieldPerHectare + 
                        yield_change_maize +
                         #maize_N_app_rate + maize_P_app_rate + maize_K_app_rate +
                        # rice_YieldPerHectare +
                        # wheat_YieldPerHectare +
                        # soybean_YieldPerHectare +
                        field_size + 
                        pop_density_change_80_20 + 
                        # net_migration_1970.1980 + 
                          net_migration_prop_1980 + net_migration_prop_1990 + net_migration_prop_2000 +
                        #net_migration_1980.1990 +
                        #net_migration_1990.2000 +
                        working_age_pop + median_age_class +
                        gdp_per_capita_change + gdp_total_change +
                        accessibility_2015,
               data = sample_df_scaled #sampled_dt_scaled
            )
plot(sp_lm_500m_sample, 1)
plot(sp_lm_500m_sample, 2)


# rename coefficients:
sp_coefs_500m_sample <- 
  tidy(sp_lm_500m_sample, conf.int = TRUE) %>%
  mutate(term_new = ifelse(term == "gdd0", "Growing Deg. Days (0 °C)",
                    ifelse(term == "precip", "Precipitation",
                     ifelse(term == "elevation", "Elevation",
                      ifelse(term == "slope", "Slope",
                       ifelse(term == "soil_ocs", "Soil Organic Content",
                       ifelse(term == "soil_cec", "Soil Cation Exchange Capacity",
                       ifelse(term == "soil_ph", "Soil pH",
                        ifelse(term == "maize_YieldPerHectare", "Maize Yield (kg/ha)",
                        ifelse(term == "yield_change_maize", "Maize Yield Change (%/yr)",
                         ifelse(term == "pop_density_change_80_20", "Change in Pop. Density ('80-'20)",
                          ifelse(term == "net_migration_1970.1980", "Net Migration ('70-'80)",
                          ifelse(term == "working_age_pop", "Working Age Pop.",
                          ifelse(term == "median_age_class", "Median Age Class",
                          ifelse(term == "gdp_per_capita_change", "Change in GDP Per Capita",
                          ifelse(term == "gdp_total_change", "Change in Total GDP",
                          ifelse(term == "accessibility_2015", "Accessibility (2015)",
                                                                     term)))))))))))))))))

# plot the coefficients:
# gg_sp_coefs_500m_sample <-
  ggplot(data = sp_coefs_500m_sample %>% 
           filter(!term %in% c("(Intercept)", "x", "y")),
         mapping = aes(x = estimate, y = fct_reorder(term_new, desc(estimate)))) + 
  theme_classic() +
  geom_point() + 
  geom_errorbar(mapping = aes(xmin = conf.low, xmax = conf.high), width = 0.3) + 
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Mean Coefficients (Scaled)", y = "Predictor", 
       color = "Model specification",
       caption = "Sampled on 0.5 km grid") #+ 
  # facet_wrap(cols = vars(term), switch = "y",
  #            scales = "free")


# save plot  
ggsave(plot = gg_sp_coef_scaled_full, 
       filename = paste0(p_plots, run_label, "/spatial_reg/", "lm_coef_scaled_full", #run_label,
                         ".pdf"), 
       width = 6, height = 4, units = "in")
```

```{r olsrr-sampled}
model <- sp_lm_500m_sample

install.packages("olsrr")
library(olsrr)
ols_coll_diag(model)

ols_step_both_p(model)
ols_plot_diagnostics(model)

glance(model)
kable(tidy(model, conf.int = TRUE), digits = 2, align = 'c',caption = "Test table")

```


```{r regression-all-pixels}

sp_lm_xy_scaled_full <- lm(formula = max_age ~ x + y + 
                        scale(gdd0) + scale(elevation) + scale(slope) + 
                        scale(soil_ocs) + scale(soil_cec) + scale(soil_ph) + 
                        scale(maize_YieldPerHectare) + 
                        scale(yield_change_maize) +
                        # scale(rice_YieldPerHectare) +
                        # scale(wheat_YieldPerHectare) +
                        # scale(soybean_YieldPerHectare) +
                        scale(pop_density_change_80_20) + 
                        scale(net_migration_1970.1980) +
                        # scale(net_migration_1980.1990) +
                        # scale(net_migration_1990.2000) +
                        scale(working_age_pop) + scale(median_age_class) +
                        scale(gdp_per_capita_change) + scale(gdp_total_change) +
                        scale(accessibility_2015),
               data = predictors_dt
            )

plot(sp_lm_xy_scaled_full, 1)


# inspect the coefficients:
tidy(sp_lm_xy_scaled_full, conf.int = TRUE)


# rename coefficients:
sp_coefs_scaled_full <- 
  tidy(sp_lm_xy_scaled_full, conf.int = TRUE) %>%
  mutate(term_new = ifelse(term == "scale(gdd0)", "Growing Deg. Days (0 °C)",
                     ifelse(term == "scale(elevation)", "Elevation",
                      ifelse(term == "scale(slope)", "Slope",
                       ifelse(term == "scale(soil_ocs)", "Soil Organic Content",
                       ifelse(term == "scale(soil_cec)", "Soil Cation Exchange Capacity",
                       ifelse(term == "scale(soil_ph)", "Soil pH",
                        ifelse(term == "scale(maize_YieldPerHectare)", "Maize Yield (kg/ha)",
                        ifelse(term == "scale(yield_change_maize)", "Maize Yield Change (%/yr)",
                         ifelse(term == "scale(pop_density_change_80_20)", "Change in Pop. Density ('80-'20)",
                          ifelse(term == "scale(net_migration_1970.1980)", "Net Migration ('70-'80)",
                          ifelse(term == "scale(working_age_pop)", "Working Age Pop.",
                          ifelse(term == "scale(median_age_class)", "Median Age Class",
                          ifelse(term == "scale(gdp_per_capita_change)", "Change in GDP Per Capita",
                          ifelse(term == "scale(gdp_total_change)", "Change in Total GDP",
                          ifelse(term == "scale(accessibility_2015)", "Accessibility (2015)",
                                                                     term))))))))))))))))

# plot the coefficients:
gg_sp_coef_scaled_full <-
  ggplot(data = sp_coefs_scaled_full %>% 
           filter(!term %in% c("(Intercept)", "x", "y")),
         mapping = aes(x = estimate, y = fct_reorder(term_new, desc(estimate)))) + 
  theme_classic() +
  geom_point() + 
  geom_errorbar(mapping = aes(xmin = conf.low, xmax = conf.high), width = 0.3) + 
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Mean Coefficients (Scaled)", y = "Predictor", 
       color = "Model specification") #+ 
  # facet_wrap(cols = vars(term), switch = "y",
  #            scales = "free")


# save plot  
ggsave(plot = gg_sp_coef_scaled_full, 
       filename = paste0(p_plots, run_label, "/spatial_reg/", "lm_coef_scaled_full", #run_label,
                         ".pdf"), 
       width = 6, height = 4, units = "in")

```


```{r run-regression-small}
names(predictors_dt)

sp_lm <- lm(formula = max_age ~ #x + y + 
              gdd0 + elevation + slope + soil_ocs + 
              maize_YieldPerHectare +
              pop_density_change_80_20 + net_migration_1990.2000 +
              working_age_pop + median_age_class +
              gdp_per_capita_change + accessibility_2015,
            data = spatdat_dt #predictors_dt[1:10000, ]
            )

sp_lm_xy <- lm(formula = max_age ~ x + y + 
                 gdd0 + elevation + slope + soil_ocs + 
                 maize_YieldPerHectare +
                 pop_density_change_80_20 + net_migration_1990.2000 +
                 working_age_pop + median_age_class +
                 gdp_per_capita_change + accessibility_2015,
               data = spatdat_dt #predictors_dt[1:10000, ]
            )

sp_lm_xy_scaled <- lm(formula = max_age ~ x + y + 
                        scale(gdd0) + scale(elevation) + scale(slope) + 
                        scale(soil_ocs) + scale(soil_cec) + scale(soil_ph) + 
                        scale(maize_YieldPerHectare) + 
                        scale(yield_change_maize) +
                        # scale(rice_YieldPerHectare) +
                        # scale(wheat_YieldPerHectare) +
                        # scale(soybean_YieldPerHectare) +
                        scale(pop_density_change_80_20) + 
                        scale(net_migration_1970.1980) +
                        # scale(net_migration_1980.1990) +
                        # scale(net_migration_1990.2000) +
                        scale(working_age_pop) + scale(median_age_class) +
                        scale(gdp_per_capita_change) + scale(gdp_total_change) +
                        scale(accessibility_2015),
               data = spatdat_dt #predictors_dt[1:10000, ]
            )



summary(sp_lm)

plot(sp_lm, 1)
plot(sp_lm_xy, 1)
plot(sp_lm_xy_scaled, 1)
par(mfrow = c(2,2))
plot(sp_lm_xy_scaled)


scale(spatdat_dt)


```

```{r plot-lm}

summary(sp_lm)
tidy(sp_lm)
augment(sp_lm)
glance(sp_lm)


# plot coefs:
sp_coefs <- tidy(sp_lm, conf.int = TRUE) %>% mutate(mod = "wo_xy")
sp_coefs_xy <- tidy(sp_lm_xy, conf.int = TRUE) %>% mutate(mod = "w_xy")

sp_coefs_combo <- bind_rows(sp_coefs, sp_coefs_xy)
sp_coefs
sp_coefs1
plot(sp_lm)[1]

print(sp_coefs_combo, n = 26)

scale()

ggplot(data = sp_coefs_combo %>% filter(!term %in% c("(Intercept)", "x", "y", "working_age_pop")),
       mapping = aes(x = estimate, y = fct_reorder(term, desc(estimate)),
                     color = mod)) + 
  theme_classic() +
  geom_point() + 
  geom_errorbar(mapping = aes(xmin = conf.low, xmax = conf.high), width = 0.3) + 
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Mean Coefficients", y = "Predictor", 
       color = "Model specification") #+ 
  # facet_wrap(cols = vars(term), switch = "y",
  #            scales = "free")


scale(spatdat)



# ------------------------------------------------------------------ #
# scaled:
expression("Temperature " (degree~C))
sp_coefs_scaled0 #<- sp_coefs_scaled
sp_coefs_scaled1 # <- sp_coefs_scaled


# rename coefficients:
sp_coefs_scaled <- 
  tidy(sp_lm_xy_scaled, conf.int = TRUE) %>%
  mutate(term_new = ifelse(term == "scale(gdd0)", "Growing Deg. Days (0 °C)",
                     ifelse(term == "scale(elevation)", "Elevation",
                      ifelse(term == "scale(slope)", "Slope",
                       ifelse(term == "scale(soil_ocs)", "Soil Organic Content",
                       ifelse(term == "scale(soil_cec)", "Soil Cation Exchange Capacity",
                       ifelse(term == "scale(soil_ph)", "Soil pH",
                        ifelse(term == "scale(maize_YieldPerHectare)", "Maize Yield (kg/ha)",
                        ifelse(term == "scale(yield_change_maize)", "Maize Yield Change (%/yr)",
                         ifelse(term == "scale(pop_density_change_80_20)", "Change in Pop. Density ('80-'20)",
                          ifelse(term == "scale(net_migration_1970.1980)", "Net Migration ('70-'80)",
                          ifelse(term == "scale(working_age_pop)", "Working Age Pop.",
                          ifelse(term == "scale(median_age_class)", "Median Age Class",
                          ifelse(term == "scale(gdp_per_capita_change)", "Change in GDP Per Capita",
                          ifelse(term == "scale(gdp_total_change)", "Change in Total GDP",
                          ifelse(term == "scale(accessibility_2015)", "Accessibility (2015)",
                                                                     term))))))))))))))))



         
# gg_sp_coef_scaled <- 
  ggplot(data = tidy(sp_lm_xy_scaled_full, conf.int = TRUE) %>% 
           filter(!term %in% c("(Intercept)", "x", "y")),
         mapping = aes(x = estimate, y = fct_reorder(term_new, desc(estimate)))) + 
  theme_classic() +
  geom_point() + 
  geom_errorbar(mapping = aes(xmin = conf.low, xmax = conf.high), width = 0.3) + 
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Mean Coefficients (Scaled)", y = "Predictor", 
       color = "Model specification") #+ 
  # facet_wrap(cols = vars(term), switch = "y",
  #            scales = "free")


# save plot  
ggsave(plot = gg_sp_coef_scaled, 
       filename = paste0(p_plots, run_label, "/spatial_reg/", "lm_coef_scaled", #run_label,
                         ".pdf"), 
       width = 5, height = 3.5, units = "in")

```

```{r save-max-age-map}

```


# Results outline

3. Spatial predictors of age and recultivation

- coefficients on various predictor variables
- map of *abandonment age in 2017*
- map of *max age*

Fig. 8. Coefficients on spatial predictors (vertical, showing coefficients on slope, elevation, suitability, population)
Fig. 9. Maps of a) abandonment *age in 2017* and b) *max age* for example site.




```{r start}
source("scripts/0_start.R")
env_size(ls())

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-site-data}
# copied from 6_figures on Feb 1 2021

# for use on cluster:
# p_dat <- "/scratch/network/clc6/abandonment_trajectories/data_derived/"
# p_dat_derived <- "/scratch/network/clc6/abandonment_trajectories/data_derived/"
# p_output <- paste0("/scratch/network/clc6/abandonment_trajectories/output/")
list.files(p_dat_derived)

site_df <- read.csv(file = paste0(p_dat_derived, "site_df.csv"))


# Land use class codes:
#       1. Non-vegetated area (e.g. water, urban, barren land)
#       2. Woody vegetation
#       3. Cropland 
#       4. Herbaceous land (e.g. grassland)

# testers:
bs <- brick(paste0(p_dat, "Abandonment/belarus_small.tif"))
bt <- brick(paste0(p_dat_derived, "belarus_subset.tif"))
names(bs) <- paste0("y", 1987:2017)
names(bt) <- paste0("y", 1987:2017)


# -------------------------- rasters --------------------------- #
# raw rasters
s <- brick(paste0(p_dat_derived, "input_rasters/shaanxi.tif"))
b <- brick(paste0(p_dat_derived, "input_rasters/belarus.tif")) # merged version

# age
s_age_r <- brick(paste0(p_dat_derived, "shaanxi_age.tif"))
b_age_r <- brick(paste0(p_dat_derived, "belarus_age.tif"))

# max_length
s_max_length_r <- brick(paste0(p_dat_derived, "shaanxi_max_length.tif"))
b_max_length_r <- brick(paste0(p_dat_derived, "belarus_max_length.tif"))

# update year names 1987 - 2017
names(s) <- paste0("y", 1987:2017)
names(b) <- paste0("y", 1987:2017)
names(s_age_r) <- paste0("y", 1987:2017)
names(b_age_r) <- paste0("y", 1987:2017)


# prepared input rasters (derived by Chris)
site_input_raster_files <- list.files(paste0(p_dat_derived, "input_rasters"), full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = TRUE)

r <- lapply(seq_along(site_input_raster_files), function(i) {brick(site_input_raster_files[i])})
names(r) <- site_df$site

# rename raster layers:
for (i in 1:11) {
  if (names(r[i]) == "nebraska") {
    names(r[[i]]) <- paste0("y", 1986:2018)
  } else {
    if (names(r[i]) == "wisconsin") {
      names(r[[i]]) <- paste0("y", 1987:2018)
    } else {
      # everything else, just 1987:2017
      names(r[[i]]) <- paste0("y", 1987:2017)
    }}}


# abandonment age maps (produced by Chris)
age_files <- list.files(paste0(p_dat_derived, "age_rasters"), full.names = TRUE) %>%
  grep(".tif", ., value = TRUE) #%>% grep("age", ., value = TRUE, invert = FALSE)

age_r <- lapply(seq_along(age_files), function(i) {brick(age_files[i])})
names(age_r) <- site_df$site
for (i in seq_along(age_r)) {names(age_r[[i]]) <- paste0("y", 1987:2017)} # remember: these are just 1987:2017

# year of first abandonment maps (from He)
yoa_files <- list.files(paste0(p_dat, "Abandonment/year_of_abandonment/"))

# -------------------------- data.tables --------------------------- #
b_age <- fread(input = paste0(p_dat_derived, "belarus_age.csv"))
names(b_age)
s_age <- fread(input = paste0(p_dat_derived, "shaanxi_age.csv"))


b_length <- fread(input = paste0(p_dat_derived, "lengths/", "belarus_length_b1.csv"))
s_length <- fread(input = paste0(p_dat_derived, "lengths/", "shaanxi_length_b1.csv"))

b_max_length <- fread(input = paste0(p_dat_derived, "lengths/", "belarus_max_length_b1.csv"))
s_max_length <- fread(input = paste0(p_dat_derived, "lengths/", "shaanxi_max_length_b1.csv"))

# original data
s_dt <- fread(input = paste0(p_dat_derived, "shaanxi.csv"))
names(s_dt) <- gsub(pattern = "andcover", replacement = "y", names(s_dt))

b_dt <- fread(input = paste0(p_dat_derived, "belarus.csv")) # caution - huge file! 8.4 GB at least. 



# -------------------------- summarized data.frames --------------------------- #
indx <- 9
site <- site_df$site[indx] # set site:
site_label <- site_df$label[indx] # set label
blip_label <- "_b1"
load(file = paste0(p_output, "abn_dat_products", blip_label, site_label, ".rds"), verbose = TRUE)

# loads:
area_b1_s
persistence_list_b1_s
abn_area_change_b1_s



```

```{r load-predictor-data}
# elevation
# de Ferranti's data:
# 110 - 112 E
# 38 - 40 N


# slope
# soils

```

```{r simple-plots}
# copied from 6_figures on Feb 1 2021

# -------------------------- plot raw data --------------------------- #
plot(s$y1987, main = "Sha(a)nxi 1987", breaks = c(0, plot_cols$breaks), col = plot_cols$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols$name, 
       fill = plot_cols$color)

plot(s$y2017, main = "Sha(a)nxi 2017", breaks = c(0, plot_cols$breaks), col = plot_cols$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols$name, 
       fill = plot_cols$color)

# ---------------------- plot abandonment age ---------------------- #
plot(s_age_r$y2017, main = "Sha(a)nxi Age of Abandonment 2017")
plot(s_age_r[[28:31]])

# -------------------------- animate --------------------------- #
# --------------
# https://www.rdocumentation.org/packages/raster/versions/3.1-5/topics/animate

animate(bt, pause = 0.5, zlim = c(1, 4), maxpixels=5000, n=1,
        breaks = c(0, plot_cols$breaks), col = plot_cols$color)

```

## Methods

- start with a regular OLS regression (lm)
- check out the residuals (the model errors) - if they are clumped, or there is a clear trend in them, then, they might be spatially auto-correlated.
- Calculating Moran's I helps identify spatial autocorrelation. 
- see code Liang shared by Raymond Huey 2020 ("/Users/christophercrawford/Google Drive/_Projects/abandonment_trajectories/scripts/Spatial analysis w Depth 2020-03-20.R")
- see code from Umesh's stats course. 

@Levers2018a use the R package `mboost` from [Hothorn et al. 201o](http://mboost.r-forge.r-project.org/) to implement "boosted regression trees" or BRT. This method has an advantage because, as quoted from @Pazur2020, "The advantages of BRT modelling compared to conventional statistical methods, such as ordinary least squares and logistic regressions, is that it allows capturing the non-linear relationship between the dependent and independent variables, does not require a normal distribution assumption and is robust against the multicollinearity of variables (Elith et al. 2008)." 

I had initially been thinking that I wouldn't need to account for too much spatial variation, since the models can have site fixed effects that account for this spatial variation. But, it might be worth exploring these BRT models.

See also the package `gbm`, and the documentation from the package [`dismo`](https://rspatial.org/raster/sdm/9_sdm_brt.html).

@Dara2018

@Pazur2020 and @Pazur2020a also use boosted regression trees

### Regression methods

1. Regular OLS regression, with a site-level fixed effect to allow for different relationships with predictors at the different sites.
2. A fancier boosted regression tree machine learning approach:
    + [Gradient boosting machines](http://uc-r.github.io/gbm_regression)
    + [Boosted regression trees for ecological modeling](https://rspatial.org/raster/sdm/9_sdm_brt.html)

See:
@Levers2018a
@Pazur2020a

Machine learning packages suggested by Alex:
- [`randomForest`](https://cran.r-project.org/web/packages/randomForest/index.html)
- [`ranger`](https://github.com/imbs-hl/ranger)
- [`https://xgboost.ai/`](https://xgboost.ai/)

@Pazur2020 used `dismo`.
@Levers2018 used `mboost`






UPDATE: I am just going to downscale data to the 30 m resolution. I will then take a random sample from a grid (0.5 km grid), rather than aggregating. 
Old: in order to perform a regression, I need to aggregate abandonment age pixels to match the coarser scale of my predictors (most of which are ~1km)

```{r old-aggregate-abn-age}
# plot
# -------------------------- plot raw data --------------------------- #
plot(s$y1987, main = "Sha(a)nxi 1987", breaks = c(0, plot_cols$breaks), col = plot_cols$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols$name, 
       fill = plot_cols$color)

plot(s$y2017, main = "Sha(a)nxi 2017", breaks = c(0, plot_cols$breaks), col = plot_cols$color)
legend("bottomleft", cex = 0.6, inset = 0,
       legend = plot_cols$name, 
       fill = plot_cols$color)

# ---------------------- plot abandonment age ---------------------- #
plot(s_age_r$y2017, main = "Sha(a)nxi Age of Abandonment 2017")
plot(s_age_r[[28:31]])



# 30 m resolution -> 1000 m resolution ------------------------------------------- #
# In order to go from 30 m to 1000m, first I downscale the 30 m grid to a 10 m grid, 
# by disaggregating with a factor of 3. This yields nine 10 m x 10 m pixels within each 
# of the original pixels. These are then aggregated by factor of 100, in order to 
# get to a 1000 m x 1000 m grid.

(1 / (3^2)) * (30/1000)^2 # 1/10,000
(1/100)^2

(1/3)^2 * (100)^2 # There are 1111.11 30m x 30m pixels in a 1km x 1km pixel.


ncell(s_age_r$y2017)

# create intermediary raster, to aggregate 
sa <- s_age_r$y2017


# age raster, with NA values set to 0:
sa_na_0 <- s_age_r$y2017
sa_na_0[is.na(sa_na_0)] <- 0

# all the same:
plot(sa, main = "sa, including NA")
plot(sa_na_0, main = "sa, with NA set to 0")
plot(s_age_r$y2017, main = "(a) Shaanxi: abandonment age in 2017")


# aggregate pixels to 1km x 1km.
sa_agg_mean <- aggregate(
  disaggregate(sa, fact = 3), 
  fact = 100, fun = mean)

sa_agg_mean_na_0 <- aggregate(
  disaggregate(sa_na_0, fact = 3), 
  fact = 100, fun = mean)

plot(sa_agg_mean, main = "(b) Aggregated with mean, NA removed")
plot(sa_agg_mean_na_0, main = "(c) Aggregated with mean, NA set to 0")


# create a binary abandonment raster
sa_bin <- sa
sa_bin[!is.na(sa_bin)] <- 1
plot(sa_bin, main = "Binary abandonment map (2017)")

# calculate the proportion of 30m x 30m pixels within 1km x 1km pixel
# that are abandoned:
sa_count <- aggregate(
  disaggregate(sa_bin, fact = 3), 
  fact = 100, fun = sum) / (100^2) # note that because the count is of 10 m pixels (there are 9 of these in each 30m pixel), this must be divided by 100^2

plot(sa_count, main = "(d) Proportion of pixel abandoned")


# note that this is the same as mean with NAs set to 0
plot(sa_agg_mean*sa_count, main = "Weighted average age")
plot(sa_agg_mean_na_0, main = "(c) Aggregated with mean, NA set to 0")


# other aggregation functions ----------------------------------------------- #

sa_agg_max <- aggregate(
  disaggregate(sa, fact = 3), 
  fact = 100, fun = max)

sa_agg_median <- aggregate(
  disaggregate(sa, fact = 3), 
  fact = 100, fun = median)

plot(sa_agg_max, main = "aggregation method: max")
plot(sa_agg_median, main = "aggregation method: median")
```

```{r age-histogram}
s_age <- fread(input = paste0(p_dat_derived, "shaanxi_age.csv"))


# histogram of age values in 2017
s_age[, .N, by = y2017][order(y2017)][y2017 >= 5] %>% data.frame() %>% 
  ggplot(data = ., mapping = aes(x = y2017, y = N)) + 
  geom_col()


# hist(s_age_r$y2017) # Caution: this is very slow. 
```


```{r old-save-agg-rasters-to-png}
# First, comparing the aggregation methods: decided to use the mean as the best method. 
png(file = paste0(p_output, "plots/age_aggregation_comparison.png"),
      width = 10, height = 3, units = "in", res = 400)
par(mfrow = c(1, 4), oma = c(0,0,0,1))

plot(s_age_r$y2017, main = "Shaanxi Age, 2017")
plot(sa_agg_mean, main = "Aggregated w mean")
plot(sa_agg_max, main = "Aggregated w max")
plot(sa_agg_median, main = "Aggregated w median")
dev.off()




# Second, comparing the NA removal methods: decided to leave the NAs removed 

png(file = paste0(p_output, "plots/age_agg_na_rm_v_na_0_wide.png"),
    width = 11, height = 3,
    units = "in", res = 400)
par(mfrow = c(1, 4), oma = c(0,0,0,1))
plot(s_age_r$y2017, main = "(a) Shaanxi: abandonment age in 2017")
plot(sa_agg_mean, main = "(b) Aggregated with mean, NA removed")
plot(sa_agg_mean_na_0, main = "(c) Aggregated with mean, NA set to 0")
plot(sa_count, main = "(d) Proportion of pixel abandoned")
dev.off()

```


