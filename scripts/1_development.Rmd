---
title: "Trajectories of Abandonment and Biodiversity, start document"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
Repository for work to investigate the trajectories of abandoned agricultural land, and implications for biodiversity

```{r initialize}
source("scripts/0_start.R")
```

```{r load-data}

# Land use class codes:
#       1. Non-vegetated area (e.g. water, urban, barren land)
#       2. Woody vegetation
#       3. Cropland 
#       4. Herbaceous land (e.g. grassland)

bs <- brick(paste0(p_dat, "Abandonment/belarus_small.tif"))
plot(bs)
nlayers(bs) # 31 years in the time series
plot(bs$smolensk1987)


# load as a data.table
bs_dt <- as.data.table.raster(bs)


ncol(bs_dt) # 31 years, plus x and y = 33.
object_size(bs_dt)



# full landsat scene, but just for individual years
b87_r <- raster("/Users/christophercrawford/Google Drive/_Projects/data/Abandonment/belarus_1987.tif")
b88_r <- raster("/Users/christophercrawford/Google Drive/_Projects/data/Abandonment/belarus_1988.tif")

plot(b87_r)
plot(b88_r)
extent(b87_r)
extent(b88_r)
ncell(b87_r)
ncell(b88_r)

# as data.tables
tic()
dt_b87 <- as.data.table.raster(b87_r)
dt_b88 <- as.data.table.raster(b88_r)
toc()

object_size(dt_b87)
object_size(dt_b87[, .(x, y)])
object_size(dt_b87[, .(belarus_1987)]) # 378 MB approximately for each year.
object_size(dt_b87) + object_size(dt_b87[, .(belarus_1987)])*30 # this is an approximation of how large the full data.table of the full scene, as a data.table, would be. 
# 13.2 GB. This is huge. I'll have to come up with some better way to do this... 
# perhaps start by figuring this out in R, then transfer it to python, and then google earth. 

object_size(dt_b88)

dt_merge <- merge(dt_b87, dt_b88, by = c("x","y"), sort = FALSE)


# write data.tables to files, for easier reading in:
fwrite(dt_b87, file = paste0(p_dat, "Abandonment/belarus_1987_dt.csv"))
fwrite(dt_b88, file = paste0(p_dat, "Abandonment/belarus_1988_dt.csv"))
fwrite(dt_merge, file = paste0(p_dat, "Abandonment/belarus_1987-88_dt.csv"))

rm(dt_b87, dt_b88, dt_merge)
rm(dt_b87)

# load data.tables
dt_b87 <- fread(file = paste0(p_dat, "Abandonment/belarus_1987_dt.csv"))
dt_b88 <- fread(file = paste0(p_dat, "Abandonment/belarus_1988_dt.csv"))
dt_merge <- fread(file = paste0(p_dat, "Abandonment/belarus_1987-88_dt.csv"))

object_size(dt_merge)
dt_merge[, c("x", "y") := NULL]

# count occurence in each land use class
dt_b87[, .N, by = .(belarus_1987)] # one year
names(dt_b87)

object_size(dt_merge) # 2.27
object_size(dt_merge[, .(x, y)]) # 1.51 GB
object_size(dt_merge[, .(belarus_1987, belarus_1988)]) # 755 MB

object_size(dt_merge[, .(x, y)]) + # 1.51 GB
object_size(dt_merge[, .(belarus_1987, belarus_1988)]) * 31 / 2 # amount per year
# estimate of about 13.2 GB for the whole time series. Probably too big, so I'll have to explore another option. 

dt_merge[belarus_1988 == 2, ][, sum(belarus_1988)]
dt_merge[, sum(belarus_1988)]

hist(dt_merge[, 3])
dt_merge_counts <- dt_merge[, .(count = .N), by = belarus_1988]
barplot(data = dt_merge_counts, count ~ belarus_1988)
```

```{r colors}
# define color palette for plotting:
# 1. Non-veg
# 2. Woody veg
# 3. Crop
# 4. Grassland
plot_cols <- c("gray80", # gray, 1. Non-veg
               terrain.colors(9)[1], # dark green, 2. Woody veg
               terrain.colors(9)[5], # gold, 3. Crop
               terrain.colors(9)[3] # light green, 4. Grassland
               )
plot_cols_new <- c("gray80", # gray, 1. Non-veg
               terrain.colors(9)[5], # gold, 2 (formerly 3) Crop
               terrain.colors(9)[3], # light green, 3 (formerly 4) Grassland
               terrain.colors(9)[1]  # dark green, 4 (formerly 2) Woody veg
               )

plot_breaks <- c(0, 1, 2, 3, 4)


show_col(plot_cols)
show_col(plot_cols[c(1, 3, 2)])
```

```{r simple-plots}
show_col(plot_cols) # (topleft = 1, topright = 2, bottomleft = 3, bottomright = 4)
# gray,         1. Non-veg
# dark green,   2. Woody veg
# gold,         3. Crop
# light green,  4. Grassland

plot(b87_r, main = "Belarus 1987", breaks = plot_breaks, col = plot_cols)
plot(bs$smolensk1987, add = T, legend = F, col = "blue")
plot(bt$smolensk1987, add = T, legend = F, col = "red")
bs

plot(bs$smolensk1987, main = "Subset: Belarus 1987", 
     breaks = plot_breaks, col = plot_cols)

plot(bt$smolensk1987, main = "Subset Subset: Belarus 1987", 
     breaks = plot_breaks, col = plot_cols)


# --------------
# animate
# --------------
# https://www.rdocumentation.org/packages/raster/versions/3.1-5/topics/animate

animate(bt, pause = 0.5, zlim = c(1, 4), maxpixels=5000, n=1,
        breaks = plot_breaks, col = plot_cols)

```

```{r subset-rasters}
plot(bs$smolensk1987)
mapView(bs$smolensk1987)
ext_bt <- drawExtent(show = TRUE, col = "red")

bt <- crop(bs, ext_bt)
plot(bt$smolensk1987)


# --------------
# update values
# --------------

r <- bt$smolensk1987
r[r == 2] <- 5 # take, woody veg (2), set to 5
# you can leave it at that, or you can re-order:
r[r == 3] <- 2 # take cropland (3), set to 2
r[r == 4] <- 3 # take grassland (4), set to 3
r[r == 5] <- 4 # take 5 (woody veg), set to 4

plot(r)
plot(bt$smolensk1987, breaks = plot_breaks, col = plot_cols)  # 1 = nonveg, 2 = woody, 3 = crop, 4 = grassland
plot(r, breaks = plot_breaks, col = plot_cols_new)

# --------------
# update to simple, 1 = cropland, 2 = noncropland
# --------------
btb <- bt
btb[btb == 1] <- NA
btb[btb == 3] <- 1 # crop
btb[btb %in% c(2, 4)] <- 2 # noncrop

plot(btb[[1]]) # 1 = crop, 2 = noncrop (woody + grassland)
# to make it binary, just subtract 1.
plot(btb[[1]] - 1) # 0 = crop, 1 = noncrop (woody + grassland)



plot(btb[[1]], breaks = c(-1, 0, 1, 2), col = plot_cols[c(1, 3, 2)])
plot(btb[[1]], col = plot_cols[c(3, 2)]) # same, just simpler

# 1 = brown, agriculture
# 2 = green, non-agriculture


animate(btb, pause = 0.5, zlim = c(1, 4), maxpixels=5000, n=1,
        breaks = c(-1, 0, 1, 2), col = plot_cols[c(1, 3, 2)])
```

```{r 0-values}
# --------------------------
# note: not yet sure what to do with these 0s. Looks like there is some padding around the edges
nrow(dt_merge) # 94403140
dt_merge[belarus_1987 > 0, nrow(.SD)] # 92323484
dt_merge[belarus_1988 > 0, nrow(.SD)] # 94216056

nrow(dt_merge[belarus_1987 == 0,]) # 92323484
nrow(dt_merge[belarus_1988 == 0,]) # 94216056

dt_merge[, .(sum87 = nrow(.SD)), by = "belarus_1987"]
dt_merge[, .(sum88 = nrow(.SD)), by = "belarus_1988"]

dt_merge[, .N, by = belarus_1987]
dt_merge[, .N, by = belarus_1988]

# number of observations across all combinations
dt_merge[, .N, keyby = .(belarus_1987, belarus_1988)]

dt_0 <- dt_merge[belarus_1987 == 0, ]
dt_0[belarus_1987 == 0, belarus_1987 := 7]
dt_0[belarus_1988 == 0, belarus_1988 := 8]
dt_merge
dt_0
r_0 <- dt_to_raster(dt_0, crs(bs))

plot(b87_r, col = plot_cols)
plot(r_0$belarus_1987, col = "red", add = T)
plot(r_0$belarus_1987)

test_ext <- drawExtent(show=T, col="red")
plot(r_0$belarus_1987, ext = test_ext)


dt_merge[, summary(y)]
dt_0[, summary(y)]
mapView(r_0)
ncell(r_0)


cellStats(b87_r, "summary")
ncell(b87_r)
summary(b87_r)
test <- b87_r
test[test == 0] <- 8
plot(test, col = plot_cols)

(187084 / 94403140) * 100

freq(b87_r)
#      value    count
# [1,]     0   187084
# [2,]     1  1892572
# [3,]     2 32779466
# [4,]     3 26552258
# [5,]     4 32991760

freq(r_0)

```

```{r big}
# how do I deal with such a large data.table?

# two real options: 
# 1. load the data onto adroit and run the codes there, or
# 2. break the raster brick into chunks, maybe four or 9. 

# test it
test_dt1 <- copy(bs_dt)
test_dt2 <- copy(bs_dt)
test_dt2[, c("x", "y") := NULL]

tic(); cc_update_lc(test_dt1); toc()
tic(); cc_update_lc(test_dt2); toc()
identical(test_dt1[, !c("x", "y")], test_dt2)

bin_test1 <- test_dt2 -1
bin_test2 <- copy(test_dt2)

# big file
rm(dt_merge)
dt_merge <- fread(file = paste0(p_dat, "Abandonment/belarus_1987-88_dt.csv"))
dt_merge[, c("x", "y") := NULL]
names(dt_merge) <- gsub("belarus_", "y", names(dt_merge))
object_size(dt_merge)

# add more columns, if desired
dt_merge[, c(paste0("y", 1989:2004)) := .(y1987, y1988, y1987, y1988, 
                                          y1987, y1988, y1987, y1988, 
                                          y1987, y1988, y1987, y1988, 
                                          y1987, y1988, y1987, y1988)] 

fwrite(dt_merge, file = paste0(p_dat, "Abandonment/test_big_dt_merge.csv"))
rm(dt_merge)
dt_merge <- fread(file = paste0(p_dat, "Abandonment/test_big_dt_merge.csv"))
env_size(ls())


# alternatively
big <- cc_create_dt(numrow = 5*1e7, numcol = 15)
big

object_size(big)


```

```{r prep_data.table}
# load as a data.table
bs_dt <- as.data.table.raster(bs)

# update column names
names(bs_dt) <- gsub("smolensk", "y", names(bs_dt))
bs_dt
object_size(bs_dt)

# count all cells in each column in each class

bs_dt[, .N, by = .(y1987)] # one year
bs_dt[, .N]

bs_dt[, .(y1987)]
bs_dt[, c("y1987")]
bs_dt[, names(bs_dt)[3], with = FALSE]


# remove NA values
# to remove all rows with NA values
na.omit(dt) 



# update cell values: see _util_dt_functions.R
tic()
cc_update_lc(bs_dt)
toc() # 0.035 seconds for the bs subset


# to make it binary, just subtract 1, or use the function cc_make_binary(): see _util_dt_functions.R
tic()
cc_make_binary(dt)
toc()
# 1 for noncrop
# 0 for crop



# update classes
tic(); cc_update_lc(dt_merge); toc() # 46.621, nice, this seems to have worked.

# remove NAs
tic()
na.omit(dt)
toc()

tic(); cc_make_binary(dt_merge); toc() # 6.8 GB, 13.43 seconds 
identical(bin_test1, bin_test2)
dt_merge[, y1987 := y1987 -1]
dt_merge[, y1988 := y1988 -1]


# update cell values:
tic()
cc_update_lc(dt_merge)
toc() # 4.51 seconds for the full dataset for 1987 and 1988. This will likely take more than a minute for the full raster brick.

bi <- dt_merge - 1
# 1 for noncrop
# 0 for crop


# older code:

# just the subset of the subset
bdt <- as.data.table.raster(bt)
names(bdt) <- gsub("smolensk", "y", names(bdt))
bdt[, c("x", "y") := NULL]
bdt

# update options for printing (it defaults to 100)
# options(datatable.print.nrows = 20)
# print(bdt, nrows=20)

# -------------------
# can also use this, but I think it's slower
tic()
bdt[bdt == 1] <- NULL # nonveg
bdt[bdt == 3] <- 1 # crop
bdt[bdt == 4] <- 2 # noncrop
toc()


```

```{r calc-diff}
# --------------
# diff with data.table...
# --------------
# first, copy the data.table, then remove the first column, add a NA column at the end.
# then simply subtract the two DT
DT_lead <- copy(DT)
DT_lead[, y1987 := NULL][, end := NA]

DT_diff <- DT_lead - DT # this works just the same.
DT_diff[, end := NULL]


# simplified, as a function (note, that it sets end to 0 and doesn't remove end as the last step)
dt
dt_diff2 <- cc_make_diff(dt)


# using apply works too, but it's slow with big data.tables
# this works on either data.frames or data.tables, but it's really slow with big data.tables, since it has to transpose all the rows. 
tic(); t(apply(as.data.frame(DT), 1, diff)); toc()
tic(); t(apply(DT, 1, diff)); toc()

diff2 <- copy(DT)
diff2[, sum3 := sum(.SD, na.rm = TRUE), by = seq_len(nrow(DT_diff))]

dt_b87[, ':='(v1 = 1, v2 = 2, v3 = 3)]
big_df <- as.data.frame(dt_b87)
head(big_df)
tic()
diffbig <- t(apply(dt_b87, 1, diff)) %>% data.table()
toc() # this didn't even finish after nearly 2 hours.

# testing the simple method with a big file. I'll probably run out of memory on my computer, and will have to do this on a cluster.
tic()
DT_big <- copy(dt_b87)
toc() # 4.5 sec

DT_big[, x := NULL][, end := NA]

tic()
DT_bigdiff <- DT_big - dt_b87 # this works just the same.
DT_bigdiff[, end := NULL]
toc() # 12.71 seconds



# ---------------------------------------------------------------------------
# performing functions on individual rows
# ---------------------------------------------------------------------------
# one way is by using by = 1:nrow

DT
DT_diff # 1 means change from crop (1) to non crop (2), i.e. abandonment
# -1 means change from noncrop (2) back to crop (1), i.e. recultivation
backup_diff <- copy(DT_diff)
DT_diff <- copy(backup_diff)

DT
dt_b87 # 94 million rows.

rowSums(DT_diff)





# -------------------
# this works for rowSums
DT_diff[, sum := rowSums(.SD, na.rm = TRUE)]
ncol(DT_diff)
DT_diff[, sum2 := rowSums(.SD, na.rm = TRUE), .SDcols = 1:13] # select columns
tic(); dt_b87[, sum2 := rowSums(.SD, na.rm = TRUE), .SDcols = 4:6]; toc() # 5.5 seconds
dt_b87[, sum2 := NULL]

DT_diff

# this works to apply functions to each individual row: the same as by = 1:nrow(DT)
DT_diff[, sum3 := sum(.SD, na.rm = TRUE), by = seq_len(nrow(DT_diff)), .SDcols = 1:13]
DT_diff[, sum4 := sum(.SD, na.rm = TRUE), by = 1:nrow(DT_diff), .SDcols = 1:13]
# the .SD in the j part of the data.table should refer to the subset of DT calculated by by
# which means..... I shouldn't have to subset it further. .SD > 0 should work as a logical statement
DT_diff[, sum4:=NULL][, sum3:=NULL]

# doesn't work
# DT_diff[, sum4 := sum(.SD, na.rm = TRUE), .SDcols = .SD > 0, by = seq_len(nrow(DT_diff))]
# DT_diff[, sum4 := sum(.SD[.SD > 0], na.rm = TRUE), by = seq_len(nrow(DT_diff))]
DT_test <- DT_diff[, .SD > 0][] %>% data.table()
DT_test[, positive := rowSums(.SD, na.rm = TRUE)][]
```


```{r age-per-pixel}
# make your own
set.seed(34L)
age <- matrix(round(runif(15*15)), nrow = 15, ncol = 15) %>%
  as.data.frame()
setDT(age)
# age <- as.data.table(age) # also works, but is less efficient because it creates a copy in memory. Not a big deal either way though.

# or just copy bin from above:
age <- copy(bin)

# update the names
names(age) <- paste0("y", 1:ncol(age))

# ---------------------------------------------------------------------------
# calculate age of each pixel since, for just one column
# ---------------------------------------------------------------------------
age[y2 > 0, y2 := y1 + 1][]

# this code does the following:
# take age, subset rows where y2 > 0, and 
# then set those equal to the value in column y1 for that row + 1.
# Note: the [] at the end prints the result.

# in order to loop over the columns, the code needs some massaging to get it to accept
# character vectors, which can be referenced with indices to be looped over.
# get() is a base command that searches by name for the object. This allows the data.table to treat it like a variable name, without the quotes. The name of the column being updated can be in quotes, because the LHS := RHS form can be:
# DT[, c("colA", "colB", ...) := list(valA, valB, ...)]
age[get(names(age)[2]) > 0, names(age)[2] := get(names(age)[1]) + 1][]

age[, print(y1987)]
age[, y1987]

age
env_size(ls())

# ---------------------------------------------------------------------------
# full implementation with a for loop - the final code
# ---------------------------------------------------------------------------

# check _util_dt_functions.R for function to calculate age

cc_calc_age(age)
print(age)




# ----------------
# ----------------
# --------------------------------------------
# try it with a bigger data.table

# make your own
set.seed(39)
age <- matrix(round(runif(30*30)), nrow = 30, ncol = 30) %>%
  as.data.frame()
setDT(age)
# or 
big <- copy(bin)

# make age big:
for (i in 1:22) {
  big <- rbind(big, big)
}

big[, c(paste0("y", 2001:2005)) := .(y1987, y1988, y1989, y1990, y1991)] # add more columns, if desired

ncol(big)
object_size(big); nrow(big)
names(big) <- paste0("y", 1:ncol(big))

tic()
cc_calc_age(big)
toc() # 2.6 seconds on 491,520 rows
# 93.915 seconds for 62,914,560 rows, 14 columns. Wow! This should work fine, as long as I can figure out a good way to load in all that data. 




# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# old, unused, test code
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------

# trying it with set
# -------------------------------
calc_age_set <- function(dt) {
  for (x in 2:ncol(dt)) {
    set(dt, 
        which(dt[[names(dt)[x]]] > 0), 
        j = names(dt)[x], 
        value = dt[get(names(dt)[x]) > 0, get(names(dt)[x-1])] + 1)
  }
}

calc_age_set_ind <- function(dt) {
  for (x in 2:ncol(dt)) {
    set(dt, 
        which(dt[[x]] > 0), 
        j = x, 
        value = dt[get(names(dt)[x]) > 0, get(names(dt)[x-1])] + 1)
  }
}

big <- copy(bin)
for (i in 1:22) {big <- rbind(big, big)} # make age big:
object_size(big); nrow(big); ncol(big)
names(big) <- paste0("y", 1:ncol(big))

# benchmarking
tic(); cc_calc_age(big); toc() # 88.971 seconds for 62.9 million rows, 14 col
tic(); calc_age_set(big); toc() # 104.153 seconds for 62.9 million rows, 14 col
tic(); calc_age_set_ind(big); toc() # 101.752 seconds for 62.9 million rows, 14 col

# set (and set_ind) worked too, but it's a bit slower. I'll use the other since it's simpler, and keep this in the back pocket until then.



# original code
# -------------------------------
# You'll note that this code works on each column. My previous code worked on individual values in each row individually, then looping over the columns, then over all the rows. This ultimately ended up being much, much slower. I realized that data.tables could be subset up front based on values in a column, and then those values could be easily manipulated. It turns out it's much easier to iterate over columns than over rows, especially when we have something like 90 million rows!

# the old code looked like this:
for (i in 1:nrow(dt)) {
  for (j in 2:ncol(dt)) {
    if (dt[i][[names(dt)[j]]] > 0) {
      dt[i][[names(dt)[j]]] <- dt[i][[names(dt)[j - 1]]] + 1
    }
  }
}
# 0.131 sec for just 15 rows
# 254.958 sec for 15,000 rows
# so, estimating what it would take to do 94 million rows.
(94000000/15000 * 254) / 60 / 60 # jeeeeez 442 hours. That's untenable.





```



```{r filter-age-for-abandonment}
# At this stage, the "age" data.table captures the length of time a given pixel has been in noncrop (grassland or woody vegetation) since the start of the time period. However, we need to filter our land was already in noncrop at the start of the time-series, and never was in agriculture. Essentially, we need to select only those periods that come after a 0, signifying a period of cropland.


# Some filtering steps:
# 1. Must have crop (0) at some point in the time series. But... what about pixels that start in noncrop and transition to crop?
# 2. Must have crop specifically before noncrop transition. 



# -------------------------------
# create test dt
# -------------------------------
age <- copy(bin)
names(age) <- paste0("V", 1:ncol(age))
cc_calc_age(age)
print(age)

dt <- copy(age)

# or just bin, with a new row full of only 0s
dt <- copy(bin)
names(dt) <- paste0("V", 1:ncol(dt))
dt[12] <- 0

dt <- cc_create_bin()
dt <- cc_create_dt(numrow = 100000)
# -------------------------------
# 1. Start by filtering out those pixels that are definitely out of scope: either all noncrop or all crop: 
# -------------------------------
# First, filter out pixels that are either always crop or always non-crop. To do this, set rows with no 0s to NA (always non-crop, or 1) and rows with no 1s to NA (always crop). Then, remove those NA rows with na.omit().
# Or, this could be done first with the binary data.table, by selecting out rows with a rowSum > 0 but < 14. This is nice and simple.
# alternatively, use set(), but it still requires overwriting
# Alternatively, can use the age data.table, and select out rows with a value in the last column equal to the number of years in the time-series (14 in this example)

# ----------
# final code:
# no need to define rowsums as its own column first. 
dt <- dt[dt[, rowSums(.SD) > 0 & rowSums(.SD) < length(.SD)], ] # this is inefficient with memory, but since I'll be in adroit anyways, it'll probably be fine.

# as a function:
dt <- cc_filter_nonabn(dt)


# ----------
# unused options below

# binary first
# a. calculate rowsum
dt[, rowsum := rowSums(.SD)][rowsum == 0] # can also include .SDcols = 1:14

dt[between(rowsum, lower = 0, upper = length(dt) - 1, incbounds = FALSE), ]
# or 
dt <- dt[rowsum > 0][rowsum < 14] # this way of assigning is inefficient with memory, but since I'll be in adroit anyways, it'll probably be fine.

# b. with set() - probably much less efficient, and I still have to assign it at the end, so it doesn't help me there. Might as well just stick with the simple above.

set(dt, 
    i = dt[, which(rowSums(.SD) == 0 | rowSums(.SD) == 14)], # indices to change
    j = 1:length(dt), 
    value = NA)

dt <- na.omit(dt)


# c. with age
set(dt, i = which(dt[[length(dt)]] == length(dt)), j = 1:length(dt), value = NA) # to work with any number of columns. length() works just the same as ncol() but apparently is a bit faster

# -------------------------------
# 2. Then, calculate the age of pixels
# -------------------------------
dt <- cc_create_bin()
dt <- cc_filter_nonabn(dt)
cc_calc_age(dt)
dt[]

# -------------------------------
# 3. Then, erase the first period of noncrop prior to abandonment
# -------------------------------

# ----------
# a. select only cells that are noncrop in first year: dt[V1 > 0]
dt[V1 > 0]

which(dt_diff[[1]] == -1)
dt

row1 <- unlist(dt[1,]) %T>% print()
row1

dt
which(dt[1,] == 0)[1] # this is the index of the first column with a zero. This is where the periods start to refer to abandonment age.
dt[V1 > 0][1, ][]
which(dt[V1 > 0][1,] == 0)[1]
seq_len(which(dt[V1 > 0][1,] == 0)[1])

set(dt[V1 > 0], 
    i = 1L,
    j = seq_len(which(dt[V1 > 0][1,] == 0)[1]),
    value = -7)
# shoot, this doesn't work with the subsetting of the data.table in set. 
# I can either subset and assign prior to going through set, and then merge back together with the rows that start with 0, or figure out another way with DT[] syntax.
1:(which(dt[V1 > 0][5, ] == 0)[1] - 1) # columns

dt[V1 > 0, 
   ][V2 > 0
     ][V3 > 0
       ][V4 > 0
         ][V5 > 0
           ][V6 > 0
             ][V7 > 0, V7 := 0][]
# this illuminated that the periods that begin the time series in noncrop will always have an age in each year that is equal to the year, or the column index


# final codes:
# set any value that is equal to the index of the column to 0.
cc_erase_nonabn_periods(dt)





# -----------
# benchmark set() vs. dt[] with big file 

# alternatively, with set(), though this is slower, so I'm not using it:
cc_erase_nonabn_periods2 <- function(dt) {
  for (colindex in seq_len(length(dt))) {
    set(dt, 
        i = which(dt[[colindex]] == colindex),
        j = colindex,
        value = 0)
}
}

big <- cc_create_dt(numrow = 1e7, numcol = 15)

tic("full filtering")

tic("filter non abandonment pixels")
big <- cc_filter_nonabn(big)
toc()  # 42.141 sec

tic("calculate age")
cc_calc_age(big) 
toc() # 51.443

# start test
big1 <- copy(big)
big2 <- copy(big)
identical(big1, big2)

tic("erase non abandonment periods, 1, non set")
cc_erase_nonabn_periods(big1)
toc() # 4.294
nrow(big1) # 9999374

tic("erase non abandonment periods, 2, with set")
cc_erase_nonabn_periods2(big2)
toc() # 2.976
nrow(big2) # 3671767

identical(big1, big2)

toc()


```

```{r extract-age}
# -------------------------------
# 4. Extract periods from each pixel:
# -------------------------------
dt

# I want the values of cells that are immediately followed by a 0, or in the last column
dt[9, max(.SD)]
row9 <- unlist(dt[9, ], use.names = FALSE)
row9 %>% length
diff(row9) %>% length()
which(diff(row9) < 0)
row9[which(diff(row9) < 0)]

# make diff
dt_lead <- copy(dt)
dt_lead[, V1 := NULL][, end := 0]

dt_lead[, names(dt_lead)[1] := NULL][, end := 0]
dt_diff <- dt_lead - dt # this works just the same.
dt_diff

# as a function
cc_make_diff <- function(dt){
  dt_lead <- copy(dt)
  dt_lead[, names(dt_lead)[1] := NULL][, end := 0]
  dt_diff <- dt_lead - dt
}

dt
dt_diff2 <- cc_make_diff(dt)
identical(dt_diff, dt_diff2)

length(dt_diff)
dt_diff[V2 > 0, V2]
dt_diff[get(names(dt_diff)[14]) < 0, get(names(dt_diff)[14])]

# extract lengths

lengths <- cc_extract_lengths(dt_diff)


# try with a big file:

big <- cc_create_dt(numrow = 2e7, numcol = 15)
object_size(big)

tic("filter non abandonment pixels")
big <- cc_filter_nonabn(big)
toc()  # 42.141 sec

tic("calculate age")
cc_calc_age(big) 
toc() # 51.443

tic("erase non abandonment periods")
cc_erase_nonabn_periods(big)
toc() # 4.294


tic("make diff")
big_diff <- cc_make_diff(big)
toc() # 7.656 s for 20 M rows
object_size(big_diff) # 2.4 GB
env_size(ls())


tic("extract lengths")
big_lengths <- cc_extract_lengths(big_diff)
toc() # 15 sec for 20 M rows

object_size(big_lengths)
length(big_lengths)
big_lengths[big_lengths > 1] %>% length
table(big_lengths)

dt_lengths <- data.table(length = big_lengths)
dt_lengths[, .N, by = length]

identical(big1, big2)

toc()

```


```{r filtering-workflow}
dt <- cc_create_bin()
dt <- cc_filter_nonabn(dt)
cc_calc_age(dt) 
cc_erase_nonabn_periods(dt)
lengths <- cc_extract_lengths(dt_diff)

mean(lengths)
abs(lengths)
```


```{r plot-trajectory-per-pixel}
ncell(bt)
# subset the data.table, for plotting
sub <- bs_dt[1:10, -c(1,2)]
names(sub) <- gsub("y", "", names(sub))
sub[, pixel := c(1:10)]
sub


sub_melt <- melt(sub, id.vars = "pixel", 
                 variable.name = "year", 
                 value.name = "land_use", na.rm = TRUE)

sub_melt$year <- gsub("y", "", sub_melt$year)

str(sub_melt)

# set colors for plotting
show_col(terrain.colors(9))

lc_cols <- scale_color_manual(name = "Land Cover",
                     labels = c("1" = "1. Non-veg",
                                "2" = "2. Woody veg",
                                "3" = "3. Crop",
                                "4" = "4. Grassland"),
                     values = c("1" = "gray80",
                                "2" = terrain.colors(9)[1], # dark green
                                "3" = terrain.colors(9)[5], # gold
                                "4" = terrain.colors(9)[3] # light green
                                )
                     ) 

# this plot shows the land-use trajectories of 10 individual pixels.
gg_10_px_traj <- ggplot(data = sub_melt, 
                        mapping = aes(x = year, y = land_use, group = pixel)) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  geom_line(mapping = aes(color = factor(land_use)), size = 2) +
  facet_grid(rows = vars(pixel), scales = "free_x", switch = "x") + 
  ylim(1, 4) + lc_cols

gg_10_px_traj
#       1. Non-vegetated area (e.g. water, urban, barren land)
#       2. Woody vegetation
#       3. Cropland 
#       4. Herbaceous land (e.g. grassland)


```
Here's the game plan:
With RS' code, I have the following:
- the year of changes, and 




```{r data.table-tips}
library(data.table)

## Create a data table
set.seed(87L)
# DT <- data.table(V1 = rep(c(1L, 2L), 5)[-10],
#                 V2 = 1:9,
#                 V3 = c(0.5, 1.0, 1.5),
#                 V4 = rep(LETTERS[1:3], 3))

DT <- matrix(round(runif(15*15)), nrow = 15, ncol = 15) %>%
  as.data.frame()
setDT(DT)
names(DT) <- paste0("V", 1:ncol(DT))

DT[, sum(V1)]
DT[, lapply(.SD, mean),
     .SDcols = c("V1", "V2")]


# potentially useful things:
# ------------------------------
vec <- unlist(DT[1], use.names = FALSE) # extract a row as a vector


# data.table syntax
DT[, sum := sum(.SD, na.rm = TRUE), by = seq_len(nrow(DT))]
DT[, rowsum := rowSums(.SD, na.rm = TRUE), .SDcols = 1:14]

# row sums... there isn't anything more efficient than rowSums(). See https://stackoverflow.com/questions/15905257/getting-rowsums-in-a-data-table-in-r?lq=1

# note that you can also do this over a subset of columns, by selecting columns with .SDcols, like so:
DT[, sum2 := rowSums(.SD, na.rm = TRUE), .SDcols = grep("8", names(DT))][] 

```





Time-series with Raster

```{r RS-raster-time-series}
library(raster)

# Create test matrices with value of:
# 1 for agriculture and 
# 2 for non-agriculture
mat1 <- matrix(rep(1, 9), nrow = 3, ncol = 3)
mat2 <- matrix(c(rep(1, 3), 2, 2, 1), nrow = 3, ncol = 3)
mat3 <- matrix(c(rep(1, 3), rep(c(2, 1, 1), 2)), nrow = 3, ncol = 3)

# Create raster stack, with one raster for each year (randomly)
rastStack <- stack(raster(mat1),
                   raster(mat2), raster(mat2),
                   raster(mat1),
                   raster(mat2), raster(mat3), 
                   raster(mat1))

# Name the years
yrs <- 1:nlayers(rastStack)
names(rastStack) <- paste("yr", yrs, sep = "")

# Have a look
# yr2 -> two cells change to non-agriculture
# yr4 -> the two cells change back to agriculture
# yr5 -> the same two cells change to non-agriculture
# yr6 -> one of the two cells changes back to agriculture
# yr7 -> the other cell also changes back to agriculture

plot(rastStack)
plot(rastStack, breaks = c(-1, 0, 1, 2), col = c("gray", "yellow", "green"))

plot(rastStack, breaks = c(-1, 0, 1, 2), col = rev(terrain.colors(3)))
# 1 = brown, agriculture
# 2 = green, non-agriculture


# Sequential difference between years
# value of 0 = no difference compared to previous year (brown)
# value of 1 = change from agriculture to non-agriculture (green)
# value of -1 = change from non-agriculture to agriculture (gray)
running_diff <- calc(rastStack, fun = diff)
plot(rastStack, breaks = c(-1, 0, 1, 2), col = rev(terrain.colors(3)))
plot(running_diff, breaks = c(-2, -1, 0, 1), col = c("#ECB176FF", # brown
                                                     "#F2F2F2FF", # gray
                                                     "#00A600FF" # green
                                                     ))

# FYI: base::diff() # calculates the differences between each entry in a vector, or in this case, differences between cells across multiple years: i.e. 1987 - 1988, 1989 - 1988, 1990 - 1989, 1991 - 1990, etc.

# Multiply by the year to record the year in which change took place (and whether it was ag -> non-ag [positive], or non-ag -> ag [negative])
running_diff2 <- running_diff * yrs[-1] 
plot(running_diff2)

# Identify years with zero change
minVals <- minValue(running_diff2) # this is the years in which at least one pixel changed from noncrop (2) to crop (1), therefore yielding a negative value. 
minVals

maxVals <- maxValue(running_diff2) # this simply tells you years in which at least one pixel changed from ag to non-ag.
maxVals
# note, this can capture years in which both types of transitions took place (year 6)
nochange <- running_diff2[[which(maxVals == 0 & minVals == 0)]] # which index is 0 in both maxVals and minVals? Subset the stack by that index
plot(nochange)
 
plot(running_diff2) # tells you the year (the absolute value of the cell), and the transition type (negative means non-ag to ag, positive means ag to non-ag) 

# For each cell, we now know the year in which it changed from agriculture to non-agriculture
# and (potentially) back to agriculture (from running_diff2), from which we can calculate
# the number of non-agriculture periods and total time as non-agriculture

# count the number of "transitions", i.e. number of times the cell switched from crop to noncrop
# Number non-agriculture transitions = number years (bands) where cell value is positive
noncrop_count <- sum(running_diff2 > 0)
# Number agriculture reversions = number years (bands) where cell value is negative
crop_count <- sum(running_diff2 < 0)

plot(running_diff2)
plot(noncrop_count)
plot(crop_count)


# Convert original stack to binary -> 1 if non-agriculture, 0 if agriculture
rastStack_bi <- rastStack
rastStack_bi[rastStack_bi == 1] <- 0
rastStack_bi[rastStack_bi == 2] <- 1
# Total time as non-agriculture = sum across years
noncrop_duration <- calc(rastStack_bi, fun = sum)
plot(noncrop_duration)
plot(calc(rastStack, fun = sum))

# Average length of time as non-agriculture = total duration / N non-crop periods
noncrop_duration_avg <- noncrop_duration / noncrop_count
plot(noncrop_duration_avg)

# cell 2 [1,2] changes from agriculture in 2001, back to agriculture in 2003 = 2 years
# cell 2 [1,2] changes from agriculture in 2004, back to agriculture in 2006 = 2 years
# cell 2 [1,2] total time = 4 years; avg time = 4 years / 2 periods = 2 years

# cell 5 [2,2] changes from agriculture in 2001, back to agriculture in 2003 = 2 years
# cell 5 [2,2] changes from agriculture in 2004, back to agriculture in 2005 = 1 year
# cell 5 [2,2] total time = 3 years; avg time = 3 years / 2 periods = 1.5 years

```

```{r test-RS-TS}
animate(btb, pause = 0.5, zlim = c(1, 4), maxpixels=5000, n=1,
        breaks = c(-1, 0, 1, 2), col = plot_cols[c(1, 3, 2)])

plot(bs$smolensk1987, breaks = plot_breaks, col = plot_cols)
plot(bt$smolensk1987, add = T)

plot(btb, breaks = plot_breaks, col = plot_cols) # binary version of bt


# Name the years
yrs <- as.numeric(gsub("smolensk", "", names(btb)))
yrs <- 0:30
plot(btb$smolensk1987)


# Sequential difference between years
# value of 0 = no difference compared to previous year (brown)
# value of 1 = change from agriculture to non-agriculture (green)
# value of -1 = change from non-agriculture to agriculture (gray)
tic()
running_diff <- calc(btb, fun = diff)
toc()

tic()
bs_diff <- calc(bs, fun = diff)
toc()

ncell(btb)
ncell(bs)
ncell(b87_r)

plot(b87_r)
plot(bs$smolensk1987, add = T, col = "red")

plot(bs$smolensk1987)
plot(btb$smolensk1987, add = T, col = "red")



show_col(plot_cols[c(1, 3, 2)])
plot(btb[[1:16]], breaks = c(-1, 0, 1, 2), col = plot_cols[c(1, 3, 2)])
# 1 = brown, crop | 2 = green, noncrop

plot(running_diff[[1:16]], breaks = c(-2, -1, 0, 1), col = plot_cols[c(3, 1, 2)]) # brown (transition noncrop to crop), gray (no trans), green (transition crop to noncrop)
show_col(plot_cols[c(3, 1, 2)])
                                                

# Multiply by the year to record the year in which change took place (and whether it was ag -> non-ag [positive], or non-ag -> ag [negative])
running_diff2 <- running_diff * yrs[-1]
plot(running_diff2)

# identify years with at least one change... (this isn't all that useful, since there is a transition in each year.)
minVals <- minValue(running_diff2) #  years with > 1 transition noncrop (2) to crop (1)
maxVals <- maxValue(running_diff2) # years with > 1 transition crop (1) to noncrop (2)
nochange <- running_diff2[[which(maxVals == 0 & minVals == 0)]] # no changes
 
plot(running_diff2) # tells you the year (the absolute value of the cell), and the transition type (negative means non-ag to ag, positive means ag to non-ag) 

# count the number of "transitions":
noncrop_count <- sum(running_diff2 > 0) # Number transitions to noncrop (# years with positive value)
crop_count <- sum(running_diff2 < 0) # Number transitions to crop (# years with negative value)

plot(noncrop_count, main = "# transitions crop -> noncrop")
plot(crop_count, main = "# transitions noncrop -> crop")

object_size(running_diff2)



# Convert original stack to binary -> 1 if non-agriculture, 0 if agriculture
btb_bi <- btb
btb_bi[btb_bi == 1] <- 0
btb_bi[btb_bi == 2] <- 1
# Total time as non-agriculture = sum across years
noncrop_duration <- calc(btb_bi, fun = sum)
plot(noncrop_duration)

# Average length of time as non-agriculture = total duration / N non-crop periods
noncrop_duration_avg <- noncrop_duration / noncrop_count
plot(noncrop_duration_avg)

```


```{r install-OpenMP}
remove.packages("data.table")
install.packages("data.table", type = "source",
    repos = "https://Rdatatable.gitlab.io/data.table")

# cran version:
remove.packages("data.table")
install.packages("data.table")

# load
library(data.table)
getDTthreads()

```


